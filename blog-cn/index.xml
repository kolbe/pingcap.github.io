<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog-cns on PingCAP.com</title>
    <link>https://pingcap.com/blog-cn/</link>
    <description>Recent content in Blog-cns on PingCAP.com</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Dec 2018 00:00:00 +0000</lastBuildDate>
    
	<atom:link href="https://pingcap.com/blog-cn/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>TiDB 在小米的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-xiaomi/</link>
      <pubDate>Mon, 03 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-xiaomi/</guid>
      <description>作者：张良，小米 DBA 负责人；潘友飞，小米 DBA；王必文，小米开发工程师。
 一、应用场景介绍 MIUI 是小米公司旗下基于 Android 系统深度优化、定制、开发的第三方手机操作系统，也是小米的第一个产品。MIUI 在 Android 系统基础上，针对中国用户进行了深度定制，在此之上孕育出了一系列的应用，比如主题商店、小米音乐、应用商店、小米阅读等。
图 1 MIUI Android 系统界面图
目前 TiDB 主要应用在：
 小米手机桌面负一屏的快递业务 商业广告交易平台素材抽审平台  这两个业务场景每天读写量均达到上亿级，上线之后，整个服务稳定运行；接下来我们计划逐步上线更多的业务场景，小米阅读目前正在积极的针对订单系统做迁移测试。
二、TiDB 特点 TiDB 结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL 协议，支持无限的水平扩展，具备强一致性和高可用性。
具有如下的特性：
 高度兼容 MySQL，大多数情况下无需修改代码即可从 MySQL 轻松迁移至 TiDB，即使已经分库分表的 MySQL 集群亦可通过 TiDB 提供的迁移工具进行实时迁移。
 水平弹性扩展，通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松应对高并发、海量数据场景。
 分布式事务，TiDB 100% 支持标准的 ACID 事务。
 真正金融级高可用，相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。
  TiDB 的架构及原理在 官网 里有详细介绍，这里不再赘述。</description>
    </item>
    
    <item>
      <title>TiDB 在西山居实时舆情监控系统中的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-xishanju/</link>
      <pubDate>Sat, 09 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-xishanju/</guid>
      <description>作者介绍：邹学，舆情监控系统技术负责人，珠海金山网络游戏科技有限公司（西山居）数据中心架构师，2015 年加入西山居，具有 10 年游戏行业软件开发经验，主要参与了公司的游戏网关设计，数据分析框架底层架构建设等，现专注于实时计算、爬虫、分布式系统方向。
 公司简介 西山居创建 1995 年初夏，在美丽的海滨小城珠海，西山居工作室孕育而生，一群西山居居士们十年如一日尅勊业业的奋斗。&amp;rdquo;创造快乐，传递快乐！&amp;rdquo; 一直是西山居居士们的创作宗旨。西山居以领先的技术作为坚实的基础以独特的本土化产品为玩家提供时尚化服务。在未来，西山居仍以娱乐软件为主导产品，不断进行研发和市场活动，逐步发展成为国内最优秀的集制作、发行于一体的数字化互动娱乐公司。
业务背景 由于公司产品的社交属性都非常强，对相关舆情进行分析与了解就显得很有必要，在此背景下，舆情监控系统应运而生。该系统利用算法组提供的分词算法，对文本进行解析与分类，打上各类标记后再通过计算产生中间结果。舆情系统直接查询这些中间结果，产生各类报表与趋势图，为及时掌握各类舆情趋势提供便利。用户可以自由组合舆情关注点，从而对平台有很严格的实时交互性查询要求，是典型的实时 HTAP 类业务。
存储技术选型 舆情系统之前我们曾经实现过一个客服系统，这个系统要求能实时查询，但面对是海量的玩家行为记录。在当时情况下（2016 年），可以选择的对象只有 MyCAT 这类数据库中间件，通过综合压力测试后，我们选定了 KingShard 这一款由公司前同事开发的中间件，KingShard 虽然没有 MyCAT 丰富的周边功能，但它在满足我们业务需求的核心功能上有更快的表现。但正因为有了这一次中间件的使用，我们对中间件有了比较全面的了解，它们在查询优化上有着天生的弱点，无法满足更复杂的查询或者表现极不友好，为此我们还不得不砍掉了客服系统的部分业务功能，所以在那时我已开始寻找更优的技术方案，其中分布式数据库是我们考察的重点方向。
BigTable、GFS、MapReduce 是谷歌在分布式存储与查询领域的探索成果，他们没有公开具体实现代码，但却发布了相应论文，对分布式文件系统、大数据挖掘和 NoSQL 发展起了重大促进作用。开源界根据这一成果开发出对应产品是 HBase、HDFS、Hadoop，这三个产品红极一时，相关周边产品更是百花齐放，很多细分领域都同时出现了多个产品竞争，让整个生态非常繁荣但也变得复杂，提高了我们的学习与使用成本。那么，在一些领域中有没有更加简单、直接、具有较强融合能力的解决方案呢？此时距谷歌这三篇论文发表已近 10 年，谷歌内部早已在尝试融合 NoSQL 和 SQL，并对它们进行了多次更新换代，Spanner、F1 两篇论文便是谷歌在这一方向的探索成果。开源分布式数据库 TiDB 便是受论文启发而设计的 HTAP (Hybrid Transactional and Analytical Processing) 数据库，结合了传统的 RDBMS 和 NoSQL 的最佳特性，兼容 MySQL，具有支持分布式事务、无限的水平扩展、数据强一致性保证等核心 NewSQL 特性。
当时，舆情系统接入的第一个游戏平均每天入库数据量就已达到 8500 万条，并且还需要支持各种实时交互性查询，显然中间件已不能满足要求，传统的关系型数据库则更加不可能了。考虑到以后还会有其它游戏接入，我们果断选择了分布式数据库。 随着互联网经济的发展，数据量跟并发数也在飞速增长，单机数据库已越来越不能满足要求了，为此谷歌、阿里等大厂都有了自研的分布式数据库，但都没有开源，而 MySQL 的 MGR 及相关功能进展的步子太小，TiDB 的出现很好的弥补了市场空白，成为我们的唯一选择。
服务器配置 舆情系统是内部孵化项目，服务器具体如下：
新购物理机器 6 台：
旧物理机 4 台：</description>
    </item>
    
    <item>
      <title>北京银行企业级 NewSQL 数据库赋能金融科技建设</title>
      <link>https://pingcap.com/cases-cn/user-case-beijing-bank/</link>
      <pubDate>Tue, 27 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-beijing-bank/</guid>
      <description>作者介绍
于振华，北京银行软件开发部，核心系统架构管理，长期从事银行核心系统研发、规划，当前主要研发方向集中在构建先进、高效、面向OLTP的银行交易系统，提升银行信息系统服务能力。
张小龙，北京银行软件开发部，核心系统架构设计，长期从事银行核心系统对公业务、中间业务模型研发、规划，软件项目管理。参与构建新型面向OLTP的银行交易系统架构设计。
 近年来，国家不断提高对信息技术安全可控的战略要求，银行业希望在快速发展业务的同时不断降低经营成本。这不仅促使商业银行积极提升自主掌控能力，也促使商业银行对基础软件的服务能力、软硬件升级成本控制提出新的要求。与此同时，面对互联网金融带来的交易复杂度及交易频次的大幅提升，商业银行信息系统采用的传统数据库一体化解决方案，在应对此类场景时遇到了明显的性能瓶颈，而提升系统性能只靠替换式的硬件升级，成本昂贵。在这种背景下，引入一种高性能、可弹性扩展、能够支持OLTP场景的数据库成为我行系统建设的优先选择方案。
一、 分布式数据库的价值与应用场景 分布式事务数据库采用多种模式实现数据的分散存储，将数据库压力分散到不同服务器上。与集中式数据库相比，分布式数据库可以均衡交易负载，并采用高并发的架构提升系统的交易处理能力，而其统一的资源管理机制也使得数据库的性能扩展不再是设备的替换式升级，而是通过增加存储或计算节点来实现弹性升级，极大地节约了升级成本。
虽然分布式事务数据库在互联网应用场景下的探索取得了良好的成效和大量的实战经验，积累了很多成熟的技术，但相比互联网企业，金融行业对风险控制的要求更高，所以在面对高复杂度交易场景、业务实时一致性等方面的需求时，需要更为完善的技术方案支持。目前绝大部分分布式数据库解决方案都是基于 MySQL 主从复制结合分库分表中间件方式进行改造和集成，无法提供商业银行交易场景中的强一致性和完整的分布式事务要求，对业务和应用有侵入性，需要做一定的技术调整和事务妥协，并且此类架构离银行业务场景中的高可用和多中心容灾及多活的高级别安全要求也有一定距离。
所以，我行在选型前先确定了六个需要特别关注的特性：ACID 特性、横向扩展能力、可用性、可维护性、透明性、兼容性。需要特别说明的是透明性和兼容性，区域银行等体量的金融机构相比互联网企业来说科技资源有限，所以希望新的分布式数据库对架构、开发、运维的影响能够降到最低，同时能够支持传统系统的迁移。
新一代分布式 NewSQL 数据库对应用透明，像一个单机数据库一样使用，支持水平扩展的同时保证分布式事务和数据的强一致性，从而避免传统分库分表、事务补偿等方案对上层应用及业务流程的影响，另一方面如果能兼容传统单机数据库，传统应用平移时不需要人工改写代码，就能极大减少迁移成本。
二、具有北京银行特色的选型方案 由于金融行业对风险控制的严格要求，以及在交易复杂度、业务实时一致性等方面诉求不同于互联网企业。所以，我行对于分布式数据库的选择也比较谨慎,利用两轮专项POC评测来探索分布式数据库的适用场景及性能指标，稳步推进由传统数据库向分布式数据库的迁移。
在第一轮 POC 测试中，主要进行了多场景的性能测试。由于 Sysbench 等开源测试工具对 OLTP 的性能测试存在较大的局限性，于是我行提出了“标准化交易组”的概念，用银行真实交易逻辑，模拟多表跨节点事务，最大程度的还原银行实际应用场景，检验数据库产品的实际交易性能。
第二轮 POC 测试关注更为全面的数据库产品特性。在当前数据库主流评测指标的基础上，结合银行的关注要点，我行自主提出了一套“分布式事务数据库评测指标”（见图），将分布式事务数据库能力进行了分解，形成具体的指标项，使得评测标准更加标准化，评测结果更加客观。
图1：分布式事务数据库评测指标
选型过程中，从多维度考察了多家厂商的产品，包括 TPS、QPS 等性能指标，和算法性能、可靠性、安全备份、数据库兼容性、产品化程度等功能指标。同时，我行也得到了 Intel 实验室的大力支持，提供最新架构的计算和存储设备进行对比测试。
结合两轮 POC 结果，TiDB 分布式数据库产品表现出了架构的先进性和高效的性能，水平扩展能力、交易处理能力和功能指标均符合我行对分布式数据库产品的要求。其采用的 Raft 算法保证了数据的强一致性，同时可以实现两地三中心多活的部署方式，以上特性在应用中具备较大优势。除了优秀的开源社区环境，其背后的团队在开发支持、技术培训、运维服务、成本控制等方面也表现出了优秀的素质。
三、NewSQL 数据库平台的建设进展 我行在进行分布式事务数据库选型之初，就将目标定为可以承载银行核心系统与核心业务，所以选型过程和应用迁移都是基于这一目标，在数据库投产后将首先应用于互联网支付业务，之后迁移部分核心系统功能模块，并进一步扩展到其他场景的使用。其他感兴趣的用户也可以从非核心业务用起，或先作为备份数据系统。
为了更好满足应用端的需求以及业务的扩展，对业务的交易量和数据量进行了预估。结合预估结果以及行内系统建设要求，北京银行率先采用了两地三中心五副本的高可用部署架构方案，支持同城两中心多活，并具备服务器级、机柜级、数据中心级容灾能力。
随着业务不断发展，客户数量、账户数量、业务交易量都会上升，这对我行信息系统的数据存储能力、运算能力等方面提出了更高的要求。我行也对系统架构进行了长远规划，利用分布式 NewSQL 数据库集群的横向水平扩展能力，通过增加存储或计算节点来实现弹性升级，节约成本与实施难度。
2018 年 3 月 22 日，北京银行分布式 NewSQL 数据库集群正式投产，成为国内首家采用同类方案应用于核心交易场景的银行。在数据库投产后，将进行生产环境多活和灾备的验证，并开始应用切换。
四、对开源软件的一些理解 银行在开展技术能力转型建设的过程中，必然会应用越来越多的开源技术。开源软件是当前软件发展的趋势，互联网企业的大规模应用和快速迭代使开源软件成为先进技术事实上的代表。传统银行业使用开源软件的初衷是希望快速获得互联网企业同样的能力，但是否存在困难与阻碍呢？
第一、大部分银行的科技资源状况使之不具备源代码级的掌控能力和基于开源组件的架构设计能力。大多选择采用由国外社区控制的软件或是直接购买国内互联网公司封装好的全家桶解决方案，很难做到真正意义的自主、安全、可控。
第二、开源软件变化快、分支多、依赖“试错”的创新，跟银行追求稳健、长期的内部机制存在差异甚至冲突，反映在选型、测试、变更、运维等各个环节。
第三、开源软件的极客思维更多面向开发者，而非使用者，灾备、监控、审计等企业级功能经常落后于核心功能，在培训、ISV 持、维保服务上跟传统企业的需求还有差距。
所以银行业采用开源软件并取得成功的成本可能会比原有模式更高。值得欣慰的是，随着多年的技术积累，国内越来越多的类似 PingCAP 这样专注于底层核心基础软件研发的团队开始崭露头角，通过全球开源协作的方式极大的提升软件的迭代速度和成熟度，且愿意倾听传统行业的客户需求，有一颗做好产品与服务的诚心。不同于部分银行在新兴业务上采用互联网公司提供的整体外包解决方案，北京银行寻求自主可控能力，主动在模式和管理上创新，与互联网思维和技术不断切磋、碰撞、融合。通过研究、评测、应用、部署等工作，在实践中做到了自主掌控。双方在合作中互惠互利，利用双方优势，实现了信息系统服务能力的快速提升，打造出具有北京银行特色的创新驱动力。
五、结语 今后我行会尝试将更多高频高并发、对可扩展性和可用性有较高要求的业务场景迁移到分布式系统上。充分发挥分布式数据库的优势，探索和开辟创新发展的新路径。同时也希望我行在分布式数据库建设过程中的经验可以分享给更多的金融机构。借此北京银行愿与各同业机构和互联网企业携手并进，为推动银行数据库应用升级贡献自己的一份力量！</description>
    </item>
    
    <item>
      <title>TiDB 在海航易建科技与香港航空研发收益支持系统过程中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ekingtech/</link>
      <pubDate>Thu, 01 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ekingtech/</guid>
      <description>背景介绍 收益支持系统（Revenue Support System，简称 RSS）是海航易建科技与香港航空共同研发的基于大数据实时分析处理的航空业务支持和决策系统。RSS 的目标在于根据顾客需求进行市场细分和定价，在科学分析的基础上通过价格和座位库存控制手段平衡需求和供给的关系，将产品销售给合适的旅客，其核心价值在于支撑和帮助航空公司业务人员和决策者进行业务管理和科学决策。 RSS 在航空公司角色和定位，决定了该系统对 OLAP 和 OLTP 的操作在准确性和实时性方面具有很高的要求，并且由于航空公司每天产生海量的订票、值机、离港和财务数据，使得要求系统在数据存储方面要有很好的水平扩展能力。
前期方案 前期我们主要使用 MySQL 数据库,但是单表记录大于 2000 万行时，现有的业务报表查询和导出操作明显变慢，通过各种 sql 调优和代码优化手段，也无法继续满足服务等级协议，只能通过分库分表来解决，但是这会增加的后续业务逻辑开发复杂度与数据库运维困难。后来，随着业务的深入和数据的积累，代理人在全球各个全球分销系统（Global Distribution System，GDS）中的订座数据数据（Marketing Information Data Tapes，MIDT）就近2年的数据就超过 3.8 亿行，后续会同步近 10 年的数据，初步预估单表数据量将突破10亿条数据，并且后续每年的正常量可能会突破 2 亿条，如果继续使用 MySQL，必然面临着更细粒度分库、分表的难题，而且当前业界很多分表分库的中间件对 OLAP 支持的并不完美,而且很难满足复杂的 OLAP 需求，并且需要进行分表策略的额外配置。这样必然加大了开发和运维的难度和降低了开发的灵活性。
在这个过程中，我们曾经使用 HDFS + Hive + Spark + Kylin 作为大数据解决方案，但是这个方案对于实时的OLTP却满足不了。
为了满足两者的需求，我们需要把一份大数据存储两份，MySQL + 分表中间件做 OLTP 操作，HDFS + Hive + Spark + Kylin 做 OLAP 分析。
茅塞顿开 在业务遇到不可妥协的技术瓶颈后，我们重新评估业务模型，发现对于数据库的选型必须满足：
 支持业务弹性的水平扩容与缩容；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL 和复杂的查询，尽量少的改动代码；</description>
    </item>
    
    <item>
      <title>贝壳金服 TiDB 在线跨机房迁移实践</title>
      <link>https://pingcap.com/cases-cn/user-case-beikejinfu/</link>
      <pubDate>Mon, 22 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-beikejinfu/</guid>
      <description>作者介绍：李振环，贝壳金服数据基础架构负责人，目前负责数据平台和企业级数据仓库开发。
 一、公司介绍 贝壳金服是专注居住场景的金融科技服务商，起步于 2006 年成立的链家金融事业部，并于 2017 年 3 月正式独立运营。贝壳金服聚焦于居住场景，在租赁、买卖、家装、安居等场景中为用户提供定制化的居住金融服务。贝壳金服以独家大数据与场景风控能力见长，致力于解决居住金融需求，以 Fintech 驱动产业升级，让每个家庭都能享受高品质的居住生活。截至 2018 年底，贝壳金服业务已覆盖全国 90 多个城市及地区，为超过 130 万用户提供了金融服务。
二、项目背景 贝壳金服数据中台使用 TiDB 和 TiSpark 平台，基于 Syncer 将业务数据实时从 MySQL 备库抽取到 TiDB 中，并通过 TiSpark 对 TiDB 中的数据进行数据分析处理，供上游业务消费，现已服务于 70 多名数据开发人员。现有集群已经使用 100 多个 Syncer 同步上游 MySQL 数据，目前已经达到 4.7TB 热数据，上百张离线和实时报表。由于机房调整，数据中台也需要同步迁移到新机房，结合 TiDB 的特性，我们探索了一种在线不停机迁移机房的方式。
TiDB 是一个分布式 NewSQL 数据库。它支持水平弹性扩展、ACID 事务、MySQL 语法，具有数据强一致的高可用特性，是一个不仅适合 OLTP 场景还适合 OLAP 场景的混合数据库。而 TiSpark 是为解决较重的 OLAP 需求而推出的产品。它借助 Spark 平台，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP 的业务需求。TiSpark 依赖于 TiKV 集群和 PD 组件，使用同一个数据源，减少对于 ETL 工具的维护，并且可以使用 Spark 进行复杂查询计算。</description>
    </item>
    
    <item>
      <title>美团点评携手 PingCAP 开启新一代数据库深度实践之旅</title>
      <link>https://pingcap.com/cases-cn/user-case-meituandianping/</link>
      <pubDate>Thu, 15 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-meituandianping/</guid>
      <description>作者介绍：赵应钢，美团点评研究员；李坤，美团点评数据库专家；朴昌俊，美团点评数据库专家。
 一、背景和现状 在美团，基于 MySQL 构建的传统关系型数据库服务已经难于支撑公司业务的爆发式增长，促使我们去探索更合理的数据存储方案和实践新的运维方式。随着近一两年来分布式数据库大放异彩，美团 DBA 团队联合架构存储团队，于 2018 年初启动了分布式数据库项目。
图 1 美团点评产品展示图
立项之初，我们进行了大量解决方案的对比，深入了解了业界多种 scale-out、scale-up 方案，考虑到技术架构的前瞻性、发展潜力、社区活跃度、以及服务本身与 MySQL 的兼容性，最终敲定了基于 TiDB 数据库进行二次开发的整体方案，并与 PingCAP 官方和开源社区进行深入合作的开发模式。
美团业务线众多，我们根据业务特点及重要程度逐步推进上线，到截稿为止，已经上线 10 个集群，近 200 个物理节点，大部分是 OLTP 类型的应用，除了上线初期遇到了一些小问题，目前均已稳定运行。初期上线的集群，已经分别服务于配送、出行、闪付、酒旅等业务。
TiDB 架构分层清晰，服务平稳流畅，但在美团当前的数据量规模和已有稳定的存储体系的基础上，推广新的存储服务体系，需要对周边工具和系统进行一系列改造和适配，从初期探索到整合落地需要走很远的路。下面从几个方面分别介绍：
 一是从 0 到 1 的突破，重点考虑做哪些事情； 二是如何规划实施不同业务场景的接入和已有业务的迁移； 三是上线后遇到的一些典型问题介绍； 四是后续规划和对未来的展望。  二、前期调研测试 2.1 对 TiDB 的定位 我们对于 TiDB 的定位，前期在于重点解决 MySQL 的单机性能和容量无法线性和灵活扩展的问题，与 MySQL 形成互补。业界分布式方案很多，我们为何选择了 TiDB 呢？考虑到公司业务规模的快速增长，以及公司内关系数据库以 MySQL 为主的现状，因此我们在调研阶段，对以下技术特性进行了重点考虑：
 协议兼容 MySQL：这个是必要项。 可在线扩展：数据通常要有分片，分片要支持分裂和自动迁移，并且迁移过程要尽量对业务无感知。 强一致的分布式事务：事务可以跨分片、跨节点执行，并且强一致。 支持二级索引：为兼容 MySQL 的业务，这个是必须的。 性能：MySQL 的业务特性，高并发的 OLTP 性能必须满足。 跨机房服务：需要保证任何一个机房宕机，服务能自动切换。 跨机房双写：支持跨机房双写是数据库领域一大难题，是我们对分布式数据库的一个重要期待，也是美团下一阶段重要的需求。  业界的一些传统方案虽然支持分片，但无法自动分裂、迁移，不支持分布式事务，还有一些在传统 MySQL 上开发一致性协议的方案，但它无法实现线性扩展，最终我们选择了与我们的需求最为接近的 TiDB。与 MySQL 语法和特性高度兼容，具有灵活的在线扩容缩容特性，支持 ACID 的强一致性事务，可以跨机房部署实现跨机房容灾，支持多节点写入，对业务又能像单机 MySQL 一样使用。</description>
    </item>
    
    <item>
      <title>TiDB 在威锐达 WindRDS 远程诊断及运维中心的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-weiruida/</link>
      <pubDate>Wed, 16 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-weiruida/</guid>
      <description>作者介绍：郭凯乐，应用软件工程师，从公司成立入职工作至今共 6 年半时间，起初主要负责公司的应用系统的服务器端程序的设计开发，对于公司的核心业务及系统架构非常熟悉。2015 年到 2016 年，主持开发了基于规则的智能诊断系统（专家系统）,该系统的开发，使自身对于专家系统有了深刻的了解和认识，并积累了丰富的经验，成为该领域的资深工程师。2016 年第至今，参与公司大数据平台项目的研发，该项目主要是围绕着大数据、工业物联网及分布式系统进行一些方法、中间件及解决方案的一些研究，而作者本身参与该项目关于数据的接入及治理方法及方案的研究工作，过程中对于数据接入融合及数据治理所面临的问题、痛点深有体会，积累了丰富经验及心得。
 公司简介 西安锐益达风电技术有限公司成立于 2012 年 1 月 4 日，是一家专业化的工业测量仪器系统、机电产品和计算机软件研发、设计和制造公司，是北京威锐达测控系统有限公司在西安成立的全资子公司。依托大学的科研实力，矢志不渝地从事仪器仪表及测量系统的研究和应用开发，积累了丰富的专业知识和实践经验，具备自主开发高端仪器系统和工程实施的完整技术能力。
为了适应我国大型风电运营商设备维护管理的需求，破解风电监测技术难题，经过多年艰苦研发，研制了一种具有完全自主知识产权的网络化、模块化、集成化的风电机组状态监测与故障诊断系统，为风电机组全生命周期的运行维护管理提供一套完整的解决方案。
业务描述 威锐达 WindRDS 远程诊断与运维中心，是以设备健康监测为核心，实现企业设备全生命周期的健康监测和基于状态的预知性设备运营维护的管理平台。
本平台以多维、丰富的数据为基础，结合传统的诊断分析方法，并充分发挥利用大数据智能化的技术手段，快速及时的发现、分析定位设备运转及企业运维过程中的问题，并以流程化、自动化的软件系统辅助用户高效的跟踪、处理问题，目标提升企业设备运维管理的能力，节约运维成本，为企业创造价值。
图 1：WindRDS 系统交互图
痛点、选型指标 痛点  WindRDS 的数据平台，对于数据的存储当前选用流行的 MySQL 数据库，面对每年 T 级的数据增长量，以及随着数据量的快速增长导致访问性能的急剧下降，目前也只是通过传统的分表、分库等解决方案进行优化，但性能提升未达到预期，且后续维护升级复杂麻烦，不能很好的满足存储和性能弹性水平扩展的需求。
 本项目同时具有 OLTP 和 OLAP 应用需求，也曾设计构建混合型的数据存储方案（MySQL+ HDFS + Hive + Kylin + HBase + Spark），功能上可同时满足 OLTP 和 OLAP 应用需求，但问题也很明显，如：
 要满足一定程度的实时在线分析，还需要做一些数据迁移同步工作，需要开发实时同步 ETL 中间件，实时从存储事务数据的关系数据库向存储面向分析的 Hive、HBase 数据库同步数据，实时性及可靠性不能保证；
 对于基于 SQL 数据访问的应用程序的切换到该数据平台构成很大挑战，应用程序的数据访问层都需要进行修改适配，工作量大，切换成本高；
 对于面向大数据的的分布式数据库产品（Hive、HBase 等）投入成本高且维护复杂，容易出错，可维护性差。
   选型指标  支持容量及性能的水平弹性扩缩；</description>
    </item>
    
    <item>
      <title>TiDB 在 Ping&#43;&#43; 金融聚合支付业务中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</link>
      <pubDate>Mon, 26 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ping&#43;&#43;/</guid>
      <description>作者：宋涛，Ping++ DBA
 Ping++ 介绍 Ping++ 是国内领先的支付解决方案 SaaS 服务商。自 2014 年正式推出聚合支付产品，Ping++ 便凭借“7 行代码接入支付”的极致产品体验获得了广大企业客户的认可。
如今，Ping++ 在持续拓展泛支付领域的服务范围，旗下拥有聚合支付、账户系统、商户系统三大核心产品，已累计为近 25000 家企业客户解决支付难题，遍布零售、电商、企业服务、O2O、游戏、直播、教育、旅游、交通、金融、房产等等 70 多个细分领域。
Ping++ 连续两年入选毕马威中国领先金融科技 50 强，并于 2017 成功上榜 CB Insights 全球 Fintech 250 强。从支付接入、交易处理、业务分析到业务运营，Ping++ 以定制化全流程的解决方案来帮助企业应对在商业变现环节可能面临的诸多问题。
TiDB 在 Ping++ 的应用场景 - 数据仓库整合优化 Ping++ 数据支撑系统主要由流计算类、报表统计类、日志类、数据挖掘类组成。其中报表统计类对应的数据仓库系统，承载着数亿交易数据的实时汇总、分析统计、流水下载等重要业务:
随着业务和需求的扩展，数仓系统历经了多次发展迭代过程：
 由于业务需求中关联维度大部分是灵活多变的，所以起初直接沿用了关系型数据库 RDS 作为数据支撑，数据由自研的数据订阅平台从 OLTP 系统订阅而来。
 随着业务扩大，过大的单表已不足以支撑复杂的查询场景，因此引入了两个方案同时提供数据服务：ADS，阿里云的 OLAP 解决方案，用来解决复杂关系型多维分析场景。ES，用分布式解决海量数据的搜索场景。
 以上两个方案基本满足业务需求，但是都仍存在一些问题：
 ADS：一是数据服务稳定性，阿里云官方会不定期进行版本升级，升级过程会导致数据数小时滞后，实时业务根本无法保证。二是扩容成本，ADS 为按计算核数付费，如果扩容就必须购买对应的核数，成本不是那么灵活可控。
 ES：单业务搜索能力较强，但是不适合对复杂多变的场景查询。且研发运维代价相对较高，没有关系型数据库兼容各类新业务的优势。
   所以需要做出进一步的迭代整合，我们属于金融数据类业务，重要性安全性不能忽视、性能也得要有保障，经过我们漫长的调研过程，最终，由 PingCAP 研发的 TiDB 数据库成为我们的目标选型。
TiDB 具备的以下核心特征是我们选择其作为实时数仓的主要原因：</description>
    </item>
    
    <item>
      <title>TiDB 在游族网络平台部的深度应用</title>
      <link>https://pingcap.com/cases-cn/user-case-youzu/</link>
      <pubDate>Thu, 08 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-youzu/</guid>
      <description>公司介绍 游族网络股份有限公司（SZ.002174）成立于 2009 年，是全球领先的互动娱乐供应商。公司以“大数据”、“全球化”、“精品化”为战略方向，立足全球化游戏研发与发行，知名 IP 管理，大数据与智能化，泛娱乐产业投资四大业务板块全面发展。
背景 2017 年初的时候，游族的用户中心体系面临迭代和重构，当时数据库有数亿多的核心数据，通过 hash key 分为了 1024 张表在 64 个数据库中来存储，使用自研的代码框架来进行对应 hash key 的 seek 操作。这时，非 hash key 的查询、DDL 变更等业务需求，分表分库逻辑代码框架的局限，让研发和运维都面临较高的数据库使用成本，数据库不能灵活高效的支撑业务需求。
图 1：分库分表方案架构图
为了解决上述问题，游族的技术团队急需一套同时满足如下的条件的数据库分布式集群：
 能够提供实时的 OLTP 的一致性数据存储服务；
 弹性的分布式架构；
 配套的监控备份方案；
 稳定的高可用性；
 较低的迁移重构成本。
  前期选择 最开始先考察了几个方案，但都有相对来说的不足：
 方案一，将整个分表分库逻辑剥离到开源分表分库中间件上：
 基于 2PC 的 XA 弱事务的一致性保证不尽如人意；
 高可用架构更加复杂，单分片的局部不可用会对全局产生影响；
 备份恢复的复杂度高；
 这些方案引入了新的 sharding key 和 join key 的设计问题，整体的迁移难度不降反升。
  方案二，官方的 MySQL cluster 集群：</description>
    </item>
    
    <item>
      <title>TiDB 在爱奇艺的应用及实践</title>
      <link>https://pingcap.com/cases-cn/user-case-iqiyi/</link>
      <pubDate>Tue, 18 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-iqiyi/</guid>
      <description>作者：朱博帅，爱奇艺资深数据库架构师
 背景介绍 爱奇艺，中国高品质视频娱乐服务提供者，2010 年 4 月 22 日正式上线，推崇品质、青春、时尚的品牌内涵如今已深入人心，网罗了全球广大的年轻用户群体，积极推动产品、技术、内容、营销等全方位创新。企业愿景为做一家以科技创新为驱动的伟大娱乐公司。我们在前沿技术领域也保持一定的关注度。
随着公司业务的快速发展，原来普遍使用的 MySQL 集群遇到了很多瓶颈，比如单机 MySQL 实例支撑的数据量有限，只能通过不停删除较旧的数据来维持数据库的运转。同时单表的数据行数不断增大导致查询速度变慢。急需一种可扩展、高可用同时又兼容 MySQL 访问方式的数据库来支撑业务的高速发展。
我司从 2017 年年中开始调研 TiDB，并且在数据库云部门内部系统中使用了 TiDB 集群。从今年 TiDB 推出 2.0 之后，TiDB 愈发成熟，稳定性与查询效率都有很大提升。今年陆续接入了边控中心、视频转码、用户登录信息等几个业务，这几个业务背景和接入方式如下详述。
项目介绍 1. 边控中心 边控中心存储的是机器的安全统计信息，包括根据 DC、IP、PORT 等不同维度统计的流量信息。上层业务会不定期做统计查询，其业务页面如下：
图 1 边控中心上层业务页面（一）
图 2 边控中心上层业务页面（二）
在选型过程中，也考虑过时序型数据库 Apache Druid（http://druid.io），但是 Druid 聚合查询不够灵活，最终放弃 Druid 选择了 TiDB 数据库。TiDB 几乎完全兼容 MySQL 的访问协议，可以使用现有的 MySQL 连接池组件访问 TiDB，业务迁移成本低，开发效率高。
边控中心是爱奇艺第一个在线业务使用 TiDB 的项目，所以我们制定了详细的上线计划。
 第一，部署单独的 TiDB 集群。然后，为了数据安全，部署了 TokuDB 集群，用作 TiDB 集群的备份数据库。
 第二，我们通过 TiDB-Binlog 将 TiDB 集群的数据变更实时同步到 TokuDB 集群中，作为 TiDB 的灾备方案。</description>
    </item>
    
    <item>
      <title>TiDB 帮助万达网络科技集团实现高性能高质量的实时风控平台</title>
      <link>https://pingcap.com/cases-cn/user-case-wanda/</link>
      <pubDate>Tue, 05 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-wanda/</guid>
      <description>作者：陈新江，万达网络科技集团大数据中心
 万达网络科技集团 是中国唯一的实业+互联网大型开放型平台公司，拥有飞凡信息、快钱支付、征信、网络信贷、大数据等公司，运用大数据、云计算、人工智能、场景应用等技术为实体产业实现数字化升级，为消费者提供生活圈的全新消费服务。
万达网络科技集团的技术团队，建设和维护着一套实时风控平台。这套实时风控平台，承担着各种关键交易的在线风控数据的写入和查询服务。实时风控平台后端的数据库系统在高性能，可靠性，可扩展性上有很高的要求，并且需要满足如下核心功能和业务要求：
 风控相关业务数据实时入库
 实时风控规则计算
 通过 BI 工具分析风控历史数据
 ETL 入库到 Hadoop 数据仓库
 应用开发侧需要兼容 MySQL，降低应用改造门槛
  为实现上述业务目标，万达网络科技集团的技术团队在实时风控数据库选型的早期阶段，首先选择了 MySQL Galera Cluster 作为数据库集群的技术架构。这套 MySQL 数据库架构通过不同于 MySQL 主流复制技术的复制机制，实现在多个 MySQL 节点间建立强同步关系，实现数据的副本和高可用。但经过业务实践，发现这套方案有诸多问题，其中比较突出的有以下几点：
 MySQL Galera Cluster 自身的强同步机制以大幅度降低集群整体性能为代价，集群整体性能比单节点 MySQL 还差。所以不能很好的满足“风控相关业务数据实时入库”的业务需求。
 同时，MySQL Galera Cluster 的 JOIN 支持非常弱，不足以支持 BI 相关的复杂分析。
 集群整体性能的短板加上对 JOIN 支持的薄弱，使得要在业务上实现大并发高性能的风控规则计算变的很困难。
  万达的技术团队还考察了市场上用的比较多的 MySQL 主从复制以及通过 MySQL Proxy 中间件实现分库分表的方案。但这些方案，无论是高可用安全性，强一致性，还是对业务应用所需要的复杂事务／JOIN 操作以及横向扩展能力上，都无法满足实时风控平台的业务要求。这些问题集中反映在以下几个方面：
 基于 MySQL 主从复制方式的高可用方案，容易出现诸如接入层脑裂和数据不一致的风险。
 基于 MySQL Proxy 中间件的方案，缺少对分库分表后的跨库跨表的分布式事务支持以及对复杂 JOIN 的良好支持，因此也无法满足业务上风控规则实时计算和复杂查询的需求以及对业务团队的 BI 需求的支持。</description>
    </item>
    
    <item>
      <title>盖娅互娱 | 日均数据量千万级，MySQL、TiDB 两种存储方案的落地对比</title>
      <link>https://pingcap.com/cases-cn/user-case-gaea-ad/</link>
      <pubDate>Thu, 09 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-gaea-ad/</guid>
      <description>作者简介：刘玄，盖娅互娱数据平台高级开发工程师，主要负责实时数据业务和数据流方向。毕业于湖南大学软件工程系，曾任百度高级运维工程师，负责大搜建库运维。
 背景介绍 盖娅广告匹配系统（GaeaAD）用于支撑盖娅互娱全平台实时广告投放系统，需要将广告数据和游戏 SDK 上报的信息进行近实时匹配，本质上来说需要实时的根据各个渠道的广告投放与相应渠道带来的游戏玩家数据进行计算，实现广告转化效果分钟级别的展现及优化。
初期的 MySQL 存储方案 在系统设计之初，基于对数据量的预估以及简化实现方案考虑，我们选用了高可用的 MySQL RDS 存储方案，当时的匹配逻辑主要通过 SQL 语句来实现，包含了很多联表查询和聚合操作。当数据量在千万级别左右，系统运行良好，基本响应还在一分钟内。
图 1 MySQL RDS 存储方案架构图
遭遇瓶颈，寻找解决方案 然而随着业务的发展，越来越多游戏的接入，盖娅广告系统系统接收数据很快突破千万/日，高峰期每次参与匹配的数据量更是需要翻几个番，数据库成为了业务的瓶颈。由于此时，整个技术架构出现了一些问题：
1. 单次匹配耗时已从原本的 10 秒左右增加到 2 分钟以上，最慢的聚合查询甚至达到 20 分钟，时效性受到严重挑战。而且 MySQL 的问题是查询的时间随着数据量的增长而增长，以至于数据量越大的情况下查询越慢。
2. 随着历史数据的积累，单表数据很快达到亿级别，此时单表的读写压力已经接近极限。
3. 由于第一点提到的查询性能问题以及单机的容量限制，需要定时删除数据，对于一些时间跨度较长的业务查询需求没法满足。
根据数据量的增长情况来看，分布式数据库会是很好的解决方案。首先考虑的是业务的垂直及水平拆分或者基于 MySQL 的数据库中间件方案和一些主流的 NoSQL 方案。
但是仔细评估后，最先排除掉的是业务水平拆分的方案，因为业务逻辑中包含大量的关联查询和子查询，如果拆表后这些查询逻辑就没有办法透明的兼容，而且是比较核心的业务系统，时间精力的关系也不允许整体做大的重构。中间件的问题和分库分表的问题类似，虽然解决了大容量存储和实时写入的问题，但是查询的灵活度受限，而且多个 MySQL 实例的维护成本也需要考虑。
第二个方案就是采用 NoSQL，因为此系统需要接收业务端并发的实时写入和实时查询，所以使用类似 Greenplum，Hive 或者 SparkSQL 这样的系统不太合适，因为这几个系统并不是针对实时写入设计的， MongoDB 的问题是文档型的查询访问接口对业务的修改太大，而且 MongoDB 是否能满足在这么大数据量下高效的聚合分析可能是一个问题。
所以很明显，我们当时的诉求就是能有一款数据库既能像 MySQL 一样便于使用，最好能让业务几乎不用做任何修改，又能满足分布式的存储需求，还要保证很高的复杂查询性能。
当时调研了一下社区的分布式数据库解决方案，找到了 TiDB 这个项目，因为协议层兼容 MySQL，而且对于复杂查询的支持不错，业务代码完全不用修改直接就能使用，使迁移使用成本降到极低。
技术转身，使用 TiDB 在部署测试的过程中，我们使用 TiDB 提供的 Syncer 工具将 TiDB 作为 MySQL Slave 接在原业务的 MySQL 主库后边观察，确保读写的兼容性以及稳定性，经过一段时间观察后，确认读写没有任何问题，业务层的读请求切换至 TiDB，随后把写的流量也切换至 TiDB 集群，完成平滑的上线。</description>
    </item>
    
    <item>
      <title>TiDB 在摩拜单车的深度实践及应用</title>
      <link>https://pingcap.com/cases-cn/user-case-mobike-2/</link>
      <pubDate>Mon, 18 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobike-2/</guid>
      <description>作者介绍：吕磊，摩拜单车高级 DBA。
 一、业务场景 摩拜单车 2017 年开始将 TiDB 尝试应用到实际业务当中，根据业务的不断发展，TiDB 版本快速迭代，我们将 TiDB 在摩拜单车的使用场景逐渐分为了三个等级：
 P0 级核心业务：线上核心业务，必须单业务单集群，不允许多个业务共享集群性能，跨 AZ 部署，具有异地灾备能力。 P1 级在线业务：线上业务，在不影响主流程的前提下，可以允许多个业务共享一套 TiDB 集群。 离线业务集群：非线上业务，对实时性要求不高，可以忍受分钟级别的数据延迟。  本文会选择三个场景，给大家简单介绍一下 TiDB 在摩拜单车的使用姿势、遇到的问题以及解决方案。
二、订单集群（P0 级业务） 订单业务是公司的 P0 级核心业务，以前的 Sharding 方案已经无法继续支撑摩拜快速增长的订单量，单库容量上限、数据分布不均等问题愈发明显，尤其是订单合库，单表已经是百亿级别，TiDB 作为 Sharding 方案的一个替代方案，不仅完美解决了上面的问题，还能为业务提供多维度的查询。
2.1 订单 TiDB 集群的两地三中心部署架构 图 1 两地三中心部署架构图
整个集群部署在三个机房，同城 A、同城 B、异地 C。由于异地机房的网络延迟较高，设计原则是尽量使 PD Leader 和 TiKV Region Leader 选在同城机房（Raft 协议只有 Leader 节点对外提供服务），我们的解决方案如下：
 PD 通过 Leader priority 将三个 PD server 优先级分别设置为 5 5 3。 将跨机房的 TiKV 实例通过 label 划分 AZ，保证 Region 的三副本不会落在同一个 AZ 内。 通过 label-property reject-leader 限制异地机房的 Region Leader，保证绝大部分情况下 Region 的 Leader 节点会选在同城机房 A、B。  2.</description>
    </item>
    
    <item>
      <title>TiDB 分布式数据库在转转公司的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</link>
      <pubDate>Tue, 29 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-zhuanzhuan/</guid>
      <description>作者：孙玄，转转公司首席架构师；陈东，转转公司资深工程师；冀浩东，转转公司资深 DBA。
 公司及业务架构介绍 转转二手交易网 —— 把家里不用的东西卖了变成钱，一个帮你赚钱的网站。由腾讯与 58 集团共同投资。为海量用户提供一个有担保、便捷的二手交易平台。转转是 2015 年 11 月 12 日正式推出的 APP，遵循“用户第一”的核心价值观，以“让资源重新配置，让人与人更信任”为企业愿景，提倡真实个人交易。
转转二手交易涵盖手机、3C 数码、母婴用品等三十余个品类。在系统设计上，转转整体架构采用微服务架构，首先按照业务领域模型垂直拆分成用户、商品、交易、搜索、推荐微服务。对每一个功能单元（商品等），继续进行水平拆分，分为商品网关层、商品业务逻辑层、商品数据访问层、商品 DB / Cache，如下图所示： 项目背景 1. 面临的问题 转转后端业务现阶段主要使用 MySQL 数据库存储数据，还有少部分业务使用 MongoDB。虽然目前情况下使用这两种存储基本可以满足我们的需求，但随着业务的增长，公司的数据规模逐渐变大，为了应对大数据量下业务服务访问的性能问题，MySQL 数据库常用的分库、分表方案会随着 MySQL Sharding（分片）的增多，业务访问数据库逻辑会越来越复杂。而且对于某些有多维度查询需求的表，我们总需要引入额外的存储或牺牲性能来满足我们的查询需求，这样会使业务逻辑越来越重，不利于产品的快速迭代。
从数据库运维角度讲，大数据量的情况下，MySQL 数据库在每次 DDL 都会对运维人员造成很大的工作量，当节点故障后，由于数据量较大，恢复时间较长。但这种 M - S 架构只能通过主从切换并且需要额外的高可用组件来保障高可用，同时在切换过程由于需要确定主库状态、新主库选举、新路由下发等原因，还是会存在短暂的业务访问中断的情况。 综上所述，我们面临的主要问题可归纳为：
 数据量大，如何快速水平扩展存储；
 大数据量下，如何快速 DDL；
 分库分表造成业务逻辑非常复杂；
 常规 MySQL 主从故障转移会导致业务访问短暂不可用。
  2. 为什么选择 TiDB 针对上章提到的问题，转转基础架构部和 DBA 团队考虑转转业务数据增速，定位简化业务团队数据库使用方案，更好的助力业务发展，决定启动新型存储服务（NewSQL）的选型调研工作。 TiDB 数据库，结合了关系库与 KV 存储的优点，对于使用方，完全可以当做 MySQL 来用，而且不用考虑数据量大了后的分库分表以及为了支持分库分表后的多维度查询而建立的 Mapping 表，可以把精力全部放在业务需求上。所以我们把 TiDB 作为选型的首选对象展开了测试和试用。</description>
    </item>
    
    <item>
      <title>TiDB 在株式会社 FUNYOURS JAPAN 的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-funyours-japan/</link>
      <pubDate>Fri, 23 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-funyours-japan/</guid>
      <description>作者：张明塘，FUNYOURS JAPAN 运营系统工程師
 背景 株式会社 FUNYOURS JAPAN 自 2014 在日本成立以来，营运多款颇受好评的页游跟手游，如：剣戟のソティラス、九十九姬 等，对于营运游戏来说，能够了解游戏中的玩家在做什么，喜欢的偏好是什么，关卡的设计是否平衡，都是相当重要的，所以随着营运时间的增长，资料库数据在亿笔以上也是寻常的。
所以我们的技术单位也一直不断在评估市面上的各种资料库以及如何改进目前现有系统与架构，近年来最热门的资料库系统可以说是 NoSQL 了，不论 MongoDB，Cassandra，Redis，HBase 等等都占有一片天，具有读写快速，容易扩展等特性。经过初步了解后，采用 NoSQL 方式，需要对于目前的资料储存架构整个重新设计，并且需要配合采用的该套 NoSQL 资料库进行业务改造设计，那么该采用哪一套 NoSQL 资料库又是一个需要慎重考虑的课题。先回过头来看当前最需要处理改进的项目：
1. 储存空间扩展不易
2. 单台资料库效能有限
初期方案 在处理储存空间不足的部分，一开始我们先采用了 MySQL innoDB 提供的压缩表格格式，对于需要时常读写更新的部分使用了 8K page size，过往的日志部分采用 4K page size，效果非常令人满意，释放了大量的储存空间，并且对于效能来说没有造成可察觉的影响。这部分网路上的测试比较多，就不在此多做说明。但是很快的压缩表格节省的空间毕竟是有限的，接下来只能增加 volume 容量以及将没有需要更新的过往日志移动到其他资料库上，虽然造成维护工作跟时间的繁复与负担，但是问题解决了。
基于 MySQL 资料库架构单台的性能限制上，我们采用了多组的资料库伺服器，来满足所需的效能。当然不同组之间资料是不共通的，也就是无法直接使用 SQL 来做跨组间的操作，需要额外的程式来作业。而当然为了大量的资料存取上的效能，分表分库对表格进行 partition 这些作业都少不了。
初识 TiDB 使用 NoSQL 式资料库看似可以完美的提供出一个解法，但需要付出的成本也是高昂的。于是我们把眼光落到了 MySQL Cluster 上，这时看到了 Google 发布 Cloud Spanner beta 的新闻，NewSQL？这是什么? 很快的引起了我们浓厚的兴趣，然后经过多方调研，我们发现了 TiDB：一个开源在 GitHub 上的 NewSQL 资料库。官方也持续不断发布了很多相关的文章，随着对 TiDB 的认识，认为对于目前现况是很合适的最佳化方案，相容于 MySQL，高可用性，容易水平扩展。</description>
    </item>
    
    <item>
      <title>TiDB 在 360 金融贷款实时风控场景应用</title>
      <link>https://pingcap.com/cases-cn/user-case-360/</link>
      <pubDate>Mon, 27 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-360/</guid>
      <description>作者：金中浩，360 金融 / 数据智能部 / 部门总监
 背景 近几年来基于互联网渠道的现金贷业务发展十分迅猛，无论是新兴的互联网企业还是传统的金融机构，都想在这个领域快速占领市场，攫取客户。然而在线贷款业务与其他互联网业务有着明显的不同，源自金融的基因决定了重视风险的必要性，这不仅关系到产品的收益，也直接影响了产品是否可以成功。
将业务推到线上意味着无法准确的获取客户信息，只能通过有限的渠道验证客户的真实性和偿还能力，极大的增加了风险成本。如果申请步骤过于繁琐则降低了用户体验，不利于产品的推广和客户的使用。因此对于互联网贷款风控的一项挑战就是能够在尽可能短的时间内，有限数据的情况下，给出明确的风险判断。
应用 建立风险策略的过程中，使用各种风险变量以及相关的衍生变量，通过专家模型进行评分，是一种较为典型的方法。实际应用中，我们发现除了已经被广泛使用的消费行为数据，基本收入数据等，基于特定维度的用户间社交关系也是比较有效的模型变量。
在使用这些变量的过程中，我们面临最直接的问题是数据量。如果考虑将用户手机通讯录中出现的电话号码作为一项关系关联的形式，假设每位用户通讯录中联系人的个数平均为 100 个，那 100 万个注册用户就有对应大约 1 亿个联系人。事实上，在系统上线大约 1 年不到的时间内，我们几张存储社交关系的表已经达到了大约 50 亿左右的规模。
相对于数据存储，变量的衍生加工和查询匹配是个更加有挑战性的工作。一个人的社交关系是个很典型的「图」数据结构。而很多专家模型中的规则是需要匹配某个用户 3 层以上关系的，最简单的就是匹配用户通过联系人关系，跃进 3 层后，命中系统黑名单的人数。我们还是按照平均 100 个联系人来估算，跃进 3 层后，需要匹配的关联人数为 100 * 100 * 100，即 100 万。而类似计算量的规则不在少数，需要调用这些计算规则的业务场景也较为频繁，同时对响应时间的要求也高。
V1.0 版本的解决方案 在评估阶段，我们考虑了几种方案，各有利弊。首先被淘汰的是使用 MySQL 的解决方案。使用关系型数据库的优势是在查询方面的便捷性。在开发效率上，SQL 是开发人员和数据分析人员的必备技能，能够较快的在功能上实现需求。但是在数据存储和计算层面，MySQL 的表现则差强人意。在面对大数据量时，MySQL 能采取的水平扩展策略无非是分库分表，这样的后果就是查询逻辑变的非常复杂，不易维护，且性能下降的较为严重。
另一个方案是把 HBase 作为数据存储的解决方案。它的优点很明显，可以水平扩展，数据量不再是瓶颈。但是它的缺点也同样明显，即对开发人员不友好，查询的 API 功能性较差，只能通过 key 来获取单条数据，或是通过 scan API 来批量读取。更关键的是 HBase 对图这样的数据结构支持的不好，只能通过使用 tall table 和存储冗余数据的形式来模拟。
第三个方案是使用纯粹的图数据库。首先我们考察了开源的 Titan，发现这个项目已经废弃了，主力团队貌似研发了一个新的商业图数据库，并成立了公司。而且 Titan 的存储引擎也是使用了 HBase 和 Cassandra(根据需求两者选一)，性能并不能满足我们的要求。接着我们考察了两款开源的商业产品 Neo4j 和 OrientDB。他们两者都提供了免费的社区版本，当然在功能上比商业版少了些。其中 Neo4j 的社区版不支持 HA，只能在单机上运行。而 OrientDB 的数据版支持 HA 和 Sharding。在编程接口上两者都支持各种主流的编程语言。Neo4j 提供了自家独创的，基于模式匹配的查询语言 cypher。OrientDB 则提供了类 SQL 的语法 API，可谓各有所长。</description>
    </item>
    
    <item>
      <title>TiDB at 丰巢：尝鲜分布式数据库</title>
      <link>https://pingcap.com/cases-cn/user-case-fengchao/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-fengchao/</guid>
      <description>随着丰巢业务系统快速增长，其核心系统的数据量，早就跨越了亿级别，而且每年增量仍然在飞速发展。整个核心系统随着数据量的压力增长，不但系统架构复杂度急剧增长，数据架构更加复杂，传统的单节点数据库，已经日渐不能满足丰巢的需求，当单表数量上亿的时候，Oracle 还能勉强抗住，而 MySQL 到单表千万级别的时候就难以支撑，需要进行分表分库。为此，一款高性能的分布式数据库，日渐成为刚需。
思考 在互联网公司业务量增大之后，并行扩展是最常用、最简单、最实时的手段。例如负载均衡设备拆流量，让海量流量变成每个机器可以承受的少量流量，并且通过集群等方式支撑起来整个业务。于是当数据库扛不住的时候也进行拆分。
但有状态数据和无状态数据不同，当数据进行拆分的时候，会发生数据分区，而整个系统又要高可用状态下进行，于是数据的一致性变成了牺牲品，大量的核对工具在系统之间跑着保证着最终的一致性。在业务上，可能业务同学经常会遇到分过库的同学说，这个需求做不了，那个需求做不了，如果有 sql 经验的业务同学可能会有疑问不就是一条 sql 的事情么，其实这就是分库分表后遗症。
为此，我们需要有个数据库帮我们解决以上问题，它的特性应该是：
 数据强一致：支持完整的 ACID；
 不分表分库：无论多少数据我们只管插入不需要关心啥时候扩容，会不会有瓶颈；
 数据高可用：当我们某台数据库的少部分机器磁盘或者其他挂了的时候，我们业务上可以无感知，甚至某个城市机房发生灾难的时候还可以持续提供服务，数据不丢失；
 复杂 SQL 功能：基本上单库的 SQL，都可以在这个数据库上运行，不需要修改或者些许修改；
 高性能：在满足高 QPS 的同时，保证比较低的延时。
  选型 根据以上期望进行分析，我们分析了目前市面上存在的 NewSQL 分布式数据库，列表如下：
在综合考虑了开源协议，成熟度，可控度，性能，服务支撑等综合因素之后，我们选择了 TiDB，它主要优势如下：
 高度兼容 MySQL  大多数情况下，无需修改代码即可从 MySQL 轻松迁移至 TiDB，分库分表后的 MySQL 集群亦可通过 TiDB 工具进行实时迁移。  水平弹性扩展  通过简单地增加新节点即可实现 TiDB 的水平扩展，按需扩展吞吐或存储，轻松松应对高并发、海量数据场景。
 分布式事务   TiDB 100% 支持标准的 ACID 事务。
 金融级别的高可用性  相比于传统主从（M-S）复制方案，基于 Raft 的多数派选举协议可以提供金融级的 100% 数据强一致性保证，且在不丢失大多数副本的前提下，可以实现故障的自动恢复（auto-failover），无需人工介入。</description>
    </item>
    
    <item>
      <title>TiDB 助力东南亚领先电商 Shopee 业务升级</title>
      <link>https://pingcap.com/cases-cn/user-case-shopee/</link>
      <pubDate>Tue, 25 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-shopee/</guid>
      <description>作者介绍：刘春辉，Shopee DBA；洪超，Shopee DBA。
 一、业务场景 Shopee 是东南亚和台湾地区领先的电子商务平台，覆盖新加坡、马来西亚、菲律宾、印度尼西亚、泰国、越南和台湾等七个市场。Shopee 母公司 Sea 为首家在纽约证券交易所上市的东南亚互联网企业。2015 年底上线以来，Shopee 业务规模迅速扩张，逐步成长为区域内发展最为迅猛的电商平台之一：
 截止 2018 年第三季度 Shopee APP 总下载量达到 1.95 亿次，平台卖家数量超过 700 万。
 2018 年第一季度和第二季度 GMV 分别为 19 亿美金和 22 亿美金，2018 上半年的 GMV 已达到 2017 全年水平。2018 年第三季度 GMV 达到了创纪录的 27 亿美元, 较 2017 年同期年增长率为 153%。
 2018 年双 11 促销日，Shopee 单日订单超过 1100 万，是 2017 年双 11 的 4.5 倍；刚刚过去的双 12 促销日再创新高，实现单日 1200 万订单。
  图 1 Shopee 电商平台展示图</description>
    </item>
    
    <item>
      <title>TiDB / TiSpark 在易果集团实时数仓中的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yiguo/</link>
      <pubDate>Mon, 18 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yiguo/</guid>
      <description>作者简介：罗瑞星，曾就职于前程无忧，参加过 Elasticsearch 官方文档中文翻译工作，现就职于易果集团，担任资深大数据工程师，负责易果集团数据分析架构设计等工作。
 项目背景 目前企业大多数的数据分析场景的解决方案底层都是围绕 Hadoop 大数据生态展开的，常见的如 HDFS + Hive + Spark + Presto + Kylin，在易果集团，我们初期也是采取这种思路，但是随着业务规模的快速增长和需求的不断变化，一些实时或者准实时的需求变得越来越多，这类业务除了有实时的 OLTP 需求，还伴随着一些有一定复杂度的 OLAP 的需求，单纯地使用 Hadoop 已经无法满足需求。
现有的准实时系统运行在 SQL Server 之上，通过开发人员编写和维护相应的存储过程来实现。由于数据量不大，SQL Server 能够满足需求，但是随着业务的发展，数据量随之增长，SQL Server 越来越不能满足需求，当数据量到达一定的阶段，性能便会出现拐点。这个时候，这套方案已完全无法支撑业务，不得不重新设计新的方案。
选型评估 在评估初期，Greenplum、Kudu、TiDB 都进入了我们的视野，对于新的实时系统，我们有主要考虑点：
 首先，系统既要满足 OLAP 还要满足 OLTP 的基本需求；
 其次，新系统要尽量降低业务的使用要求；
 最后，新系统最好能够与现有的 Hadoop 体系相结合。
  Greenplum 是一套基于 PostgreSQL 分析为主的 MPP 引擎，大多用在并发度不高的离线分析场景，但在 OLTP 方面，我们的初步测试发现其对比 TiDB 的性能差很多。
再说说 Kudu。Kudu 是 CDH 2015年发布的一套介于 Hbase 和 HDFS 中间的一套存储系统，目前在国内主要是小米公司应用的较多，在测试中，我们发现其在 OLTP 表现大致与 TiDB 相当，但是一些中等数据量下，其分析性能相比 TiDB 有一定差距。另外我们的查询目前主要以 Presto 为主，Presto 对接 Kudu 和 PostgreSQL 都是需要考虑兼容性的问题，而 TiDB 兼容 MySQL 协议，在应用初期可以直接使用 Presto-MySQL 进行统一查询，下一步再考虑专门开发 Presto-TiDB。</description>
    </item>
    
    <item>
      <title>TiDB 在量化派风控系统中的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-lianghuapai/</link>
      <pubDate>Mon, 10 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-lianghuapai/</guid>
      <description>作者：朱劲松，量化派研发中心系统架构师，主要参与了基础组件开发、API Gateway 等项目，现在致力于公司风控系统相关业务的架构设计和研发。
 一、公司简介 量化派（QuantGroup）创办于 2014 年，是数据驱动的科技公司，是国家高新技术企业。量化派以「MOVE THE WORLD WITH DATA, ENLIGHTEN LIFE WITH AI」（数据驱动世界，智能点亮生活）为愿景，利用人工智能、机器学习、大数据技术。为金融、电商、旅游、出行、汽车供应链等多个领域的合作伙伴提供定制化的策略和模型，帮助提升行业效率。量化派已与国内外超过 300 家机构和公司达成深度合作，致力于打造更加有活力的共赢生态，推动经济的可持续发展。
我司从 2017 年年中开始调研 TiDB，并在用户行为数据分析系统中搭建 TiDB 集群进行数据存储，经过一年多的应用和研究，积累了丰富的经验。同时，TiDB 官方推出 2.0 GA 版本，TiDB 愈发成熟，稳定性和查询效率等方面都有很大提升。我们于 2018 年 7 月部署 TiDB 2.0.5 版本，尝试将其应用于风控业务中。风控系统主要是在用户申请放款时，根据风控规则结合模型和用户特征进行实时计算并返回放款结果。
二、业务背景 风控系统中用到的数据主要可以分为两部分：
 一类是原始数据，用于分析用户当前的特征指标。
 一类是快照数据，用于计算历史指定时间点的特征指标，供模型训练使用。
  原始数据主要分为三种：
 产生自公司内各个产品线的业务系统数据。
 爬虫组提供的用户联系人、运营商、消费记录等数据。
 经过处理后的用户特征数据。
  由于我们的风控策略中用到了大量的模型，包括神经网络模型，评分模型等，这些模型的训练需要依靠大量的历史订单以及相关的用户特征，为了训练出更多精准、优秀的模型，就需要更多维度的特征，此时特征的准确性就直接影响了模型的训练结果，为此我们在回溯每一个订单的用户在指定时间的特征表现时，就需要用到数据快照。
我们可以通过拉链表的方式来实现数据快照功能，简单说就是在每张表中增加三个字段，分别是new_id、start_time、end_time，每一次记录的更新都会产生一条新的数据，同时变更原有记录的end_time，以记录数据的变更历史。
通过上面的介绍可以看到，业务数据和爬虫数据本身数据量就很大，再加上需要产生对应的拉链数据，数据量更是成倍增长。假设每条数据自创建后仅变更一次，那拉链表的数据量就已经是原始表的两倍了，而实际生产环境下数据的变更远不止一次。
通过上述的介绍，我们总结风控系统下的数据存储需求应满足以下几点：
 业务数据。
 业务数据拉链表。
 爬虫数据，如联系人信息、运营商数据，消费记录等。
 爬虫数据拉链表。
 其他数据，如预处理数据等。
  三、当前方案 以前方案主要是采用 HBase 进行数据存储。它的水平扩展很好的解决了数据量大的问题。但是在实际使用中，也存在着比较明显的问题，最明显的就是查询的 API 功能性较弱，只能通过 Key 来获取单条数据，或是通过 Scan API 来批量读取，这无疑在特征回溯时增加了额外的开发成本，无法实现代码复用。</description>
    </item>
    
    <item>
      <title>TiDB 在转转的业务实战</title>
      <link>https://pingcap.com/cases-cn/user-case-zhuanzhuan-2/</link>
      <pubDate>Wed, 16 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-zhuanzhuan-2/</guid>
      <description>作者：陈维，转转优品技术部 RD。
 开篇 世界级的开源分布式数据库 TiDB 自 2016 年 12 月正式发布第一个版本以来，业内诸多公司逐步引入使用，并取得广泛认可。
对于互联网公司，数据存储的重要性不言而喻。在 NewSQL 数据库出现之前，一般采用单机数据库（比如 MySQL）作为存储，随着数据量的增加，“分库分表”是早晚面临的问题，即使有诸如 MyCat、ShardingJDBC 等优秀的中间件，“分库分表”还是给 RD 和 DBA 带来较高的成本；NewSQL 数据库出现后，由于它不仅有 NoSQL 对海量数据的管理存储能力、还支持传统关系数据库的 ACID 和 SQL，所以对业务开发来说，存储问题已经变得更加简单友好，进而可以更专注于业务本身。而 TiDB，正是 NewSQL 的一个杰出代表！
站在业务开发的视角，TiDB 最吸引人的几大特性是：
 支持 MySQL 协议（开发接入成本低）；
 100% 支持事务（数据一致性实现简单、可靠）；
 无限水平拓展（不必考虑分库分表）。
  基于这几大特性，TiDB 在业务开发中是值得推广和实践的，但是，它毕竟不是传统的关系型数据库，以致我们对关系型数据库的一些使用经验和积累，在 TiDB 中是存在差异的，现主要阐述“事务”和“查询”两方面的差异。
TiDB 事务和 MySQL 事务的差异 MySQL 事务和 TiDB 事务对比 在 TiDB 中执行的事务 b，返回影响条数是 1（认为已经修改成功），但是提交后查询，status 却不是事务 b 修改的值，而是事务 a 修改的值。
可见，MySQL 事务和 TiDB 事务存在这样的差异：</description>
    </item>
    
    <item>
      <title>支撑百亿级应用的 NewSQL——TiDB 在同程旅游的应用</title>
      <link>https://pingcap.com/cases-cn/user-case-tongcheng/</link>
      <pubDate>Thu, 12 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-tongcheng/</guid>
      <description>作者：瞿锴，同程网资深 DBA。
 项目背景 初次接触 TiDB，是通过同程网首席架构师王晓波先生的分享，当时同程网正在使开发和数据库全面往开源方向转型，由于业务需要，很多在线业务数据量和访问量都非常的大，而 MySQL 无法满足大数据量下的复杂查询需求，为了使数据库分片对开发透明，同程自研了 DBrouter。但分片后的合并、实时汇总统计及全量数据的监控仍然是困扰我们的一个难点。一直没有特别好的办法解决。
急速增长的业务 2016 年国庆前，同程的票务项目（微信九宫格中的火车票、机票等票务业务背后是同程在提供）由于流量激增，订单库压力越来越大，同时相关业务需求也在增加，开发不断的在订单库上新增各种查询，例如为了及时定位异常而增加的限定各类条件的分钟级订单量监控（每分钟执行根据不同的条件进行汇总的订单量）。这样的功能越来越多，同时订单库总大小数 T 左右。对此，公司内部决定将票务订单库进行分片来降低单库压力，应对即将到来的国庆高峰订单爆发。
引入 TiDB 经过评估，发现公司自研的分片可以满足绝大多数的查询需求，但是部分复杂条件的查询将会影响整个分片集群的性能，少量的全片扫描 SQL 经常会占用 80% 以上的 IO 资源，导致其他的查询性能下降。这时，刚好我们的首席架构师提议，使用 TiDB 试试，经过中间件组和 DBA 组的配合测试，我们尝试将 TiDB 作为所有数据的集合库提供复杂查询，分片集群则提供简单查询，同时由于 TiDB 高度兼容 MySQL 的连接协议，我们基于 PingCAP 提供的数据同步工具 Syncer 进行了二次开发，可以自定义库名和表名（后来同 TiDB 工程师交流，他们最新的 Wormhole &amp;amp; Syncer 也都已经支持了自定义选项），同时新增了同步状态监控，如 TPS、延迟等，如果出现异常，会通过微信告警。从 MySQL 将数据实时同步到 TiDB 来确保数据的一致。
确定方案后，我们连夜安排压测同事和开发同事协作，紧急测试，发现这套分片集群 + TiDB 的方案能够满足我们的功能和性能方面的需求，于是迅速调整了该项目的架构，我们将数千个 MySQL 分片汇总到一个 TiDB 集群，保障了 2016 年国庆的高峰平稳渡过。当时的流量达到了我们平时流量的 2 倍，然而并没有出现异常。
该实时同步查询系统架构如下所示：
在该项目实施成功后，我们加深了对于 TiDB 的使用。并根据 PingCAP 的建议和协助部署了各类监控。
同时，为了更好的关注数据库的情况，第一时间发现异常，我们将 TiDB 的异常报警接入了公司的监控系统和自愈系统。当发生异常的时候，监控系统会第一时间发现，然后自愈系统会依据提前制定的愈合逻辑处理对应异常，在第一时间恢复应用的可用。</description>
    </item>
    
    <item>
      <title>TiDB 在特来电的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-telaidian/</link>
      <pubDate>Fri, 29 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-telaidian/</guid>
      <description>作者介绍：潘博存，特来电大数据技术研发部架构师，具有 10 多年平台软件设计开发经验，现专注于大数据领域快速读写方向。
 背景介绍 特来电新能源有限公司是创业板第一股特锐德（300001）的全资子公司，主要从事新能源汽车充电网的建设、运营及互联网的增值服务。特来电颠覆了传统充电桩的模式，世界首创了电动汽车群智能充电系统，获得 336 项技术专利，以“无桩充电、无电插头、群管群控、模块结构、主动防护、柔性充电”的特点引领世界新能源汽车充电的发展，系统的鉴定结论为：“产品世界首创、技术水平国际领先。主动柔性充电对电池寿命可以延长 30% 左右，电池充电的安全性可以提升 100 倍以上。”
特来电采用互联网思维，依靠国际领先的汽车群智能充电技术和系统，创新电动汽车充电商业模式，建设全国最大的汽车充电网，通过大系统卖电、大平台卖车、大共享租车、大数据修车、大支付金融、大客户电商，打造让客户满意、政府放心的中国最大汽车充电网生态公司，引领充电网、车联网、互联网“三网融合”的新能源互联网。
为什么研究 TiDB 特来电大数据平台通过开源与自研相结合的方式，目前已经上线多套集群满足不同的业务需求。目前在大数据存储和计算方面主要使用了 HBase、Elasticsearch、Druid、Spark、Flink。大数据技术可谓是百花齐放、百家争鸣，不同的技术都有针对性的场景。结合实际情况，选择合适的技术不是一件容易的事情。
随着接入大数据平台的核心业务的增加，我们在 OLAP 上主要遇到以下痛点问题：
 随着基于大数据分析计算的深入应用，使用 SQL 进行分析的需求越来越旺盛，但目前已经上线的大数据集群（HBase、Elasticsearch、Druid、Spark、Flink）对 SQL 的支持度都比较弱。
 目前进入大数据集群的数据主要以宽表方式进行，导致在数据归集和后期基础数据放生变化时应用成本较高。
 数据仓库业务有些还是基于复杂的 T+1 模式的 ETL 过程，延时较高，不能实时的反映业务变化。
 由于每个大数据集群主要针对特定的场景，数据重复存储的情况较多，这就造成了存储成本的增加，同时也会导致数据的不一致性。
 目前进入 HDFS / Druid / ES 的数据，在历史数据更新时，成本较高，灵活性降低。
  大数据技术发展迅速，我们也一直希望采用新的技术可以解决我们以上问题，我们关注到目前 NewSQL 技术已经有落地产品，并且不少企业在使用，所以决定在我们平台内尝试引入 NewSQL 技术解决我们的痛点问题。
我们先了解一下 NewSQL。
图 1 数据库发展史
如图 1 所示，数据库的发展经历了 RDBMS、NoSQL 以及现在的 NewSQL，每种不同的技术都有对应的产品，每种数据库的技术背后，都有典型的理论支撑。2003 年 Google GFS 开创了分布式文件系统、2006 年的 BigTable 论文催生了 Hadoop 生态，在 2012 年的 Spanner 和 2013 年的 F1 论文发表后，被业界认为指明了未来关系型数据库的发展。</description>
    </item>
    
    <item>
      <title>TiDB 在今日头条的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-toutiao/</link>
      <pubDate>Fri, 16 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-toutiao/</guid>
      <description>本文整理自今日头条数据库中间件/分布式数据库负责人吴镝（知乎 ID：吴镝）在 TiDB DevCon2018 上的分享内容。
 TiDB 主要应用在今日头条核心 OLTP 系统 - 对象存储系统中，存储其中一部分元数据，支持头条图片和视频相关业务，比如抖音等。
如今（数据截至发文），TiDB 支撑着今日头条 OLTP 系统里 QPS 比较高的场景：集群容量约几十 T，日常 QPS 峰值会达到几十万。
为什么我们需要用 TiDB 今日头条内部有一些业务数据量非常大，之前用的 MySQL 的单机盘是大概 2.8T 的 SSD 盘。我们做对象存储。因为头条不但做视频，还做图片，这些视频和图片当中基本上都是用我们自研的 S3 存储系统，这种存储系统需要一个元数据，比如一个图片存下来，它存在 S3 系统的哪个机器、哪个文件、哪个偏移里面的数据，还有比如一个大的视频，S3 会把它切成很多小的视频片段，每一个分片的位置，都会存在元数据里面。
用 TiDB 之前，元数据是存在 MySQL 里的一个 2.8TB 的盘，因为增长的特别快，所以导致磁盘不够用，只能用分库分表的方案。我们以前用的的分库分表方案是 MyCAT。但用这个方案的过程中我们有遇到了一些问题，比如丢数据。某一个数据我 commit 了之后，最后发现这个数据丢了。
再就是连接的问题，目前头条做分片是大概固定分 100 个片。如果你的业务是需要分库分表，那你这边搞 101 个分片，这样有些业务，他用了一个分片键，用分片键来做查询，那可能中间件只用一个连接就可以找到相关数据。但有些业务，确实有不带分片键的请求。会导致 select 语句过来的时候，下面会建 101 个对后端的连接，也就是说，因为有连接的限制，有一个没有带分片键的这种请求过来之后， MyCAT 可以启 101 个连接到后面的每一个 MySQL 库。那这样的话，有时候我给它 5 万个连接，他一下子就把一百万用掉了。这样会导致它在非分片键的 select 请求，它连接速度消耗非常快，经常在业务这边会抛出说，连接数不够。
头条的数据库主要用的是 MySQL 和 MongoDB，相对比较单一，所我们也想多尝试一些其他的数据库。</description>
    </item>
    
    <item>
      <title>TiDB 在摩拜单车在线数据业务的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobike/</link>
      <pubDate>Mon, 25 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobike/</guid>
      <description>作者：丁宬杰 / 胡明，Mobike 技术研发部基础平台中心
 背景 摩拜单车于 2015 年 1 月成立，2016 年 4 月 22 日地球日当天正式推出智能共享单车服务，截至 2017 年 11 月中旬，已先后进入国内外超过 180 个城市，运营着超过 700 万辆摩拜单车，为全球超过 2 亿用户提供着智能出行服务，日订单量超过 3000 万，成为全球最大的智能共享单车运营平台和移动物联网平台。摩拜每天产生的骑行数据超过 30TB，在全球拥有最为全面的骑行大数据，飞速增长的业务使摩拜面临数据库扩展与运维的巨大挑战。
面对飞速增长的并发数与数据量，单机数据库终将因无法支撑业务压力而罢工。在摩拜正式上线以来，我们就在不断思考数据库扩展和运维的未来，近年来业内对数据库进行扩展的常见的方案是通过中间件把数据库表进行水平拆分，将表内数据按照规则拆分到多个物理数据库中。使用这样的中间件方案，在数据库扩容时需要先停下业务，再重构代码，之后进行数据迁移，对于摩拜这样与时间赛跑的创业公司来讲代价巨大，中间件方案对业务过强的侵入性，不支持跨分片的分布式事务，无法保证强一致性事务的特性都使我们望而却步。
摩拜单车于 2017 年初开始使用 TiDB，从最早的 RC3、RC4、PreGA、到现在的 1.0 正式版，一步步见证了 TiDB 的成熟和稳定。目前支撑着摩拜内部的实时分析和部分线上业务，同时正在规划迁移更多的线上业务至 TiDB。
目前，TiDB 在摩拜部署了数套集群，近百个节点，承载着数十 TB 的各类数据。
TiDB 在摩拜的角色和主要应用场景 在摩拜，TiDB 是一个核心的数据交易与存储支撑平台，引入它的主要目的是用来解决海量数据的在线存储、大规模实时数据分析和处理。
在我们看来，TiDB 的好处主要有：
 弹性扩容。具有 NoSQL 类似的扩容能力，在数据量和访问流量持续增长的情况下能够通过水平扩容提高系统的业务支撑能力，并且响应延迟稳定； 简单易用。兼容 MySQL 协议，基本上开箱即用，完全不用担心传统分库分表方案带来的心智负担和复杂的维护成本，而且用户界面友好，常规的技术技术人员都可以很高地进行维护和管理； 响应及时。因为和 PingCAP 团队有非常深入的合作关系，所以有任何问题都可以第一时间和 PingCAP 团队直接沟通交流，遇到问题都能很快的处理和解决。  下面介绍 TiDB 的应用场景：
场景一：开关锁日志成功率统计 开关锁成功率是摩拜业务监控的重点指标之一。</description>
    </item>
    
    <item>
      <title>Qunar 高速发展下数据库的创新与发展 - TiDB 篇</title>
      <link>https://pingcap.com/cases-cn/user-case-qunar/</link>
      <pubDate>Thu, 14 Dec 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-qunar/</guid>
      <description>作者：蒲聪，去哪儿平台事业部 DBA，拥有近 6 年的 MySQL 和 HBase 数据库运维管理经验，2014 年 6 月加入去哪儿网，工作期间负责支付平台事业部的 MySQL 和 HBase 整体运维工作，从无到有建立去哪儿网 HBase 运维体系，在 MySQL 和 Hbase 数据库上有丰富的架构、调优和故障处理等经验。目前专注于分布式数据库领域的研究和实践工作。
 目前互联网公司数据存储主要依赖于 MySQL 为代表的关系型数据库，但是随着业务量的增长，使用场景更加多样，传统的关系型数据库不能很好的满足业务需求，主要是在两个维度：一是随着数据量爆炸式增长，性能急剧下降，而且很难在单机内存储；二是一些场景下业务对响应速度要求较高，数据库无法及时返回结果，而传统的 memcached 缓存又存在无法持久化数据，存储容量受限于内存等问题。针对这两个问题，去哪儿的 DBA 团队分别调研了 TiDB 和 InnoDB memcached 以满足业务需求，为用户提供更多的选择方案。
接下来的文章系列，我们将陆续为大家带来 TiDB 和 InnoDB memcached 在去哪儿的调研和实践，本篇文章先介绍 TiDB。
分布式数据库诞生背景 随着互联网的飞速发展，业务量可能在短短的时间内爆发式地增长，对应的数据量可能快速地从几百 GB 涨到几百个 TB，传统的单机数据库提供的服务，在系统的可扩展性、性价比方面已经不再适用。随着业界相关分布式数据库论文的发布，分布式数据库应运而生，可以预见分布式数据库必将成为海量数据处理技术发展的又一个核心。
目前业界最流行的分布式数据库有两类，一个是以 Google Spanner 为代表，一个是以 AWS Auraro 为代表。 Spanner 是 shared nothing 的架构，内部维护了自动分片、分布式事务、弹性扩展能力，数据存储还是需要 sharding，plan 计算也需要涉及多台机器，也就涉及了分布式计算和分布式事务。主要产品代表为 TiDB、CockroachDB、OceanBase 等。 Auraro 主要思想是计算和存储分离架构，使用共享存储技术，这样就提高了容灾和总容量的扩展。但是在协议层，只要是不涉及到存储的部分，本质还是单机实例的 MySQL，不涉及分布式存储和分布式计算，这样就和 MySQL 兼容性非常高。主要产品代表为 PolarDB。</description>
    </item>
    
    <item>
      <title>TiDB 在猿辅导数据快速增长及复杂查询场景下的应用实践</title>
      <link>https://pingcap.com/cases-cn/user-case-yuanfudao/</link>
      <pubDate>Tue, 01 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yuanfudao/</guid>
      <description>猿辅导是国内拥有最多中小学生用户的在线教育机构，旗下有猿题库、小猿搜题、猿辅导三款在线教育 APP，为用户提供在线题库、拍照搜题、名师在线辅导相关的服务。其中，猿辅导 APP 已经有超过 116 万付费用户，提供小学英语、奥数，和初中高中全学科的直播辅导课程，全国任何地区的中小学生，都可以享受在家上北京名师辅导课的服务。
海量的题库、音视频答题资料、用户数据以及日志，对猿辅导后台数据存储和处理能力都提出了严峻的要求。
猿辅导的业务决定了其后台系统具有以下特点：
 数据体量大，增速快，存储系统需要能够灵活的水平扩展；
 有复杂查询，BI 方面的需求，可以根据索引，例如城市、渠道等，进行实时统计；
 数据存储要具备高可用、高可运维性，实现自动故障转移。
  在最初方案选型时，猿辅导初期考虑用单机 MySQL。但根据业务发展速度预估，数据存储容量和并发压力很快就会达到单机数据库的处理瓶颈。如果在 MySQL 上加入分库中间件方案，则一定要指定 sharding key，这样是无法支持跨 shard 的分布式事务。同时 proxy 的方案对业务层的侵入性较强，开发人员必须了解数据库的分区规则，无法做到透明。
除此之外，分库分表很难实现跨 shard 的聚合查询，例如全表的关联查询、子查询、分组聚合等业务场景，查询的复杂度需要转嫁给开发者。即使某些中间件能实现简单的 join 支持，但是仍然没有办法保证查询的正确性。另外广播是一个没有办法 Scale 的方案，当集群规模变大，广播的性能开销是很大的。同时，传统 RDBMS 上 DDL 锁表的问题，对于数据量较大的业务来说，锁定的时间会很长，如果使用 gh-ost 这样第三方工具来实现非阻塞 DDL，额外的空间开销会比较大，而且仍然需要人工的介入确保数据的一致性，最后切换的过程系统可能会有抖动。可以说，运维的复杂性是随着机器数量指数级增长，而扩容复杂度则是直接转嫁给了 DBA。
最终，猿辅导的后台开发同学决定寻求一个彻底的分布式存储解决方案。通过对社区方案的调研，猿辅导发现分布式关系型数据库 TiDB 项目。
TiDB 是一款定位于在线事务处理/在线分析处理（HTAP）的融合型数据库产品，具备在线弹性水平扩展、分布式强一致性事务、故障自恢复的高可用、跨数据中心多活等核心特性；对业务没有任何侵入性，能优雅的替换传统的数据库中间件、数据库分库分表等 Sharding 方案，并在此过程中保证了事务的 ACID 特性。同时它也让开发运维人员不用关注数据库 Scale 的细节问题，专注于业务开发，极大的提升研发的生产力。用户可以把 TiDB 当作一个容量无限扩展的单机数据库，复杂的分布式事务和数据复制由底层存储引擎来支持，开发者只需要集中精力在业务逻辑的开发上面。
图为 TiDB 与传统的 MySQL 中间件方案的一些对比
TiDB 集群主要分为三个组件：TiDB Server、TiKV Server、PD Server。
TiDB 整体架构图
TiDB Server 负责处理 SQL 请求，随着业务的增长，可以简单的添加 TiDB Server 节点，提高整体的处理能力，提供更高的吞吐。TiKV 负责存储数据，随着数据量的增长，可以部署更多的 TiKV Server 节点解决数据 Scale 的问题。PD 会在 TiKV 节点之间以 Region 为单位做调度，将部分数据迁移到新加的节点上。所以企业在业务的早期，可以只部署少量的服务实例，随着业务量的增长，按照需求添加 TiKV 或者 TiDB 实例。</description>
    </item>
    
    <item>
      <title>TiDB 在二维火餐饮管理实时报表中的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-erweihuo/</link>
      <pubDate>Wed, 31 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-erweihuo/</guid>
      <description>作者介绍：火烧（花名），二维火架构运维负责人
 二维火 SaaS 平台介绍 二维火作为餐饮商家管理标准化服务提供商，帮助商家节省经营成本、提升服务效果是我们的使命。在商家日常生产中，上游系统产生了很多数据，包括供应链采购系统（Support），门店收银系统（POS），食客排队系统（Queueing），智能厨房显示系统（KDS），电子菜谱系统等（E-Menu）， 一个实时、精准、可多维度分析的报表系统能充分利用这些数据，支持商家对经营决策进行优化，极大提升商家工作效率。主要服务于以下场景：
 收银员交接班需要通过收银软件、财务报表进行多维度对账，来保障收银员一天的辛苦劳动。
 商家运营人员需要时段性监控每个门店的经营状况，并通过监控数据实时调整运营策略。
 中小型店老板解放自我，不再需要时时刻刻呆在门店里，也能从原料变化到收入波动进行实时把控。
 大型门店连锁更有专门的指挥中心，实时了解每个门店的经营状况，实现一体化管理。
  二维火各类报表界面：
二维火实时报表的业务约束  要求实时或者准实时，数据延迟不超过 3 秒。
 数据量大、数据增速快，报表结果查询需要在 500 ms 之内返回结果。
 查询维度多，查询条件复杂，涉及十几个业务表，上百个维度汇总查询。
  随着业务范围扩大以及功能扩展，实时报表业务不光承担了报表业务，业务方同时希望这是一个数据实时、可多维度查询分析的数据平台工具，为业务进行各种数据支持。
二维火数据的特殊场景  商家门店连锁关系不是固定的，A 门店数据今天属于 AA 连锁，明天可能会变成 BB 连锁。
 数据展现多人多面，权限不同展现结果不同。
 数据变更非常频繁，一条数据最少也会经过五六次变更操作。
 实时报表展现的不仅是当天数据，涉及到挂帐、垮天营业、不结账等复杂状况，生产数据的生命周期往往会超过一个月以上。
  如果用 MySQL 作为报表存储引擎的话，一个门店所属连锁总部变更，相当于分库的路由值产生了变化，意味着需要对这家店的数据进行全量迁移，这是个灾难性的事情，我们希望连锁只是个属性，而不用受到 Sharding Key 的制约导致的一地鸡毛。
开始的解决方案 我们的业务数据是构建在 MySQL 之上，按照业务和商家维度进行分库。利用 Otter 订阅业务数据，进行数据整理归并到 Apache Solr[1] 中，输出分析、统计报表所需要的数据。然而随着业务的快速发展以及客户定制化需求不断增加，Solr 的瓶颈从一张白纸慢慢地被填充。
 不断的添加检索维度，需要不停的对索引进行 Full Build，Solr 的 Full Build 成本慢慢地高成了一座大山。</description>
    </item>
    
    <item>
      <title>TiDB 助力客如云餐饮 SaaS 服务</title>
      <link>https://pingcap.com/cases-cn/user-case-keruyun/</link>
      <pubDate>Fri, 25 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-keruyun/</guid>
      <description>作者：客如云 BigData Infra Team  公司介绍 客如云成立于 2012 年，是全球领先、 国内最大的 SaaS 系统公司。 目前面向餐饮、 零售等服务业商家， 提供软硬一体的新一代智能化前台、收银等 SaaS 云服务，包括预订、排队、外卖、点餐、收银、会员管理、进销存等系统服务，并将数据实时传达云端。我们是客如云的大数据基础架构组，负责公司的大数据架构和建设工作，为公司提供大数据基础数据服务。
业务发展遇到的痛点 1. 随着公司业务架构越来越复杂，技术架构组需要在服务器端与应用端尽可能的通过微服务化实现业务解耦，同时需要第三方熔断服务机制来保证核心业务正常运行。数据库层面，为了保证高并发的实时写入、实时查询、实时统计分析，我们针对地做了很多工作，比如对实时要求较高的服务走缓存、对大表进行分库分表操作、对有冷热属性的大表进行归档、库分离，虽然用大量人力资源解决了部分问题，但是同时也带来了历史数据访问、跨库分表操作、多维度查询等问题。
2. 大数据量下，MySQL 稍微复杂的查询都会很慢，线上业务也存在单一复杂接口包含执行几十次 SQL 的情况，部分核心交易大库急需解决访问性能。
3. 餐饮行业有明显的业务访问高峰时间，高峰期期间数据库会出现高并发访问，而有些业务，比如收银，在高峰期出现任何 RDS 抖动都会严重影响业务和用户体验。
4. 传统的数仓业务往往有复杂的 T+1 的 ETL 过程，无法实时的对业务变化进行动态分析和及时决策。
业务描述 大数据的 ODS（Operational Data Store）以前选型的是 MongoDB，ODS 与支持 SaaS 服务的 RDS 进行数据同步。初期的设想是线上的复杂 SQL、分析 SQL，非核心业务 SQL 迁移到大数据的 ODS 层。同时 ODS 也作为大数据的数据源，可以进行增量和全量的数据处理需求。但是由于使用的 MongoDB，对业务有一定侵入，需要业务线修改相应查询语句，而这点基本上遭到业务线的同学不同程度的抵制。同时目前大数据使用的是 Hadoop + Hive 存储和访问方案，业务线需要把历史明细查询迁移到 Hadoop ，然后通过 Impala、Spark SQL、Hive SQL 进行查询，而这三个产品在并发度稍微高的情况下，响应时间都会很慢，所以大数据组在提供明细查询上就比较麻烦。 同时更为棘手的是，面对客户查询服务（历史细则、报表等），这类查询的并发会更高，而且客户对响应时间也更为敏感，我们首先将处理后的数据（历史细则等）放在了 MongoDB 上（当时 TiDB 1.</description>
    </item>
    
    <item>
      <title>TiDB 助力卡思数据视频大数据业务创新</title>
      <link>https://pingcap.com/cases-cn/user-case-kasi/</link>
      <pubDate>Mon, 05 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-kasi/</guid>
      <description>作者：刘广信，火星文化技术经理
 卡思数据是国内领先的视频全网数据开放平台，依托领先的数据挖掘与分析能力，为视频内容创作者在节目创作和用户运营方面提供数据支持，为广告主的广告投放提供数据参考和效果监测，为内容投资提供全面客观的价值评估。
图 1 卡思数据产品展示图
业务发展遇到的痛点 卡思数据首先通过分布式爬虫系统进行数据抓取，每天新增数据量在 50G - 80G 之间，并且入库时间要求比较短，因此对数据库写入性能要求很高，由于数据增长比较快，对数据库的扩展性也有很高的要求。数据抓取完成后，对数据进行清洗和计算，因为数据量比较大，单表 5 亿 + 条数据，所以对数据库的查询性能要求很高。
起初卡思数据采用的是多个 MySQL 实例和一个 MongoDB 集群，如图 2。
 MySQL 存储业务相关数据，直接面向用户，对事务的要求很高，但在海量数据存储方面偏弱，由于单行较大，单表数据超过千万或 10G 性能就会急剧下降。
 MongoDB 存储最小单元的数据，MongoDB 有更好的写入性能，保证了每天数据爬取存储速度；对海量数据存储上，MongoDB 内建的分片特性，可以很好的适应大数据量的需求。
  图 2 起初卡思数据架构图
但是随着业务发展，暴露出一些问题：
 MySQL 在大数据量的场景下，查询性能难以满足要求，并且扩展能力偏弱，如果采用分库分表方式，需要对业务代码进行全面改造，成本非常高。
 MongoDB 对复杂事务的不支持，前台业务需要用到数据元及连表查询，当前架构支持的不太友好。
  架构优化 1. 需求 针对我们遇到的问题，我们急需这样一款数据库：
 兼容 MySQL 协议，数据迁移成本和代码改造成本低
 插入性能强
 大数据量下的实时查询性能强，无需分库分表
 水平扩展能力强
 稳定性强，产品最好有成熟的案例
  2. 方案调研 未选择 TiDB 之前我们调研了几个数据库，Greenplum、HybirdDB for MySQL（PetaData）以及 PolarDB。Greenplum 由于插入性能比较差，并且跟 MySQL 协议有一些不兼容，首先被排除。</description>
    </item>
    
    <item>
      <title>TiDB 在凤凰网新闻内容业务的创新实践</title>
      <link>https://pingcap.com/cases-cn/user-case-ifeng/</link>
      <pubDate>Thu, 04 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-ifeng/</guid>
      <description>作者：卞新栋，凤凰网工程师
 背景 凤凰网（纽交所上市公司，代码：FENG）是全球领先的跨平台网络新媒体公司，整合旗下综合门户凤凰网、手机凤凰网和凤凰视频三大平台，秉承&amp;rdquo;中华情怀，全球视野，兼容开放，进步力量&amp;rdquo;的媒体理念，为主流华人提供互联网、无线通信、电视网的三网融合无缝衔接的新媒体优质内容与服务。
在媒体行业，新闻内容就是核心的业务数据，我们需要一个稳定的、具有高可用的、易水平扩展的数据存储系统，来存放公司核心数据，在最早，我们采用比较流行的 MySQL 来存储各个业务模块的内容，通过主从切换的方式进行高可用，但随着数据量的增加，MySQL 单机容量成为了瓶颈，传统的基于 MySQL 分片方案在实现及运维都需要比较昂贵的成本，同时 MySQL 主流主从切换方案由于机制问题，在判断“主库真死”，“新主库选举”及“新路由信息广播”上都存在一些不足，整体时间消耗比较大，并不能达到公司核心业务的高可用要求。于是，我们不得不寻找新的解决方案。
选择 TiDB 前期方案选择 在选择评估初期，我们主要有以下几个考虑点：
 支持业务弹性的水平扩容与缩容；
 满足业务故障自恢复的高可用；
 支持 MySQL 便捷稳定的迁移，不影响线上业务；
 支持 SQL，尽量少的改动代码；
 使用上、运维上要足够优化，最好支持在线 DDL。
  在寻找的道路中，我们惊喜的发现了 TiDB — 中国人研发主导的开源分布式数据库。
数据库容量及扩展 记得有这样一句话：“单机 MySQL 能解决的问题，不要使用 TiDB！”，我们原有的数据存储存放于多个 MySQL 数据库中。诚然，对于数据量小的库来说，一些常见的点查、范围查 MySQL 的性能要比 TiDB 的性能好，如果不考虑扩张的问题，短期内使用主从 MySQL 比使用 TiDB 更满足我们的线上需求，但是，即使如此，我们也不得不考虑成本问题。将多套线上的主从 MySQL 迁移到 TiDB，更能充分利用服务器资源，减少资源的浪费。而对于很多业务来说，扩张问题是不可能回避的，对数据日益增长的数据库来说，单表响应时间会越来越长，而分库分表的成本过高，代码需要改动和测试，即使业务上能接受这一次的操作，那下次扩容呢？TiDB 通过底层自动进行分片帮我们解决了这个问题，同时业务量的增加或减少可以通过添加减少节点来处理，代码上基本无改动，这也是我们所期望的。
高可用 对于原有的主从 MySQL，并没有配置高可用，我们也对 MHA 等第三方工具做过调研，在发生主从切换后，在新路由信息分发这块也依赖修改网络配置或者数据库中间件（DBproxy），有一定的时间成本，虽然业界有很多中间件方案，但也很多问题和技术成本，所以这个方向并不是我们首选，之前的方式是一旦 MySQL 主数据库宕机，我们通过内部的监控系统获知，再进行更改 Keepalived + HAproxy 配置，即使人为响应非常及时，其影响的时间也早已超过业务的容忍。而选择天然的多节点 TiDB 自然就避免了这一点，配合网络 HAproxy 完全实现了 DB 层面的高可用。前一段时间，我们内部监控系统升级，其中一台机器没有对 TiKV 添加监控，而该 TiKV 节点由于硬件原因服务宕了几天，我们业务上也未感知，当然这是我们的失误，但是也侧面反应了 TiDB 自身的高可用机制。</description>
    </item>
    
    <item>
      <title>TiDB 在 G7 的实践和未来</title>
      <link>https://pingcap.com/cases-cn/user-case-g7/</link>
      <pubDate>Mon, 15 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-g7/</guid>
      <description>作者简介：廖强，曾供职于百度，负责百度钱包的分布式事务数据库，基础架构和收银台。现 G7 汇通天下技术合伙人，负责金融产品研发、运维和安全。
 背景 2010 年，G7 正式为物流运输行业提供面向车队管理的 SaaS 服务，经过持续创新，通过软硬一体化的产品技术能力，致力于数字化每一辆货车，以实时感知技术创造智慧物流新生态。G7 为客户提供全方位的数据服务、智能的安全和运营管理、手机管车、数字运力、以及 ETC、油和金融等增值服务。
目前，G7 连接了 600,000 辆货车，每天行驶 6500 万公里（可绕地球赤道 1625 圈），13.5 亿个轨迹点和 2,200 万次车辆事件触发，并且以直线速度飞速增长。G7 每天产生的车辆行驶、状态、消费等数据超过 2T，飞速增加的车辆、数据类型和复杂的金融业务，使得数据库的事务、分析、扩展和可用性面临巨大的挑战。
在大量的车辆信息和轨迹相关数据业务中，当前我们通过 Spark、Hive 等对大量原始数据进行分析后，存入阿里云 DRDS，对外提供基础数据接口服务。由于清洗后的数据量依然很大，使用 DRDS 的存储成本非常高，且面对很多 OLAP 的查询时，效率不如人意。
而在金融和支付这种复杂业务场景中，面临 CAP 中 C 和 P 的挑战。在以往的工作中，支付系统由于面临强一致性事务的高峰值写入问题，采用了 2PC+MySQLXA（单个 MySQL 作为参与者，上层增加 Proxy 作为协调者）完成了分布式事务数据库的方案。但是这种方案在 Partition 中，极为麻烦。同时，运营和风控系统经常需要做相对复杂的查询，要么通过 MySQL+ETL+OLAP 数据库（成本高），要么容忍查询的效率问题。
探索 G7 的技术团队一直在寻找一种能解决上述问题的数据库。要找到这样一种数据库，除了需要满足上述需求以外，还需要满足另一个需求：可维护性和易迁移性。这要求该数据库具体需要满足如下几个要求：
 兼容 MySQL 协议，使得数据库的变更对上层业务透明，这个有多重要，做过基础架构升级落地的同学应该深有感触。
 支持 MySQL 的主从同步机制，使得数据库的变更可以平滑逐步升级，降低变更风险。
 必须是开源的。数据库的稳定需要付出很大的精力和时间，在这个过程中，或多或少都出现问题。出现问题不可怕，可怕的是无法定位和解决问题，只能依赖“他人”。数据库的一个 BUG 对“他人”来说，可能是一个小问题，对 G7 业务而言，可能是一个巨大的灾难。当“屁股”不在同一个板凳上时，我们需要对数据库有很强的掌控力。
 开源的同时，背后一定需要有一个有实力的技术团队或商业公司的全力投入。在见识了不少“烂尾”和“政绩”的开源项目后，只有一个稳定全职投入的技术团队或商业公司，才能最终让这个数据库越来越好。</description>
    </item>
    
    <item>
      <title>TiDB 在 Mobikok 广告系统中的应用和实践</title>
      <link>https://pingcap.com/cases-cn/user-case-mobikok/</link>
      <pubDate>Wed, 18 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-mobikok/</guid>
      <description>作者：rayi，深圳可可网络服务端架构负责人
 公司介绍 Mobikok（可可网络）成立于 2013 年，是一家快速成长的移动互联网营销公司，专注于移动 eCPM 营销。总部在中国深圳，聚焦于订阅 offer 的海外流量变现业务。Mobikok 提供的接口方式支持各类手机端流量（API、SDK、Smartlink），RTB（实时竞价系统）对接海外的 DSP（Demand-Side Platform，需求方平台）高效优化客户的广告效果。截止目前，系统已对 2 亿用户进行广告优化，已接入上百家广告主以及上百家渠道，Mobikok 致力于高效，便捷，专业的帮助广告主以及渠道互惠共赢。
场景介绍：SSP 系统 订阅 SSP（Sell-Side-Platform）平台当前业务主要分为：SDK、Smartlink、Online API 以及 Offline API；在当前 SSP SDK 业务系统当中，累计用户已达到 2 亿，最初使用的是 MySQL 主从分表的方式存储用户数据，随着数据量的增加，MySQL 单机容量以及大数据量查询成为了瓶颈；当单表数据达到 2 千万以上时，单机 MySQL 的查询以及插入已经不能满足业务的需求，当访问量到一定阶段后，系统响应能力在数据库这一块是一个瓶颈。
一次很偶然的机会在 GitHub 上面了解到 TiDB，并且因为现在业务系统当中使用的 Redis 集群是 Codis，已在线上稳定使用两年，听闻 TiDB 创始团队就是之前 Codis 的作者，所以对 TiDB 有了极大的兴趣并且进行测试。通过测试单机 MySQL 和 TiDB 集群，当数据量达到数千万级别的时候发现 TiDB 效率明显高于 MySQL。所以就决定进行 MySQL 到 TiDB 迁移。
迁移后整体架构图：
引入 TiDB 在选择使用替换 MySQL 方案当中。我们主要考虑几点：
 支持 MySQL 便捷稳定的迁移，不影响线上业务；</description>
    </item>
    
    <item>
      <title>TiDB 在零氪科技（LinkDoc）大数据医疗系统的实践</title>
      <link>https://pingcap.com/cases-cn/user-case-linkdoc/</link>
      <pubDate>Mon, 05 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-linkdoc/</guid>
      <description>作者介绍：杨浩，现任零氪科技运维&amp;amp;安全负责人，曾就职于阿里巴巴-技术保障部-CDN。专注 CDN、安全、自动化运维、大数据等领域。
 公司介绍 零氪科技作为全球领先的人工智能与医疗大数据平台，拥有国内最大规模、体量的医疗大数据资源库和最具优势的技术支撑服务体系。多年来，零氪科技凭借在医疗大数据整合、处理和分析上的核心技术优势，依托先进的人工智能技术，致力于为社会及行业、政府部门、各级医疗机构、国内外医疗器械厂商、药企等提供高质量医疗大数据整体解决方案，以及人工智能辅助决策系统（辅助管理决策、助力临床科研、AI 智能诊疗）、患者全流程管理、医院舆情监控及品牌建设、药械研发、保险控费等一体化服务。
LinkDoc 的主要应用场景 LinkDoc 通过将患者真实的病例数据和算法模型应用于肿瘤治疗，构建精准的诊疗模型并提供数据支持，从而辅助医院管理决策、辅助科研、辅助临床诊疗。目前 Hubble 系统“肺癌淋巴结跳跃转移风险预测”模块可避免肺癌病人由于误判而导致提前 8-10 个月的复发，每年能让近两万病人的生命再延长 8-10 个月。Hubble 系统“AI - 肺结节智能诊断”模块全自动地识别 CT 影像中所有的结节，识别率达 91.5%。LinkDoc 希望凭借医疗大数据整合、处理和分析上的核心技术优势，以互联网人工智能上的创新研发，提升中国医师的全球医学水准，并通过支持药物研发与医疗保险行业的发展，让每一位患者享有普惠、精准的医疗服务。
支撑 LinkDoc 业务的底层数据库平台也面临着医疗行业新领域的技术 &amp;amp; 业务挑战，如数据量的快速增长（亿级别）、大数据量下的清洗逻辑的数据擦写、分析型事务对数据库的读压力都要求我们在数据库平台进行重新探索，选择一款适合医疗大数据业务的数据库解决方案。
选择 TiDB 业务痛点  数据量大，单实例 MySQL 扩容操作复杂；
 写入量大，主从延时高，由于业务对数据有低延时的要求，所以传统的 MySQL 主从架构在该项目下不能满足需求，大量数据写入下主库成为性能瓶颈；
 随着数据量越来越大，部分统计查询速度慢；
 分库分表业务开发和维护成本高。
  业务需求  高可靠性 &amp;amp; 稳定性；
 可扩展性，可随数据量 &amp;amp; 请求量增长快速提升存储 &amp;amp; 请求处理能力；
 更低的延时。
  方案调研 未选择 TiDB 之前我们调研了 MyCAT、Cobar、Atlas 等中间件解决方案，这些中间件整体来说就是让使用者觉得很“拧巴”，从社区支持、MySQL 功能兼容、系统稳定性上都不尽人意，需要业务做大量改造，对于快速发展的公司来说切换成本太高。
在 LinkDoc 首席架构师王晓哲的推荐下我们调研了 TiDB, TiDB 的如下特性让我们眼前一亮：</description>
    </item>
    
    <item>
      <title>TiDB 助力一面数据实现消费领域的决策分析平台</title>
      <link>https://pingcap.com/cases-cn/user-case-yimian/</link>
      <pubDate>Fri, 15 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/cases-cn/user-case-yimian/</guid>
      <description>作者：刘畅，一面数据高级 AI 工程师。
 公司介绍 深圳市一面网络技术有限公司（下称：一面数据）是一家为消费领域的领导企业提供实时、精准、全面的数据洞察和决策指导的创新型企业，利用人工智能和算法，进行自然语言处理，语义情感分析，回归预测模型等，帮助客户实现精准产品运营和预测市场变化。一面数据服务于国内外一流企业，包括世界最大的对冲基金、国际一线汽车品牌、快消品龙头厂商，以及时尚鞋服大牌等。
改造前系统架构 一面数据的核心 IT 系统覆盖了从数据获取、数据清洗处理、数据建模到数据可视化的全套数据分析流程。核心系统每天有海量从互联网采集的公开数据和来自企业内部的数据，对数据存储的容量、扩展性和可用性都有很高的要求。
起初，一面数据的核心系统采用的是多个 MySQL 实例和一个 Cassandra 集群。MySQL 多实例集群主要存储指定特征的爬虫数据，Cassandra 主要存储数据量大、不适合存储 MySQL 的全页面缓存的数据。在数据量/请求量小的时候系统运行正常。下图为一面数据改造前系统构架图：
随着数据量的增长，逐渐暴露出很多问题：
 MySQL：随着数据增长，存储容量接近单机的磁盘极限，单机的磁盘 IO 繁忙且易阻塞，查询性能难以满足业务增长的需求。数据量大了以后，传统的 MySQL 水平扩展能力弱，性能和稳定性容易产生问题，在数据量和访问量增长到一定阶段将无法满足常见的 OLAP 场景分析需求。技术团队通过诊断系统性能问题，认识到现有数据库已经成为瓶颈。
 Cassandra：Cassandra 对磁盘 IO 和内存要求高，添加一个实例，需要从其他实例迁数据，对网络带宽、 磁盘要求特别高。另外 CQL 支持的特性太少，业务开发麻烦，例如不能联表，不支持主键之外的索引，对主键以外的查询比较困难，虽然有 Secondary Index，但是使用限制大。生态圈不完善，例如很难找到好用的监控。
  改造后的系统架构 引入 TiDB 替换 MySQL 和 Cassandra 为从根本上解决以上问题，一面数据的技术团队决定通过增加部署一套高性能的数据库系统，以解决当前业务的痛点。 在评估和验证了 MySQL Sharding 和 MongoDB 等传统技术手段之后，团队认识到：基于 MySQL Sharding (即利用 MySQL 中间件分库分表) 架构在高可用安全能力，业务和查询的灵活支持以及运维管理难度和成本上都不尽如人意，有着诸多架构上和技术上的缺陷；而 MongoDB 比较适合存储爬虫数据，但迁移成本高，不管是数据还是应用程序都需要做侵入性修改和调整，难度和开发成本骤升。另外，作为 NoSQL 数据库，MongoDB 不支持 SQL 和 JOIN ，对 BI 工具的支持也不完善，数据分析师们无法直接使用。 最终从满足业务需求、降低切换成本和减少运维成本等角度考虑，一面数据选择了分布式关系型数据库－TiDB 作为业务的首选事务型数据库。</description>
    </item>
    
    <item>
      <title>Golang Failpoint 的设计与实现</title>
      <link>https://pingcap.com/blog-cn/golang-failpoint/</link>
      <pubDate>Tue, 30 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/golang-failpoint/</guid>
      <description>对于一个大型复杂的系统来说，通常包含多个模块或多个组件构成，模拟各个子系统的故障是测试中必不可少的环节，并且这些故障模拟必须做到无侵入地集成到自动化测试系统中，通过在自动化测试中自动激活这些故障点来模拟故障，并观测最终结果是否符合预期结果来判断系统的正确性和稳定性。如果在一个分布式系统中需要专门请一位同事来插拔网线来模拟网络异常，一个存储系统中需要通过破坏硬盘来模拟磁盘损坏，昂贵的测试成本会让测试成为一场灾难，并且难以模拟一些需要精细化控制的的测试。所以我们需要一些自动化的方式来进行确定性的故障测试。
Failpoint 项目 就是为此而生，它是 FreeBSD failpoints 的 Golang 实现，允许在代码中注入错误或异常行为， 并由环境变量或代码动态激活来触发这些异常行为。Failpoint 能用于各种复杂系统中模拟错误处理来提高系统的容错性、正确性和稳定性，比如：
 微服务中某个服务出现随机延迟、某个服务不可用。 存储系统磁盘 IO 延迟增加、IO 吞吐量过低、落盘时间长。 调度系统中出现热点，某个调度指令失败。 充值系统中模拟第三方重复请求充值成功回调接口。 游戏开发中模拟玩家网络不稳定、掉帧、延迟过大等，以及各种异常输入（外挂请求）情况下系统是否正确工作。 ……  为什么要重复造轮子？ Etcd 团队在 2016 年开发了 gofail 极大地简化了错误注入，为 Golang 生态做出了巨大贡献。我们在 2018 年已经引入了 gofail 进行错误注入测试，但是我们在使用中发现了一些功能性以及便利性的问题，所以我们决定造一个更好的「轮子」。
如何使用 gofail  使用注释在程序中注入一个 failpoint：
// gofail: var FailIfImportedChunk int // if merger, ok := scp.merger.(*ChunkCheckpointMerger); ok &amp;amp;&amp;amp; merger.Checksum.SumKVS() &amp;gt;= uint64(FailIfImportedChunk) { // rc.checkpointsWg.Done() // rc.checkpointsWg.Wait() // panic(&amp;#34;forcing failure due to FailIfImportedChunk&amp;#34;) // } // goto RETURN1  // gofail: RETURN1:  // gofail: var FailIfStatusBecomes int // if merger, ok := scp.</description>
    </item>
    
    <item>
      <title>DM 源码阅读系列文章（四）dump/load 全量同步的实现</title>
      <link>https://pingcap.com/blog-cn/dm-source-code-reading-4/</link>
      <pubDate>Fri, 26 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/dm-source-code-reading-4/</guid>
      <description>本文为 DM 源码阅读系列文章的第四篇，上篇文章 介绍了数据同步处理单元实现的功能，数据同步流程的运行逻辑以及数据同步处理单元的 interface 设计。本篇文章在此基础上展开，详细介绍 dump 和 load 两个数据同步处理单元的设计实现，重点关注数据同步处理单元 interface 的实现，数据导入并发模型的设计，以及导入任务在暂停或出现异常后如何恢复。
dump 处理单元 dump 处理单元的代码位于 github.com/pingcap/dm/mydumper 包内，作用是从上游 MySQL 将表结构和数据导出到逻辑 SQL 文件，由于该处理单元总是运行在任务的第一个阶段（full 模式和 all 模式），该处理单元每次运行不依赖于其他处理单元的处理结果。另一方面，如果在 dump 运行过程中被强制终止（例如在 dmctl 中执行 pause-task 或者 stop-task），也不会记录已经 dump 数据的 checkpoint 等信息。不记录 checkpoint 是因为每次运行 mydumper 从上游导出数据，上游的数据都可能发生变更，为了能得到一致的数据和 metadata 信息，每次恢复任务或重新运行任务时该处理单元会 清理旧的数据目录，重新开始一次完整的数据 dump。
导出表结构和数据的逻辑并不是在 DM 内部直接实现，而是 通过 os/exec 包调用外部 mydumper 二进制文件 来完成。在 mydumper 内部，我们需要关注以下几个问题：
 数据导出时的并发模型是如何实现的。
 no-locks, lock-all-tables, less-locking 等参数有怎样的功能。
 库表黑白名单的实现方式。
  mydumper 的实现细节 mydumper 的一次完整的运行流程从主线程开始，主线程按照以下步骤执行：</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（六）raft-rs 日志复制过程分析</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-6/</link>
      <pubDate>Wed, 24 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-6/</guid>
      <description>在 《TiKV 源码解析系列文章（二）raft-rs proposal 示例情景分析》  中，我们主要介绍了 raft-rs 的基本 API 使用，其中，与应用程序进行交互的主要 API 是：
 RawNode::propose 发起一次新的提交，尝试在 Raft 日志中追加一个新项；
 RawNode::ready_since 从 Raft 节点中获取最近的更新，包括新近追加的日志、新近确认的日志，以及需要给其他节点发送的消息等；
 在将一个 Ready 中的所有更新处理完毕之后，使用 RawNode::advance 在这个 Raft 节点中将这个 Ready 标记为完成状态。
  熟悉了以上 3 个 API，用户就可以写出基本的基于 Raft 的分布式应用的框架了，而 Raft 协议中将写入同步到多个副本中的任务，则由 raft-rs 库本身的内部实现来完成，无须应用程序进行额外干预。本文将对数据冗余复制的过程进行详细展开，特别是关于 snapshot 及流量控制的机制，帮助读者更深刻地理解 Raft 的原理。
一般 MsgAppend 及 MsgAppendResponse 的处理 在 Raft leader 上，应用程序通过 RawNode::propose 发起的写入会被处理成一条 MsgPropose 类型的消息，然后调用 Raft::append_entry 和 Raft::bcast_append 将消息中的数据追加到 Raft 日志中并广播到其他副本上。整体流程如伪代码所示：
fn Raft::step_leader(&amp;amp;mut self, mut m: Message) -&amp;gt; Result&amp;lt;()&amp;gt; { if m.</description>
    </item>
    
    <item>
      <title>DM 源码阅读系列文章（三）数据同步处理单元介绍</title>
      <link>https://pingcap.com/blog-cn/dm-source-code-reading-3/</link>
      <pubDate>Wed, 10 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/dm-source-code-reading-3/</guid>
      <description>本文为 DM 源码阅读系列文章的第三篇，上篇文章 介绍了 DM 的整体架构，DM 组件 DM-master 和 DM-worker 的入口代码，以及两者之间的数据交互模型。本篇文章详细地介绍 DM 数据同步处理单元（DM-worker 内部用来同步数据的逻辑单元），包括数据同步处理单元实现了什么功能，数据同步流程、运行逻辑，以及数据同步处理单元的 interface 设计。
数据同步处理单元 从上图可以了解到目前 DM 包含 relay log、dump、load、binlog replication（sync） 4 个数据同步处理单元，涵盖了以下数据同步处理的功能：
   处理单元 功能     relay log 持久化 MySQL/MariaDB Binlog 到磁盘   dump 从 MySQL/MariaDB dump 全量数据   load 加载全量数据到 TiDB cluster   binlog replication（sync） 复制 relay log 存储的 Binlog 到 TiDB cluster    数据同步流程 Task 数据同步流程初始化操作步骤：</description>
    </item>
    
    <item>
      <title>Kubernetes 中如何保证优雅地停止 Pod</title>
      <link>https://pingcap.com/blog-cn/tidb-opeartor-webhook/</link>
      <pubDate>Mon, 01 Apr 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-opeartor-webhook/</guid>
      <description>一直以来我对优雅地停止 Pod 这件事理解得很单纯：不就利用是 PreStop hook 做优雅退出吗？但最近发现很多场景下 PreStop Hook 并不能很好地完成需求，这篇文章就简单分析一下“优雅地停止 Pod”这回事儿。
何谓优雅停止？ 优雅停止（Graceful shutdown）这个说法来自于操作系统，我们执行关机之后都得 OS 先完成一些清理操作，而与之相对的就是硬中止（Hard shutdown），比如拔电源。
到了分布式系统中，优雅停止就不仅仅是单机上进程自己的事了，往往还要与系统中的其它组件打交道。比如说我们起一个微服务，网关把一部分流量分给我们，这时：
 假如我们一声不吭直接把进程杀了，那这部分流量就无法得到正确处理，部分用户受到影响。不过还好，通常来说网关或者服务注册中心会和我们的服务保持一个心跳，过了心跳超时之后系统会自动摘除我们的服务，问题也就解决了；这是硬中止，虽然我们整个系统写得不错能够自愈，但还是会产生一些抖动甚至错误。 假如我们先告诉网关或服务注册中心我们要下线，等对方完成服务摘除操作再中止进程，那不会有任何流量受到影响；这是优雅停止，将单个组件的启停对整个系统影响最小化。  按照惯例，SIGKILL 是硬终止的信号，而 SIGTERM 是通知进程优雅退出的信号，因此很多微服务框架会监听 SIGTERM 信号，收到之后去做反注册等清理操作，实现优雅退出。
PreStop Hook 回到 Kubernetes（下称 K8s），当我们想干掉一个 Pod 的时候，理想状况当然是 K8s 从对应的 Service（假如有的话）把这个 Pod 摘掉，同时给 Pod 发 SIGTERM 信号让 Pod 中的各个容器优雅退出就行了。但实际上 Pod 有可能犯各种幺蛾子：
 已经卡死了，处理不了优雅退出的代码逻辑或需要很久才能处理完成。 优雅退出的逻辑有 BUG，自己死循环了。 代码写得野，根本不理会 SIGTERM。  因此，K8s 的 Pod 终止流程中还有一个“最多可以容忍的时间”，即 grace period（在 Pod 的 .spec.terminationGracePeriodSeconds 字段中定义），这个值默认是 30 秒，我们在执行 kubectl delete 的时候也可通过 --grace-period 参数显式指定一个优雅退出时间来覆盖 Pod 中的配置。而当 grace period 超出之后，K8s 就只能选择 SIGKILL 强制干掉 Pod 了。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（五）fail-rs 介绍</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-5/</link>
      <pubDate>Fri, 29 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-5/</guid>
      <description>本文为 TiKV 源码解析系列的第五篇，为大家介绍 TiKV 在测试中使用的周边库 fail-rs。
fail-rs 的设计启发于 FreeBSD 的 failpoints，由 Rust 实现。通过代码或者环境变量，其允许程序在特定的地方动态地注入错误或者其他行为。在 TiKV 中通常在测试中使用 fail point 来构建异常的情况，是一个非常方便的测试工具。
Fail point 需求 在我们的集成测试中，都是简单的构建一个 KV 实例，然后发送请求，检查返回值和状态的改变。这样的测试可以较为完整地测试功能，但是对于一些需要精细化控制的测试就鞭长莫及了。我们当然可以通过 mock 网络层提供网络的精细模拟控制，但是对于诸如磁盘 IO、系统调度等方面的控制就没办法做到了。
同时，在分布式系统中时序的关系是非常关键的，可能两个操作的执行顺行相反，就导致了迥然不同的结果。尤其对于数据库来说，保证数据的一致性是至关重要的，因此需要去做一些相关的测试。
基于以上原因，我们就需要使用 fail point 来复现一些 corner case，比如模拟数据落盘特别慢、raftstore 繁忙、特殊的操作处理顺序、错误 panic 等等。
基本用法 示例 在详细介绍之前，先举一个简单的例子给大家一个直观的认识。
还是那个老生常谈的 Hello World：
#[macro_use] extern crate fail; fn say_hello() { fail_point!(“before_print”); println!(“Hello World~”); } fn main() { say_hello(); fail::cfg(&amp;#34;before_print&amp;#34;, &amp;#34;panic&amp;#34;); say_hello(); } 运行结果如下：
Hello World~ thread &amp;#39;main&amp;#39; panicked at &amp;#39;failpoint before_print panic&amp;#39; .</description>
    </item>
    
    <item>
      <title>What’s New in TiDB 3.0.0 Beta.1</title>
      <link>https://pingcap.com/blog-cn/what-is-new-in-tidb-3.0.0-beta.1/</link>
      <pubDate>Tue, 26 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/what-is-new-in-tidb-3.0.0-beta.1/</guid>
      <description>今年 1 月份，我们发布了 TiDB 3.0.0 Beta 版本，DevCon 上也对这个版本做了介绍，经过两个月的努力，今天推出了下一个 Beta 版本 3.0.0 Beta.1。让我们看一下这个版本相比于之前有什么改进。
新增特性解读 Skyline Pruning 查询计划正确性和稳定性对于关系型数据库来说至关重要，3.0.0 Beta.1 对这部分进行了优化，引入一个叫 Skyline Pruning 的框架，通过一些启发式规则来更快更准确地找到最好的查询计划。详细信息可以参考 这篇设计文档。
日志格式统一 日志是排查程序问题的重要工具，统一且结构化的日志格式不但有利于用户理解日志内容，也有助于通过工具对日志进行定量分析。3.0.0 Beta.1 版本中对 tidb/pd/tikv 这三个组件的日志格式进行了统一，详细格式参见 这篇文档。
慢查询相关改进 慢查询日志是常用于排查性能问题, 在 3.0.0 Beta.1 之前慢查询日志跟其他日志混合存储在同个日志文件，并且格式为自定义的格式，不支持使用 SQL 语句或工具对其进行分析，严重影响排查问题的效率。从3.0.0 Beta.1 版本开始 TiDB 将查询日志文件输出到单独的日志文件中（默认日志文件名为 tidb-slow.log），用户可以系统变量或配置文件进行修改，同时兼容 MySQL 慢查询日志格式，支持使用 MySQL 生态分析工具（如 pt-query-digest）对慢查询日志进行分析。
除了慢查询日志之外，还增加一个虚拟表 INFORMATION_SCHEMA.SLOW_QUERY，可以对慢查询日志进行展示和过滤。
关于如何处理慢查询，我们后续还会专门写一篇文档进行介绍。如果你有一些好用的慢查询处理工具，也欢迎和我们进行交流。
Window Function MySQL 所支持的 Window Function TiDB 3.0.0 Beta.1 版本已经全都支持，这为 TiDB 向 MySQL 8 兼容迈出了一大步。想体验功能的可以下载版本尝鲜，但是不建议在生产中使用，这项功能还需要大量的测试，欢迎大家测试并反馈问题。
热点调度策略可配置化 热点调度是保持集群负载均衡的重要手段，但是一些场景下默认的热点调度显得不那么智能，甚至会对集群负载造成影响，所以 3.0.0 Beta.1 中增加了对负载均衡策略的人工干预方法，可以临时调整调度策略。</description>
    </item>
    
    <item>
      <title>DM 源码阅读系列文章（二）整体架构介绍</title>
      <link>https://pingcap.com/blog-cn/dm-source-code-reading-2/</link>
      <pubDate>Mon, 25 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/dm-source-code-reading-2/</guid>
      <description>本文为 DM 源码阅读系列文章的第二篇，第一篇文章 简单介绍了 DM 源码阅读的目的和规划，以及 DM 的源码结构以及工具链。从本篇文章开始，我们会正式开始阅读 DM 的源码。
本篇文章主要介绍 DM 的整体架构，包括 DM 有哪些组件、各组件分别实现什么功能、组件之间交互的数据模型和 RPC 实现。
整体架构 通过上面的 DM 架构图，我们可以看出，除上下游数据库及 Prometheus 监控组件外，DM 自身有 DM-master、DM-worker 及 dmctl 这 3 个组件。其中，DM-master 负责管理和调度数据同步任务的各项操作，DM-worker 负责执行具体的数据同步任务，dmctl 提供用于管理 DM 集群与数据同步任务的各项命令。
DM-master DM-master 的入口代码在 cmd/dm-master/main.go，其中主要操作包括：
 调用 cfg.Parse 解析命令行参数与参数配置文件
 调用 log.SetLevelByString 设置进程的 log 输出级别
 调用 signal.Notify 注册系统 signal 通知，用于接受到指定信号时退出进程等
 调用 server.Start 启动 RPC server，用于响应来自 dmctl 与 DM-worker 的请求
  在上面的操作中，可以看出其中最关键的是步骤 4，其对应的实现代码在 dm/master/server.</description>
    </item>
    
    <item>
      <title>DM 源码阅读系列文章（一）序</title>
      <link>https://pingcap.com/blog-cn/dm-source-code-reading-1/</link>
      <pubDate>Tue, 19 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/dm-source-code-reading-1/</guid>
      <description>前言 TiDB-DM 是由 PingCAP 开发的一体化数据同步任务管理平台，支持从 MySQL 或 MariaDB 到 TiDB 的全量数据迁移和增量数据同步，在 TiDB DevCon 2019 正式开源。作为一款连接 MySQL/MariaDB 生态和 TiDB 生态的中台类型产品，DM 获得了广泛的关注，很多公司、开发者和社区的伙伴已经在使用 DM 来进行数据迁移和管理。随着大家使用的广泛和深入，遇到了不少由于对 DM 原理不理解而错误使用的情况，也发现了一些 DM 支持并不完善的场景和很多可以改进的地方。
在这样的背景下，我们希望开展 DM 源码阅读分享活动，通过对 DM 代码的分析和设计原理的解读，帮助大家理解 DM 的实现原理，和大家进行更深入的交流，也有助于我们和社区共同进行 DM 的设计、开发和测试。
背景知识 本系列文章会聚焦 DM 自身，读者需要有一些基本的知识，包括但不限于：
 Go 语言，DM 由 Go 语言实现，有一定的 Go 语言基础有助于快速理解代码。
 数据库基础知识，包括 MySQL、TiDB 的功能、配置和使用等；知道基本的 DDL、DML 语句和事务的基本常识；MySQL 数据备份、主从同步的原理等。
 基本的后端服务知识，比如后台服务进程管理、RPC 工作原理等。
  总体而言，读者需要有一定 MySQL/TiDB 的使用经验，了解 MySQL 数据备份和主从同步的原理，以及可以读懂 Go 语言程序。在阅读 DM 源码之前，可以先从阅读《TiDB-DM 架构设计与实现原理》入手，并且参考 使用文档 在本地搭建一个 DM 的测试环境，从基础原理和使用对 DM 有一个初步的认识，然后再进一步分析源码，深入理解代码的设计和实现。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（四）Prometheus（下）</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-4/</link>
      <pubDate>Wed, 13 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-4/</guid>
      <description>本文为 TiKV 源码解析系列的第四篇，接上篇继续为大家介绍 rust-prometheus。上篇 主要介绍了基础知识以及最基本的几个指标的内部工作机制，本篇会进一步介绍更多高级功能的实现原理。
 与上篇一样，以下内部实现都基于本文发布时最新的 rust-prometheus 0.5 版本代码，目前我们正在开发 1.0 版本，API 设计上会进行一些简化，实现上出于效率考虑也会和这里讲解的略微有一些出入，因此请读者注意甄别。
指标向量（Metric Vector） Metric Vector 用于支持带 Label 的指标。由于各种指标都可以带上 Label，因此 Metric Vector 本身实现为了一种泛型结构体，Counter、Gauge 和 Histogram 在这之上实现了 CounterVec、GaugeVec 和 HistogramVec。Metric Vector 主要实现位于 src/vec.rs。
以 HistogramVec 为例，调用 HistogramVec::with_label_values 可获得一个 Histogram 实例，而 HistogramVec 定义为：
pub type HistogramVec = MetricVec&amp;lt;HistogramVecBuilder&amp;gt;; pub struct MetricVec&amp;lt;T: MetricVecBuilder&amp;gt; { pub(crate) v: Arc&amp;lt;MetricVecCore&amp;lt;T&amp;gt;&amp;gt;, } impl&amp;lt;T: MetricVecBuilder&amp;gt; MetricVec&amp;lt;T&amp;gt; { pub fn with_label_values(&amp;amp;self, vals: &amp;amp;[&amp;amp;str]) -&amp;gt; T::M { self.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（三）Prometheus（上）</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-3/</link>
      <pubDate>Fri, 08 Mar 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-3/</guid>
      <description>本文为 TiKV 源码解析系列的第三篇，继续为大家介绍 TiKV 依赖的周边库 rust-prometheus，本篇主要介绍基础知识以及最基本的几个指标的内部工作机制，下篇会介绍一些高级功能的实现原理。
rust-prometheus 是监控系统 Prometheus 的 Rust 客户端库，由 TiKV 团队实现。TiKV 使用 rust-prometheus 收集各种指标（metric）到 Prometheus 中，从而后续能再利用 Grafana 等可视化工具将其展示出来作为仪表盘监控面板。这些监控指标对于了解 TiKV 当前或历史的状态具有非常关键的作用。TiKV 提供了丰富的监控指标数据，并且代码中也到处穿插了监控指标的收集片段，因此了解 rust-prometheus 很有必要。
感兴趣的小伙伴还可以观看我司同学在 FOSDEM 2019 会议上关于 rust-prometheus 的技术分享。
 基础知识 指标类别 Prometheus 支持四种指标：Counter、Gauge、Histogram、Summary。rust-prometheus 库目前还只实现了前三种。TiKV 大部分指标都是 Counter 和 Histogram，少部分是 Gauge。
Counter Counter 是最简单、常用的指标，适用于各种计数、累计的指标，要求单调递增。Counter 指标提供基本的 inc() 或 inc_by(x) 接口，代表增加计数值。
在可视化的时候，此类指标一般会展示为各个时间内增加了多少，而不是各个时间计数器值是多少。例如 TiKV 收到的请求数量就是一种 Counter 指标，在监控上展示为 TiKV 每时每刻收到的请求数量图表（QPS）。
Gauge Gauge 适用于上下波动的指标。Gauge 指标提供 inc()、dec()、add(x)、sub(x) 和 set(x) 接口，都是用于更新指标值。
这类指标可视化的时候，一般就是直接按照时间展示它的值，从而展示出这个指标按时间是如何变化的。例如 TiKV 占用的 CPU 率是一种 Gauge 指标，在监控上所展示的直接就是 CPU 率的上下波动图表。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（二）raft-rs proposal 示例情景分析</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-2/</link>
      <pubDate>Fri, 15 Feb 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-2/</guid>
      <description>本文为 TiKV 源码解析系列的第二篇，按照计划首先将为大家介绍 TiKV 依赖的周边库 raft-rs 。raft-rs 是 Raft 算法的 Rust 语言实现。Raft 是分布式领域中应用非常广泛的一种共识算法，相比于此类算法的鼻祖 Paxos，具有更简单、更容易理解和实现的特点。
分布式系统的共识算法会将数据的写入复制到多个副本，从而在网络隔离或节点失败的时候仍然提供可用性。具体到 Raft 算法中，发起一个读写请求称为一次 proposal。本文将以 raft-rs 的公共 API 作为切入点，介绍一般 proposal 过程的实现原理，让用户可以深刻理解并掌握 raft-rs API 的使用， 以便用户开发自己的分布式应用，或者优化、定制 TiKV。
文中引用的代码片段的完整实现可以参见 raft-rs 仓库中的 source-code 分支。
Public API 简述 仓库中的 examples/five_mem_node/main.rs 文件是一个包含了主要 API 用法的简单示例。它创建了一个 5 节点的 Raft 系统，并进行了 100 个 proposal 的请求和提交。经过进一步精简之后，主要的类型封装和运行逻辑如下：
struct Node { // 持有一个 RawNode 实例 raft_group: Option&amp;lt;RawNode&amp;lt;MemStorage&amp;gt;&amp;gt;, // 接收其他节点发来的 Raft 消息 my_mailbox: Receiver&amp;lt;Message&amp;gt;, // 发送 Raft 消息给其他节点 mailboxes: HashMap&amp;lt;u64, Sender&amp;lt;Message&amp;gt;&amp;gt;, } let mut t = Instant::now(); // 在 Node 实例上运行一个循环，周期性地处理 Raft 消息、tick 和 Ready。 loop { thread::sleep(Duration::from_millis(10)); while let Ok(msg) = node.</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列文章（一）序</title>
      <link>https://pingcap.com/blog-cn/tikv-source-code-reading-1/</link>
      <pubDate>Mon, 28 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-source-code-reading-1/</guid>
      <description>TiKV 是一个支持事务的分布式 Key-Value 数据库，有很多社区开发者基于 TiKV 来开发自己的应用，譬如 titan、tidis。尤其是在 TiKV 成为 CNCF 的 Sandbox 项目之后，吸引了越来越多开发者的目光，很多同学都想参与到 TiKV 的研发中来。这时候，就会遇到两个比较大的拦路虎：
 Rust 语言：众所周知，TiKV 是使用 Rust 语言来进行开发的，而 Rust 语言的学习难度相对较高，有些人认为其学习曲线大于 C++，所以很多同学在这一步就直接放弃了。
 文档：最开始 TiKV 是作为 HTAP 数据库 TiDB 的一个底层存储引擎设计并开发出来的，属于内部系统，缺乏详细的文档，以至于同学们不知道 TiKV 是怎么设计的，以及代码为什么要这么写。
  对于第一个问题，我们内部正在制作一系列的 Rust 培训课程，由 Rust 作者以及 Rust 社区知名的开发者亲自操刀，预计会在今年第一季度对外发布。希望通过该课程的学习，大家能快速入门 Rust，使用 Rust 开发自己的应用。
而对于第二个问题，我们会启动 《TiKV 源码解析系列文章》以及 《Deep Dive TiKV 系列文章》计划，在《Deep Dive TiKV 系列文章》中，我们会详细介绍与解释 TiKV 所使用技术的基本原理，譬如 Raft 协议的说明，以及我们是如何对 Raft 做扩展和优化的。而 《TiKV 源码解析系列文章》则是会从源码层面给大家抽丝剥茧，让大家知道我们内部到底是如何实现的。我们希望，通过这两个系列，能让大家对 TiKV 有更深刻的理解，再加上 Rust 培训，能让大家很好的参与到 TiKV 的开发中来。</description>
    </item>
    
    <item>
      <title>Titan 的设计与实现</title>
      <link>https://pingcap.com/blog-cn/titan-design-and-implementation/</link>
      <pubDate>Tue, 22 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/titan-design-and-implementation/</guid>
      <description>Titan 是由 PingCAP 研发的一个基于 RocksDB 的高性能单机 key-value 存储引擎，其主要设计灵感来源于 USENIX FAST 2016 上发表的一篇论文 WiscKey。WiscKey 提出了一种高度基于 SSD 优化的设计，利用 SSD 高效的随机读写性能，通过将 value 分离出 LSM-tree 的方法来达到降低写放大的目的。
我们的基准测试结果显示，当 value 较大的时候，Titan 在写、更新和点读等场景下性能都优于 RocksDB。但是根据 RUM Conjecture，通常某些方面的提升往往是以牺牲其他方面为代价而取得的。Titan 便是以牺牲硬盘空间和范围查询的性能为代价，来取得更高的写性能。随着 SSD 价格的降低，我们认为这种取舍的意义会越来越明显。
设计目标 Titan 作为 TiKV 的一个子项目，首要的设计目标便是兼容 RocksDB。因为 TiKV 使用 RocksDB 作为其底层的存储引擎，而 TiKV 作为一个成熟项目已经拥有庞大的用户群体，所以我们需要考虑已有的用户也可以将已有的基于 RocksDB 的 TiKV 平滑地升级到基于 Titan 的 TiKV。
因此，我们总结了四点主要的设计目标：
 支持将 value 从 LSM-tree 中分离出来单独存储，以降低写放大。 已有 RocksDB 实例可以平滑地升级到 Titan，这意味着升级过程不需要人工干预，并且不会影响线上服务。 100% 兼容目前 TiKV 所使用的所有 RocksDB 的特性。 尽量减少对 RocksDB 的侵入性改动，保证 Titan 更加容易升级到新版本的 RocksDB。  架构与实现 Titan 的基本架构如下图所示：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二十四）TiDB Binlog 源码解析</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-24/</link>
      <pubDate>Tue, 15 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-24/</guid>
      <description>TiDB Binlog Overview 这篇文章不是讲 TiDB Binlog 组件的源码，而是讲 TiDB 在执行 DML/DDL 语句过程中，如何将 Binlog 数据 发送给 TiDB Binlog 集群的 Pump 组件。目前 TiDB 在 DML 上的 Binlog 用的类似 Row-based 的格式。具体 Binlog 具体的架构细节可以参看这篇 文章。
这里只描述 TiDB 中的代码实现。
DML Binlog TiDB 采用 protobuf 来编码 binlog，具体的格式可以见 binlog.proto。这里讨论 TiDB 写 Binlog 的机制，以及 Binlog 对 TiDB 写入的影响。
TiDB 会在 DML 语句提交，以及 DDL 语句完成的时候，向 pump 输出 Binlog。
Statement 执行阶段 DML 语句包括 Insert/Replace、Update、Delete，这里挑 Insert 语句来阐述，其他的语句行为都类似。首先在 Insert 语句执行完插入（未提交）之前，会把自己新增的数据记录在 binlog.TableMutation 结构体中。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二十三）Prepare/Execute 请求处理</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-23/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-23/</guid>
      <description>在之前的一篇文章《TiDB 源码阅读系列文章（三）SQL 的一生》中，我们介绍了 TiDB 在收到客户端请求包时，最常见的 Command --- COM_QUERY 的请求处理流程。本文我们将介绍另外一种大家经常使用的 Command --- Prepare/Execute 请求在 TiDB 中的处理过程。
Prepare/Execute Statement 简介 首先我们先简单回顾下客户端使用 Prepare 请求过程：
 客户端发起 Prepare 命令将带 “?” 参数占位符的 SQL 语句发送到数据库，成功后返回 stmtID。
 具体执行 SQL 时，客户端使用之前返回的 stmtID，并带上请求参数发起 Execute 命令来执行 SQL。
 不再需要 Prepare 的语句时，关闭 stmtID 对应的 Prepare 语句。
  相比普通请求，Prepare 带来的好处是：
 减少每次执行经过 Parser 带来的负担，因为很多场景，线上运行的 SQL 多是相同的内容，仅是参数部分不同，通过 Prepare 可以通过首次准备好带占位符的 SQL，后续只需要填充参数执行就好，可以做到“一次 Parse，多次使用”。
 在开启 PreparePlanCache 后可以达到“一次优化，多次使用”，不用进行重复的逻辑和物理优化过程。
 更少的网络传输，因为多次执行只用传输参数部分，并且返回结果 Binary 协议。
 因为是在执行的同时填充参数，可以防止 SQL 注入风险。</description>
    </item>
    
    <item>
      <title>写给社区的回顾和展望：TiDB 2019, Level Up!</title>
      <link>https://pingcap.com/blog-cn/for-community-tidb-2019-level-up/</link>
      <pubDate>Wed, 02 Jan 2019 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/for-community-tidb-2019-level-up/</guid>
      <description>2018 年对于 TiDB 和 PingCAP 来说是一个由少年向成年的转换的一年，如果用一个关键字来概括就是「蜕变」。在这一年很欣喜的看到 TiDB 和 TiKV 在越来越多的用户使用在了越来越广泛的场景中，作为一个刚刚 3 岁多的开源项目，没有背后强大的社区的话，是没有办法取得这样的进展的。 同时在技术上，2018 年我觉得也交出了一份令人满意的答卷，TiDB 的几个主要项目今年一共合并了 4380 个提交，这几天在整理 2018 年的 Change Log 时候，对比了一下年初的版本，这 4380 个 Commits 背后代表了什么，这里简单写一个文章总结一下。
回想起来，TiDB 是最早定位为 HTAP 的通用分布式数据库之一，如果熟悉我们的老朋友一定知道，我们最早时候一直都是定位 NewSQL，当然现在也是。但是 NewSQL 这个词有个问题，到底 New 在哪，解决了哪些问题，很难一目了然，其实一开始我们就想解决一个 MySQL 分库分表的问题，但是后来慢慢随着我们的用户越来越多，使用的场景也越来越清晰，很多用户的场景已经开始超出了一个「更大的 MySQL 」的使用范围，于是我们从实验室和学术界找到了我们觉得更加清晰的定义：HTAP，希望能构建一个融合 OLTP 和 OLAP 通用型分布式数据库。但是要达成这个目标非常复杂，我们的判断是如果不是从最底层重新设计，很难达到我们的目标，我们认为这是一条更困难但是正确的路，现在看来，这条路是走对了，而且未来会越走越快，越走越稳。
在 SQL 层这边，TiDB 选择了 MySQL 的协议兼容，一方面持续的加强语法兼容性，另一方面选择自研优化器和执行器，带来的好处就是没有任何历史负担持续优化。回顾今年最大的一个工作应该是重构了执行器框架，TiDB的 SQL 层还是经典的 Volcano 模型，我们引入了新的内存数据结构 Chunk 来批量处理多行数据，并对各个算子都实现了基于 Chunk 的迭代器接口，这个改进对于 OLAP 请求的改进非常明显，在 TiDB 的 TPC-H 测试集上能看出来（https://github.com/pingcap/docs-cn/blob/master/benchmark/tpch.md），Chunk 的引入为我们全面的向量化执行和 CodeGen 支持打下了基础。目前在 TiKV 内部对于下推算子的执行还没有使用 Chunk 改造，不过这个已经在计划中，在 TiKV 中这个改进，预期对查询性能的提升也将非常显著。</description>
    </item>
    
    <item>
      <title>TBSSQL 的那些事 | TiDB Hackathon 2018</title>
      <link>https://pingcap.com/blog-cn/tidb-hackathon-2018-06/</link>
      <pubDate>Thu, 27 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-hackathon-2018-06/</guid>
      <description>本文作者是来自 TiBoys 队的崔秋同学，他们的项目 TBSSQL 在 TiDB Hackathon 2018 中获得了一等奖。
TiDB Batch and Streaming SQL（简称 TBSSQL）扩展了 TiDB 的 SQL 引擎，支持用户以类似 StreamSQL 的语法将 Kafka、Pulsar 等外部数据源以流式表的方式接入 TiDB。通过简单的 SQL 语句，用户可以实现对流式数据的过滤，流式表与普通表的 Join（比如流式事实表与多个普通维度表），甚至通过 CREATE TABLE AS SELECT 语法将处理过的流式数据写入普通表中。此外，针对流式数据的时间属性，我们实现了基于时间窗口的聚合/排序算子，使得我们可以对流式数据进行时间维度的聚合/排序。
 序 算起来这应该是第三次参加的 Hackathon 了，第一次参加的时候还是在小西天的豌豆荚，和东旭一起，做跨平台数据传输的工具，两天一夜；第二次和奇叔一起在 3W 咖啡，又是两天一夜；这次在自己家举办 Hackathon 比赛，下定决心一定要佛性一些，本着能抱大腿就不单干的心态，迅速决定拉唐长老（唐刘）下水。接下来就计划着折腾点啥，因为我们两个前端都不怎么样，所以只能硬核一些，于是拍了两个方案。
方案一：之前跟唐长老合作过很长一段时间，我们两个对于测试质量之类的事情也都非常关注，所以想着能不能在 Chaos 系统上做一些文章，把一些前沿的测试理论和经验方法结合到系统里面来，做一套通用的分布式系统测试框架，就像 Jepsen 那样，用这套系统去测试和验证主流的开源分布式项目。
方案二：越接近于业务实时性的数据处理越有价值，不管是 Kafka/KSQL，Flink/Spark Streaming 都是在向着实时流计算领域方向进行未来的探索。TiDB 虽然已经能够支持类 Real Time OLAP 的场景，但是对于更实时的流式数据处理方面还没有合适的解决方案，不过 TiDB 具有非常好的 Scale 能力，天然的能存储海量的数据库表数据，所以在 Streaming Event 和 Table 关联的场景下具有非常明显的优势。如果在 TiDB 上能够实现一个 Streaming SQL 的引擎，实现 Batch/Streaming 的计算融合，那将会是一件非常有意思的事情。</description>
    </item>
    
    <item>
      <title>TiDB Ecosystem Tools 原理解读系列（三）TiDB-DM 架构设计与实现原理</title>
      <link>https://pingcap.com/blog-cn/tidb-ecosystem-tools-3/</link>
      <pubDate>Wed, 26 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-ecosystem-tools-3/</guid>
      <description>简介 TiDB-DM（Data Migration）是用于将数据从 MySQL/MariaDB 迁移到 TiDB 的工具。该工具既支持以全量备份文件的方式将 MySQL/MariaDB 的数据导入到 TiDB，也支持通过解析执行 MySQL/MariaDB binlog 的方式将数据增量同步到 TiDB。特别地，对于有多个 MySQL/MariaDB 实例的分库分表需要合并后同步到同一个 TiDB 集群的场景，DM 提供了良好的支持。如果你需要从 MySQL/MariaDB 迁移到 TiDB，或者需要将 TiDB 作为 MySQL/MariaDB 的从库，DM 将是一个非常好的选择。
架构设计 DM 是集群模式的，其主要由 DM-master、DM-worker 与 DM-ctl 三个组件组成，能够以多对多的方式将多个上游 MySQL 实例的数据同步到多个下游 TiDB 集群，其架构图如下：
 DM-master：管理整个 DM 集群，维护集群的拓扑信息，监控各个 DM-worker 实例的运行状态；进行数据同步任务的拆解与分发，监控数据同步任务的执行状态；在进行合库合表的增量数据同步时，协调各 DM-worker 上 DDL 的执行或跳过；提供数据同步任务管理的统一入口。
 DM-worker：与上游 MySQL 实例一一对应，执行具体的全量、增量数据同步任务；将上游 MySQL 的 binlog 拉取到本地并持久化保存；根据定义的数据同步任务，将上游 MySQL 数据全量导出成 SQL 文件后导入到下游 TiDB，或解析本地持久化的 binlog 后增量同步到下游 TiDB；编排 DM-master 拆解后的数据同步子任务，监控子任务的运行状态。
 DM-ctl：命令行交互工具，通过连接到 DM-master 后，执行 DM 集群的管理与数据同步任务的管理。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二十二）Hash Aggregation</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-22/</link>
      <pubDate>Fri, 21 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-22/</guid>
      <description>聚合算法执行原理 在 SQL 中，聚合操作对一组值执行计算，并返回单个值。TiDB 实现了 2 种聚合算法：Hash Aggregation 和 Stream Aggregation。
我们首先以 AVG 函数为例（案例参考 Stack Overflow），简述这两种算法的执行原理。
假设表 t 如下：
   列 a 列 b     1 9   1 -8   2 -7   2 6   1 5   2 4    SQL: select avg(b) from t group by a, 要求将表 t 的数据按照 a 的值分组，对每一组的 b 值计算平均值。不管 Hash 还是 Stream 聚合，在 AVG 函数的计算过程中，我们都需要维护 2 个中间结果变量 sum 和 count。Hash 和 Stream 聚合算法的执行原理如下。</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 支持 AST 还原为 SQL</title>
      <link>https://pingcap.com/blog-cn/support-ast-restore-to-sql-text/</link>
      <pubDate>Thu, 20 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/support-ast-restore-to-sql-text/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后首先会经过 parser，从文本 parse 成为 AST（抽象语法树），AST 节点与 SQL 文本结构是一一对应的，我们通过遍历整个 AST 树就可以拼接出一个与 AST 语义相同的 SQL 文本。
对 parser 不熟悉的小伙伴们可以看 TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现。
为了控制 SQL 文本的输出格式，并且为方便未来新功能的加入（例如在 SQL 文本中用 “*” 替代密码），我们引入了 RestoreFlags 并封装了 RestoreCtx 结构（相关源码）：
// `RestoreFlags` 中的互斥组: // [RestoreStringSingleQuotes, RestoreStringDoubleQuotes] // [RestoreKeyWordUppercase, RestoreKeyWordLowercase] // [RestoreNameUppercase, RestoreNameLowercase] // [RestoreNameDoubleQuotes, RestoreNameBackQuotes] // 靠前的 flag 拥有更高的优先级。 const ( RestoreStringSingleQuotes RestoreFlags = 1 &amp;lt;&amp;lt; iota ... ) // RestoreCtx is `Restore` context to hold flags and writer.</description>
    </item>
    
    <item>
      <title>TiDB Ecosystem Tools 原理解读系列（二）TiDB-Lightning Toolset 介绍</title>
      <link>https://pingcap.com/blog-cn/tidb-ecosystem-tools-2/</link>
      <pubDate>Tue, 18 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-ecosystem-tools-2/</guid>
      <description>简介 TiDB-Lightning Toolset 是一套快速全量导入 SQL dump 文件到 TiDB 集群的工具集，自 2.1.0 版本起随 TiDB 发布，速度可达到传统执行 SQL 导入方式的至少 3 倍、大约每小时 100 GB，适合在上线前用作迁移现有的大型数据库到全新的 TiDB 集群。
设计 TiDB 从 2017 年开始提供全量导入工具 Loader，它以多线程操作、错误重试、断点续传以及修改一些 TiDB 专属配置来提升数据导入速度。
然而，当我们全新初始化一个 TiDB 集群时，Loader 这种逐条 INSERT 指令在线上执行的方式从根本上是无法尽用性能的。原因在于 SQL 层的操作有太强的保证了。在整个导入过程中，TiDB 需要：
 保证 ACID 特性，需要执行完整的事务流程。
 保证各个 TiKV 服务器数据量平衡及有足够的副本，在数据增长的时候需要不断的分裂、调度 Regions。
  这些动作确保 TiDB 整段导入的期间是稳定的，但在导入完毕前我们根本不会对外提供服务，这些保证就变成多此一举了。此外，多线程的线上导入也代表资料是乱序插入的，新的数据范围会与旧的重叠。TiKV 要求储存的数据是有序的，大量的乱序写入会令 TiKV 要不断地移动原有的数据（这称为 Compaction），这也会拖慢写入过程。
TiKV 是使用 RocksDB 以 KV 对的形式储存数据，这些数据会压缩成一个个 SST 格式文件。TiDB-Lightning Toolset使用新的思路，绕过SQL层，在线下将整个 SQL dump 转化为 KV 对、生成排好序的 SST 文件，然后直接用 Ingestion 推送到 RocksDB 里面。这样批量处理的方法略过 ACID 和线上排序等耗时步骤，让我们提升最终的速度。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二十一）基于规则的优化 II</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-21/</link>
      <pubDate>Tue, 11 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-21/</guid>
      <description>在 TiDB 源码阅读系列文章（七）基于规则的优化 一文中，我们介绍了几种 TiDB 中的逻辑优化规则，包括列剪裁，最大最小消除，投影消除，谓词下推和构建节点属性，本篇将继续介绍更多的优化规则：聚合消除、外连接消除和子查询优化。
聚合消除 聚合消除会检查 SQL 查询中 Group By 语句所使用的列是否具有唯一性属性，如果满足，则会将执行计划中相应的 LogicalAggregation 算子替换为 LogicalProjection 算子。这里的逻辑是当聚合函数按照具有唯一性属性的一列或多列分组时，下层算子输出的每一行都是一个单独的分组，这时就可以将聚合函数展开成具体的参数列或者包含参数列的普通函数表达式，具体的代码实现在 rule_aggregation_elimination.go 文件中。下面举一些具体的例子。
例一：
下面这个 Query 可以将聚合函数展开成列的查询：
select max(a) from t group by t.pk; 被等价地改写成：
select a from t; 例二：
下面这个 Query 可以将聚合函数展开为包含参数列的内置函数的查询：
select count(a) from t group by t.pk; 被等价地改写成：
select if(isnull(a), 0, 1) from t; 这里其实还可以做进一步的优化：如果列 a 具有 Not Null 的属性，那么可以将 if(isnull(a), 0, 1) 直接替换为常量 1（目前 TiDB 还没做这个优化，感兴趣的同学可以来贡献一个 PR）。
另外提一点，对于大部分聚合函数，参数的类型和返回结果的类型一般是不同的，所以在展开聚合函数的时候一般会在参数列上构造 cast 函数做类型转换，展开后的表达式会保存在作为替换 LogicalAggregation 算子的 LogicalProjection 算子中。</description>
    </item>
    
    <item>
      <title>TiDB Ecosystem Tools 原理解读系列（一）：TiDB-Binlog 架构演进与实现原理</title>
      <link>https://pingcap.com/blog-cn/tidb-ecosystem-tools-1/</link>
      <pubDate>Fri, 07 Dec 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-ecosystem-tools-1/</guid>
      <description>简介 TiDB-Binlog 组件用于收集 TiDB 的 binlog，并提供实时备份和同步功能。该组件在功能上类似于 MySQL 的主从复制，MySQL 的主从复制依赖于记录的 binlog 文件，TiDB-Binlog 组件也是如此，主要的不同点是 TiDB 是分布式的，因此需要收集各个 TiDB 实例产生的 binlog，并按照事务提交的时间排序后才能同步到下游。如果你需要部署 TiDB 集群的从库，或者想订阅 TiDB 数据的变更输出到其他的系统中，TiDB-Binlog 则是必不可少的工具。
架构演进 TiDB-Binlog 这个组件已经发布了 2 年多时间，经历过几次架构演进，去年十月到现在大规模使用的是 Kafka 版本，架构图如下：
Kafka 版本的 TiDB-Binlog 主要包括两个组件：
Pump：一个守护进程，在每个 TiDB 主机的后台运行。其主要功能是实时记录 TiDB 产生的 binlog 并顺序写入 Kafka 中。
Drainer： 从 Kafka 中收集 binlog，并按照 TiDB 中事务的提交顺序转化为指定数据库兼容的 SQL 语句或者指定格式的数据，最后同步到目的数据库或者写到顺序文件。
这个架构的工作原理为：
 TiDB 需要与 Pump 绑定，即 TiDB 实例只能将它生成的 binlog 发送到一个指定的 Pump 中；
 Pump 将 binlog 先写到本地文件，再异步地写入到 Kafka；</description>
    </item>
    
    <item>
      <title>TiDB 2.1 GA Release Notes</title>
      <link>https://pingcap.com/blog-cn/tidb-21-ga-release-notes/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-21-ga-release-notes/</guid>
      <description>2018 年 11 月 30 日，TiDB 发布 2.1 GA 版。相比 2.0 版本，该版本对系统稳定性、性能、兼容性、易用性做了大量改进。
TiDB SQL 优化器  优化 Index Join 选择范围，提升执行性能 优化 Index Join 外表选择，使用估算的行数较少的表作为外表 扩大 Join Hint TIDB_SMJ 的作用范围，在没有合适索引可用的情况下也可使用 Merge Join 加强 Join Hint TIDB_INLJ 的能力，可以指定 Join 中的内表 优化关联子查询，包括下推 Filter 和扩大索引选择范围，部分查询的效率有数量级的提升 支持在 UPDATE 和 DELETE 语句中使用 Index Hint 和 Join Hint 支持更多函数下推：ABS/CEIL/FLOOR/IS TRUE/IS FALSE 优化内建函数 IF 和 IFNULL 的常量折叠算法 优化 EXPLAIN 语句输出格式, 使用层级结构表示算子之间的上下游关系  SQL 执行引擎  重构所有聚合函数，提升 Stream 和 Hash 聚合算子的执行效率 实现并行 Hash Aggregate 算子，部分场景下有 350% 的性能提升 实现并行 Project 算子，部分场景有 74% 的性能提升 并发地读取 Hash Join 的 Inner 表和 Outer 表的数据，提升执行性能 优化 REPLACE INTO 语句的执行速度，性能提升 10x 优化时间类型的内存占用，时间类型数据的内存使用降低为原来的一半 优化点查的查询性能, Sysbench 点查效率提升 60% TiDB 插入和更新宽表，性能提升接近 20 倍 支持在配置文件中设置单个查询的内存使用上限 优化 Hash Join 的执行过程，当 Join 类型为 Inner Join 或者 Semi Join 时，如果内表为空，不再读取外表数据，快速返回结果 支持 EXPLAIN ANALYZE 语句，用于查看 Query 执行过程中各个算子的运行时间，返回结果行数等运行时统计信息  统计信息  支持只在一天中的某个时间段开启统计信息自动 ANALYZE 的功能</description>
    </item>
    
    <item>
      <title>TiDB 2.1：Battle-Tested for an Unpredictable World</title>
      <link>https://pingcap.com/blog-cn/tidb-21-battle-tested-for-an-unpredictable-world/</link>
      <pubDate>Fri, 30 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-21-battle-tested-for-an-unpredictable-world/</guid>
      <description>TiDB 是由 PingCAP 开发的分布式关系型数据库，今天我们很高兴地推出 TiDB 2.1 正式版，提供更丰富的功能、更好的性能以及更高的可靠性。
回顾 2.0 版本 今年 4 月份我们发布了 TiDB 2.0 版本，提升了稳定性、性能以及可运维性，这个版本在接下来的半年中得到了广泛的关注和使用。
迄今为止 TiDB 已经在 数百家用户 的生产环境中稳定运行，涉及互联网、游戏、金融、保险、制造业、银行、证券等多个行业，最大集群包含数百个节点及数百 TB 数据，业务场景包含纯 OLTP、纯 OLAP 以及混合负载。另外，既有使用 TiDB 当做关系数据库的场景，也有只用 TiKV 作为分布式 Key Value 存储的场景。
这几个月，在这些场景中，我们亲历了跨机房容灾需求、亲历了几十万级别的高吞吐业务、亲历了双十一的流量激增、亲历了高并发点查、高并发写入与上百行复杂 SQL 的混合负载、见到过多次的硬件/网络故障、见到过操作系统内核/编译器的 Bug。
简而言之，我们的世界充满了未知，而分布式关系型数据库这样一种应用广泛、功能丰富且非常关键的基础软件，最大的困难就是这些“未知”。在 2.1 版本中，我们引入了不少新的特性来抵御这些未知，适配各种复杂的场景，提升性能和稳定性，帮助我们的用户更好地支撑复杂的业务。
新特性 更全面的 Optimizer 在 2.1 版本中，我们对 TiDB 的 Cost-based Optimizer 做了改进，希望这个优化器能够处理各种复杂的 Query，尽量少的需要人工介入去处理慢 SQL。例如对 Index Join 选择索引、外表的优化，对关联子查询的优化，显著地提升了复杂 SQL 的查询效率。
当然，除了自动的查询优化之外，2.1 也增加了更多的手动干预机制，比如对 Join 算子的 Hint、Update/Delete 语句的 Hint。用户可以在优化器没有指定合适的计划时，手动干预结果或者是用来确保查询计划稳定。
更强大的执行引擎 在 2.1 版本中，我们对部分物理算子的执行效率进行了优化，特别是对 Hash Aggregation 和 Projection 这两个算子进行了并行化改造，另外重构了聚合算子的运行框架，支持向量化计算。</description>
    </item>
    
    <item>
      <title>TiDB 开源社区指南（上）</title>
      <link>https://pingcap.com/blog-cn/tidb-community-guide-1/</link>
      <pubDate>Fri, 09 Nov 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-community-guide-1/</guid>
      <description>本系列文章旨在帮助社区开发者了解 TiDB 项目的全貌，更好的参与 TiDB 项目开发。大致会分两个角度进行描述：
 从社区参与者的角度描述如何更好的参与 TiDB 项目开发；
 从 PingCAP 内部团队的角度展示 TiDB 的开发流程，包括版本规划、开发流程、Roadmap 制定等。
  希望通过一内一外两条线的描述，读者能在技术之外对 TiDB 有更全面的了解。本篇将聚焦在社区参与者的角度进行描述，也就是“外线”。
了解 TiDB 参与一个开源项目第一步总是了解它，特别是对 TiDB 这样一个大型的项目，了解的难度比较高，这里列出一些相关资料，帮助 newcomers 从架构设计到工程实现细节都能有所了解：
 Overview How we build TiDB TiDB 源码阅读系列文章 Deep Dive TiKV (Work-In-Process)  当然，最高效地熟悉 TiDB 的方式还是使用它，在某些场景下遇到了问题或者是想要新的 feature，去跟踪代码，找到相关的代码逻辑，在这个过程中很容易对相关模块有了解，不少 Contributor 就是这样完成了第一次贡献。 我们还有一系列的 Infra Meetup，大约两周一次，如果方便到现场的同学可以听到这些高质量的 Talk。除了北京之外，其他的城市（上海、广州、成都、杭州）也开始组织 Meetup，方便更多的同学到现场来面基。
发现可以参与的事情 对 TiDB 有基本的了解之后，就可以选一个入手点。在 TiDB repo 中我们给一些简单的 issue 标记了 for-new-contributors 标签，这些 issue 都是我们评估过容易上手的事情，可以以此为切入点。另外我们也会定期举行一些活动，把框架搭好，教程写好，新 Contributor 按照固定的模式即可完成某一特性开发。
当然除了那些标记为 for-new-contributors 的 issue 之外，也可以考虑其他的 issue，标记为 help-wanted 标签的 issue 可以优先考虑。除此之外的 issue 可能会比较难解决，需要对 TiDB 有较深入的了解或者是对完成时间有较高的要求，不适合第一次参与的同学。</description>
    </item>
    
    <item>
      <title>PingCAP University · TiDB DBA 官方培训认证计划启动</title>
      <link>https://pingcap.com/blog-cn/pingcap-university-tidb-dba-plan/</link>
      <pubDate>Tue, 30 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pingcap-university-tidb-dba-plan/</guid>
      <description>伴随着产品的成熟，TiDB 在越来越多样化的应用场景中落地。在落地过程中，大家遇到问题会寻求官方的答疑和支持，但由于咨询量很大，我们有时无法及时响应。因此，为了赋能社区，提升社区用户满意度，避免因测试用户过多官方无法及时响应的问题，同时打造活跃的 TiDB 技术社区，培养熟悉分布式系统、能独立运维 TiDB 的一流 NewSQL 人才，我们宣布正式成立 PingCAP University。
PingCAP University 是 PingCAP 官方设立的对企业和个人进行 TiDB 全线产品培训并认证的部门，其培训讲师团队由来自 PingCAP 官方的资深解决方案架构师、顶尖核心技术研发工程师和高级资深 TiDB DBA 组成，拥有丰富且专业的 TiDB 实践经验和培训经验。
PingCAP University 也在今天正式启动 TiDB DBA 官方培训认证计划。
通过该培训认证计划，大家可以：
 深度理解 TiDB 架构、原理及最佳实践，具备独立部署、运维和调优 TiDB 的能力
 提升分布式计算和存储领域的技术前沿视野
 获得来自 PingCAP 官方的专业技术能力认可，提升个人技术竞争力
  培训特色  理论与实践结合，强调动手能力（实践超过 50%），提供累计 4 个半天实战
 课程滚动更新，包含大量前沿技术解读及实践分享
  TiDB DBA 官方培训认证总览  初级 TiDB DBA：PCTA（PingCAP Certified TiDB Associate）培训及认证
 高级 TiDB DBA：PCTP（PingCAP Certified TiDB Professional） 培训及认证</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二十）Table Partition</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-20/</link>
      <pubDate>Fri, 26 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-20/</guid>
      <description>Table Partition 什么是 Table Partition Table Partition 是指根据一定规则，将数据库中的一张表分解成多个更小的容易管理的部分。从逻辑上看只有一张表，但是底层却是由多个物理分区组成。相信对有关系型数据库使用背景的用户来说可能并不陌生。
TiDB 正在支持分区表这一特性。在 TiDB 中分区表是一个独立的逻辑表，但是底层由多个物理子表组成。物理子表其实就是普通的表，数据按照一定的规则划分到不同的物理子表类内。程序读写的时候操作的还是逻辑表名字，TiDB 服务器自动去操作分区的数据。
分区表有什么好处？  优化器可以使用分区信息做分区裁剪。在语句中包含分区条件时，可以只扫描一个或多个分区表来提高查询效率。
 方便地进行数据生命周期管理。通过创建、删除分区、将过期的数据进行 高效的归档，比使用 Delete 语句删除数据更加优雅，打散写入热点，将一个表的写入分散到多个物理表，使得负载分散开，对于存在 Sequence 类型数据的表来说（比如 Auto Increament ID 或者是 create time 这类的索引）可以显著地提升写入吞吐。
  分区表的限制  TiDB 默认一个表最多只能有 1024 个分区 ，默认是不区分表名大小写的。
 Range, List, Hash 分区要求分区键必须是 INT 类型，或者通过表达式返回 INT 类型。但 Key 分区的时候，可以使用其他类型的列（BLOB，TEXT 类型除外）作为分区键。
 如果分区字段中有主键或者唯一索引的列，那么有主键列和唯一索引的列都必须包含进来。
 TiDB 的分区适用于一个表的所有数据和索引。不能只对表数据分区而不对索引分区，也不能只对索引分区而不对表数据分区，也不能只对表的一部分数据分区。
  常见分区表的类型  Range 分区：按照分区表达式的范围来划分分区。通常用于对分区键需要按照范围的查询，分区表达式可以为列名或者表达式 ，下面的 employees 表当中 p0, p1, p2, p3 表示 Range 的访问分别是 (min, 1991), [1991, 1996), [1996, 2001), [2001, max) 这样一个范围。</description>
    </item>
    
    <item>
      <title>线性一致性和 Raft</title>
      <link>https://pingcap.com/blog-cn/linearizability-and-raft/</link>
      <pubDate>Thu, 18 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/linearizability-and-raft/</guid>
      <description>在讨论分布式系统时，共识算法（Consensus algorithm）和一致性（Consistency）通常是讨论热点，两者的联系很微妙，很容易搞混。一些常见的误解：使用了 Raft [0] 或者 paxos 的系统都是线性一致的（Linearizability [1]，即强一致），其实不然，共识算法只能提供基础，要实现线性一致还需要在算法之上做出更多的努力。以 TiKV 为例，它的共识算法是 Raft，在 Raft 的保证下，TiKV 提供了满足线性一致性的服务。
本篇文章会讨论一下线性一致性和 Raft，以及 TiKV 针对前者的一些优化。
线性一致性 什么是一致性，简单的来说就是评判一个并发系统正确与否的标准。线性一致性是其中一种，CAP [2] 中的 C 一般就指它。什么是线性一致性，或者说怎样才能达到线性一致？在回答这个问题之前先了解一些背景知识。
背景知识 为了回答上面的问题，我们需要一种表示方法描述分布式系统的行为。分布式系统可以抽象成几个部分:
 Client Server Events  Invocation Response  Operations  Read Write   一个分布式系统通常有两种角色，Client 和 Server。Client 通过发起请求来获取 Server 的服务。一次完整请求由两个事件组成，Invocation（以下简称 Inv）和 Response（以下简称 Resp）。一个请求中包含一个 Operation，有两种类型 Read 和 Write，最终会在 Server 上执行。
说了一堆不明所以的概念，现在来看如何用这些表示分布式系统的行为。
上图展示了 Client A 的一个请求从发起到结束的过程。变量 x 的初始值是 1，“x R() A” 是一个事件 Inv 意思是 A 发起了读请求，相应的 “x OK(1) A” 就是事件 Resp，意思是 A 读到了 x 且值为 1，Server 执行读操作（Operation）。</description>
    </item>
    
    <item>
      <title>TiKV 是如何存取数据的</title>
      <link>https://pingcap.com/blog-cn/how-tikv-store-get-data/</link>
      <pubDate>Thu, 11 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-tikv-store-get-data/</guid>
      <description>本文会详细的介绍 TiKV 是如何处理读写请求的，通过该文档，同学们会知道 TiKV 是如何将一个写请求包含的数据更改存储到系统，并且能读出对应的数据的。
基础知识 在开始之前，我们需要介绍一些基础知识，便于大家去理解后面的流程。
Raft TiKV 使用 Raft 一致性算法来保证数据的安全，默认提供的是三个副本支持，这三个副本形成了一个 Raft Group。
当 Client 需要写入某个数据的时候，Client 会将操作发送给 Raft Leader，这个在 TiKV 里面我们叫做 Propose，Leader 会将操作编码成一个 entry，写入到自己的 Raft Log 里面，这个我们叫做 Append。
Leader 也会通过 Raft 算法将 entry 复制到其他的 Follower 上面，这个我们叫做 Replicate。Follower 收到这个 entry 之后也会同样进行 Append 操作，顺带告诉 Leader Append 成功。
当 Leader 发现这个 entry 已经被大多数节点 Append，就认为这个 entry 已经是 Committed 的了，然后就可以将 entry 里面的操作解码出来，执行并且应用到状态机里面，这个我们叫做 Apply。
在 TiKV 里面，我们提供了 Lease Read，对于 Read 请求，会直接发给 Leader，如果 Leader 确定自己的 lease 没有过期，那么就会直接提供 Read 服务，这样就不用走一次 Raft 了。如果 Leader 发现 lease 过期了，就会强制走一次 Raft 进行续租，然后在提供 Read 服务。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十九）tikv-client（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</link>
      <pubDate>Wed, 26 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-19/</guid>
      <description>上篇文章 中，我们介绍了数据读写过程中 tikv-client 需要解决的几个具体问题，本文将继续介绍 tikv-client 里的两个主要的模块——负责处理分布式计算的 copIterator 和执行二阶段提交的 twoPhaseCommitter。
copIterator copIterator 是什么 在介绍 copIterator 的概念之前，我们需要简单回顾一下前面 TiDB 源码阅读系列文章（六）中讲过的 distsql 和 coprocessor 的概念以及它们和 SQL 语句的关系。
tikv-server 通过 coprocessor 接口，支持部分 SQL 层的计算能力，大部分只涉及单表数据的常用的算子都可以下推到 tikv-server 上计算，计算下推以后，从存储引擎读取的数据虽然是一样的多，但是通过网络返回的数据会少很多，可以大幅节省序列化和网络传输的开销。
distsql 是位于 SQL 层和 coprocessor 之间的一层抽象，它把下层的 coprocessor 请求封装起来对上层提供一个简单的 Select 方法。执行一个单表的计算任务。最上层的 SQL 语句可能会包含 JOIN，SUBQUERY 等复杂算子，涉及很多的表，而 distsql 只涉及到单个表的数据。一个 distsql 请求会涉及到多个 region，我们要对涉及到的每一个 region 执行一次 coprocessor 请求。
所以它们的关系是这样的，一个 SQL 语句包含多个 distsql 请求，一个 distsql 请求包含多个 coprocessor 请求。
copIterator 的任务就是实现 distsql 请求，执行所有涉及到的 coprocessor 请求，并依次返回结果。</description>
    </item>
    
    <item>
      <title>TiKV 集群版本的安全迁移</title>
      <link>https://pingcap.com/blog-cn/tikv-cluster-migration/</link>
      <pubDate>Wed, 19 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-cluster-migration/</guid>
      <description>问题描述 在 TiDB 的产品迭代中，不免会碰到一些兼容性问题出现。通常协议上的兼容性 protobuf 已经能帮我们处理的很好，在进行功能开发，性能优化时，通常会保证版本是向后兼容的，但并不保证向前兼容性，因此，当集群中同时有新旧版本节点存在时，旧版本不能兼容新版本的特性，就有可能造成该节点崩溃，影响集群可用性，甚至丢失数据。目前在有不兼容的版本升级时，会要求进行离线升级，但这会影响到服务，我们需要一个适合的机制来进行不停服务的升级。因此我们需要在进行滚动升级时，让这些不能保证整个集群的向后兼容性的功能不被启用。只有在保证集群中所有节点都已经升级完成后，我们才安全的启用这些功能。
常见的当我们对引入新的 RaftCommand 的时候，旧版本的 TiKV 并不能识别新的添加的 RaftCommand，对于不能认知的 RaftCommand TiKV 有不同的处理，可能会报错退出或忽略。比如为了支持 Raft Learner, 在 raftpb 里对添加新的 ConfChange 类型。 当 PD 在进行 Region 调度时，会先发送 AddLearner 到 TiKV 上，接受到这个命令的肯定是这个 Region 的 Leader，在进行一系列检查后，会将该命令 Proposal, 而 Follwer 如果是旧版本的话，在 Apply 这条 Command 就会出错。而在滚动升级时，很有可能存在 Leader 是新版本，Follwer 是老版本的情况。
引入版本检查机制 TiDB 的版本定义是遵循 Semver 的版本规则的。版本格式一般由主版本号（Major），次版本号（Minor），修订号（Patch），版本号递增规则如下：
 主版本号：当进行了不兼容的 API 修改。 次版本号：当做了向下兼容的功能性新增。 修订号：当做了向下兼容的问题修正。  先行版本号（PreRelase）及版本编译信息可以加到“主版本号.次版本号.修订号”的后面，作为延伸。比如 TiDB 目前的版本是 2.1.0-beta，先行版号为 beta 版。
在此之前，集群并没有版本的概念，虽然每个组件都有各自的版本信息，但各个节点的各自组件的版本都可以任意的。没有一个管理机制可以管理或查看所有组件的版本信息。为了解决滚动升级过程中存在多个版本的兼容性问题，这里引入集群版本的概念，并由 TiDB 集群的中心节点 PD 来进行管理和检查。
具体实现 1.</description>
    </item>
    
    <item>
      <title>使用 TiKV 构建分布式类 Redis 服务</title>
      <link>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</link>
      <pubDate>Fri, 07 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/use-tikv-to-build-distributed-redis-service/</guid>
      <description>什么是 Redis Redis 是一个开源的，高性能的，支持多种数据结构的内存数据库，已经被广泛用于数据库，缓存，消息队列等领域。它有着丰富的数据结构支持，譬如 String，Hash，Set 和 Sorted Set，用户通过它们能构建自己的高性能应用。
Redis 非常快，没准是世界上最快的数据库了，它虽然使用内存，但也提供了一些持久化机制以及异步复制机制来保证数据的安全。
Redis 的不足 Redis 非常酷，但它也有一些问题：
 内存很贵，而且并不是无限容量的，所以我们不可能将大量的数据存放到一台机器。 异步复制并不能保证 Redis 的数据安全。 Redis 提供了 transaction mode，但其实并不满足 ACID 特性。 Redis 提供了集群支持，但也不能支持跨多个节点的分布式事务。  所以有时候，我们需要一个更强大的数据库，虽然在延迟上面可能赶不上 Redis，但也有足够多的特性，譬如：
 丰富的数据结构 高吞吐，能接受的延迟 强数据一致 水平扩展 分布式事务  为什么选择 TiKV 大约 4 年前，我开始解决上面提到的 Redis 遇到的一些问题。为了让数据持久化，最直观的做法就是将数据保存到硬盘上面，而不是在内存里面。所以我开发了 LedisDB，一个使用 Redis 协议，提供丰富数据结构，但将数据放在 RocksDB 的数据库。LedisDB 并不是完全兼容 Redis，所以后来，我和其他同事继续创建了 RebornDB，一个完全兼容 Redis 的数据库。 无论是 LedisDB 还是 RebornDB，因为他们都是将数据放在硬盘，所以能存储更大量的数据。但它们仍然不能提供 ACID 的支持，另外，虽然我们可以通过 codis 去提供集群的支持，我们也不能很好的支持全局的分布式事务。
所以我们需要另一种方式，幸运的是，我们有 TiKV。
TiKV 是一个高性能，支持分布式事务的 key-value 数据库。虽然它仅仅提供了简单的 key-value API，但基于 key-value，我们可以构造自己的逻辑去创建更强大的应用。譬如，我们就构建了 TiDB ，一个基于 TiKV 的，兼容 MySQL 的分布式关系型数据库。TiDB 通过将 database 的 schema 映射到 key-value 来支持了相关 SQL 特性。所以对于 Redis，我们也可以采用同样的办法 - 构建一个支持 Redis 协议的服务，将 Redis 的数据结构映射到 key-value 上面。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十八）tikv-client（上）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</link>
      <pubDate>Thu, 06 Sep 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-18/</guid>
      <description>在整个 SQL 执行过程中，需要经过 Parser，Optimizer，Executor，DistSQL 这几个主要的步骤，最终数据的读写是通过 tikv-client 与 TiKV 集群通讯来完成的。
为了完成数据读写的任务，tikv-client 需要解决以下几个具体问题：
 如何定位到某一个 key 或 key range 所在的 TiKV 地址？
 如何建立和维护和 tikv-server 之间的连接？
 如何发送 RPC 请求？
 如何处理各种错误？
 如何实现分布式读取多个 TiKV 节点的数据？
 如何实现 2PC 事务？
  我们接下来就对以上几个问题逐一解答，其中 5、6 会在下篇中介绍。
如何定位 key 所在的 tikv-server 我们需要回顾一下之前 《三篇文章了解 TiDB 技术内幕——说存储》 这篇文章中介绍过的一个重要的概念：Region。
TiDB 的数据分布是以 Region 为单位的，一个 Region 包含了一个范围内的数据，通常是 96MB 的大小，Region 的 meta 信息包含了 StartKey 和 EndKey 这两个属性。当某个 key &amp;gt;= StartKey &amp;amp;&amp;amp; key &amp;lt; EndKey 的时候，我们就知道了这个 key 所在的 Region，然后我们就可以通过查找该 Region 所在的 TiKV 地址，去这个地址读取这个 key 的数据。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十七）DDL 源码解析</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</link>
      <pubDate>Mon, 27 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-17/</guid>
      <description>DDL 是数据库非常核心的组件，其正确性和稳定性是整个 SQL 引擎的基石，在分布式数据库中，如何在保证数据一致性的前提下实现无锁的 DDL 操作是一件有挑战的事情。本文首先会介绍 TiDB DDL 组件的总体设计，介绍如何在分布式场景下支持无锁 schema 变更，描述这套算法的大致流程，然后详细介绍一些常见的 DDL 语句的源码实现，包括 create table、add index、drop column、drop table 这四种。
DDL in TiDB TiDB 的 DDL 通过实现 Google F1 的在线异步 schema 变更算法，来完成在分布式场景下的无锁，在线 schema 变更。为了简化设计，TiDB 在同一时刻，只允许一个节点执行 DDL 操作。用户可以把多个 DDL 请求发给任何 TiDB 节点，但是所有的 DDL 请求在 TiDB 内部是由 owner 节点的 worker 串行执行的。
 worker：每个节点都有一个 worker 用来处理 DDL 操作。 owner：整个集群中只有一个节点能当选 owner，每个节点都可能当选这个角色。当选 owner 后的节点 worker 才有处理 DDL 操作的权利。owner 节点的产生是用 Etcd 的选举功能从多个 TiDB 节点选举出 owner 节点。owner 是有任期的，owner 会主动维护自己的任期，即续约。当 owner 节点宕机后，其他节点可以通过 Etcd 感知到并且选举出新的 owner。  这里只是简单概述了 TiDB 的 DDL 设计，下两篇文章详细介绍了 TiDB DDL 的设计实现以及优化，推荐阅读：</description>
    </item>
    
    <item>
      <title>TiDB Operator，让 TiDB 成为真正的 Cloud-Native 数据库</title>
      <link>https://pingcap.com/blog-cn/tidb-operator-introduction/</link>
      <pubDate>Wed, 22 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-operator-introduction/</guid>
      <description>TiDB Operator 是 TiDB 在 Kubernetes 平台上的自动化部署运维工具。目前，TiDB Operator 已正式开源（pingcap/tidb-operator）。借助 TiDB Operator，TiDB 可以无缝运行在公有云厂商提供的 Kubernetes 平台上，让 TiDB 成为真正的 Cloud-Native 数据库。
要了解 TiDB Operator，首先需要对 TiDB 和 Kubernetes 有一定了解，相信长期以来一直关注 TiDB 的同学可能对 TiDB 已经比较熟悉了。本文将首先简单介绍一下 TiDB 和 Kubernetes，聊一聊为什么我们要做 TiDB Operator，然后讲讲如何快速体验 TiDB Operator，以及如何参与到 TiDB Operator 项目中来成为 Contributor。
TiDB 和 Kubernetes 简介 TiDB 作为一个开源的分布式数据库产品，具有多副本强一致性的同时能够根据业务需求非常方便的进行弹性伸缩，并且扩缩容期间对上层业务无感知。TiDB 包括三大核心组件：TiDB/TiKV/PD。  TiDB Server：主要负责 SQL 的解析器和优化器，它相当于计算执行层，同时也负责客户端接入和交互。
 TiKV Server：是一套分布式的 Key-Value 存储引擎，它承担整个数据库的存储层，数据的水平扩展和多副本高可用特性都是在这一层实现。
 PD Server：相当于分布式数据库的大脑，一方面负责收集和维护数据在各个 TiKV 节点的分布情况，另一方面 PD 承担调度器的角色，根据数据分布状况以及各个存储节点的负载来采取合适的调度策略，维持整个系统的平衡与稳定。
  上面的这三个组件，每个角色都是一个多节点组成的集群，所以最终 TiDB 的架构看起来是这样的。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十六）INSERT 语句详解</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</link>
      <pubDate>Fri, 17 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-16/</guid>
      <description>在之前的一篇文章 《TiDB 源码阅读系列文章（四）INSERT 语句概览》 中，我们已经介绍了 INSERT 语句的大体流程。为什么需要为 INSERT 单独再写一篇？因为在 TiDB 中，单纯插入一条数据是最简单的情况，也是最常用的情况；更为复杂的是在 INSERT 语句中设定各种行为，比如，对于 Unique Key 冲突的情况应如何处理：是报错？是忽略当前插入的数据？还是覆盖已有数据？所以，这篇会为大家继续深入介绍 INSERT 语句。
本文将首先介绍在 TiDB 中的 INSERT 语句的分类，以及各语句的语法和语义，然后分别介绍五种 INSERT 语句的源码实现。
INSERT 语句的种类 从广义上讲，TiDB 有以下六种 INSERT 语句：
 Basic INSERT
 INSERT IGNORE
 INSERT ON DUPLICATE KEY UPDATE
 INSERT IGNORE ON DUPLICATE KEY UPDATE
 REPLACE
 LOAD DATA
  这六种语句理论上都属于 INSERT 语句。
第一种，Basic INSERT，即是最普通的 INSERT 语句，语法 INSERT INTO VALUES ()，语义为插入一条语句，若发生唯一约束冲突（主键冲突、唯一索引冲突），则返回执行失败。
第二种，语法 INSERT IGNORE INTO VALUES ()，是当 INSERT 的时候遇到唯一约束冲突后，忽略当前 INSERT 的行，并记一个 warning。当语句执行结束后，可以通过 SHOW WARNINGS 看到哪些行没有被插入。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十五）Sort Merge Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</link>
      <pubDate>Tue, 07 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-15/</guid>
      <description>什么是 Sort Merge Join 在开始阅读源码之前, 我们来看看什么是 Sort Merge Join (SMJ)，定义可以看 wikipedia。简单说来就是将 Join 的两个表，首先根据连接属性进行排序，然后进行一次扫描归并, 进而就可以得出最后的结果。这个算法最大的消耗在于对内外表数据进行排序，而当连接列为索引列时，我们可以利用索引的有序性避免排序带来的消耗, 所以通常在查询优化器中，连接列为索引列的情况下可以考虑选择使用 SMJ。
TiDB Sort Merge Join 实现 执行过程 TiDB 的实现代码在 tidb/executor/merge_join.go 中 MergeJoinExec.NextChunk 是这个算子的入口。下面以 SELECT * FROM A JOIN B ON A.a = B.a 为例，对 SMJ 执行过程进行简述，假设此时外表为 A，内表为 B，join-keys 为 a，A，B 表的 a 列上都有索引：
 顺序读取外表 A 直到 join-keys 中出现另外的值，把相同 keys 的行放入数组 a1，同样的规则读取内表 B，把相同 keys 的行放入数组 a2。如果外表数据或者内表数据读取结束，退出。
 从 a1 中读取当前第一行数据，设为 v1。从 a2 中读取当前第一行数据，设为 v2。</description>
    </item>
    
    <item>
      <title>三十分钟成为 Contributor | 为 TiKV 添加 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</link>
      <pubDate>Wed, 01 Aug 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/30mins-become-contributor-of-tikv/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后经过 parser 生成 AST（抽象语法树），再经过 Query Optimizer 生成执行计划，执行计划切分成很多子任务，这些子任务以表达式的方式最后下推到底层的各个 TiKV 来执行。
图 1
如图 1，当 TiDB 收到来自客户端的查询请求
select count(*) from t where a + b &amp;gt; 5
时，执行顺序如下：
 TiDB 对 SQL 进行解析，组织成对应的表达式，下推给 TiKV
 TiKV 收到请求后，循环以下过程
 获取下一行完整数据，并按列解析
 使用参数中的 where 表达式对数据进行过滤
 若上一条件符合，进行聚合计算
  TiKV 向 TiDB 返回聚合计算结果
 TiDB 对所有涉及的结果进行二次聚合，返回给客户端
  这里的 where 条件便是以表达式树的形式下推给 TiKV。在此之前 TiDB 只会向 TiKV 下推一小部分简单的表达式，比如取出某一个列的某个数据类型的值，简单数据类型的比较操作，算术运算等。为了充分利用分布式集群的资源，进一步提升 SQL 在整个集群的执行速度，我们需要将更多种类的表达式下推到 TiKV 来运行，其中的一大类就是 MySQL built-in 函数。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十四）统计信息（下）</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</link>
      <pubDate>Wed, 18 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-14/</guid>
      <description>在 统计信息（上） 中，我们介绍了统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价，本篇将会结合原理介绍 TiDB 的源码实现。
文内会先介绍直方图和 Count-Min(CM) Sketch 的数据结构，然后介绍 TiDB 是如何实现统计信息的查询、收集以及更新的。
数据结构定义 直方图的定义可以在 histograms.go 中找到，值得注意的是，对于桶的上下界，我们使用了在 《TiDB 源码阅读系列文章（十）Chunk 和执行框架简介》 中介绍到 Chunk 来存储，相比于用 Datum 的方式，可以减少内存分配开销。
CM Sketch 的定义可以在 cmsketch.go 中找到，比较简单，包含了 CM Sketch 的核心——二维数组 table，并存储了其深度与宽度，以及总共插入的值的数量，当然这些都可以直接从 table 中得到。
除此之外，对列和索引的统计信息，分别使用了 Column 和 Index 来记录，主要包含了直方图，CM Sketch 等。 统计信息创建 在执行 analyze 语句时，TiDB 会收集直方图和 CM Sketch 的信息。在执行 analyze 命令时，会先将需要 analyze 的列和索引在 builder.go 中切分成不同的任务，然后在 analyze.go 中将任务下推至 TiKV 上执行。由于在 TiDB 中也包含了 TiKV 部分的实现，因此在这里还是会以 TiDB 的代码来介绍。在这个部分中，我们会着重介绍直方图的创建。
列直方图的创建 在统计信息（上）中提到，在建立列直方图的时候，会先进行抽样，然后再建立直方图。
在 collect 函数中，我们实现了蓄水池抽样算法，用来生成均匀抽样集合。由于其原理和代码都比较简单，在这里不再介绍。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十三）索引范围计算简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</link>
      <pubDate>Thu, 12 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-13/</guid>
      <description>简述 在数据库中处理查询请求时，如果可以尽早的将无关数据过滤掉，那么后续的算子就可以少做无用功，提升整个 SQL 的执行效率。过滤数据最常用的手段是使用索引，TiDB 的优化器也会尽量采用索引过滤的方式处理请求，利用索引有序的特点来提升查询效率。比如当查询条件为 a = 1 时，如果 a 这一列上有索引，我们就可以利用索引很快的把满足 a = 1 的数据拿出来，而不需要逐行检查 a 的值是否为 1。当然是否会选择索引过滤也取决于代价估算。
索引分为单列索引和多列索引（组合索引），筛选条件也往往不会是简单的一个等值条件，可能是非常复杂的条件组合。TiDB 是如何分析这些复杂条件，来得到这些条件在对应的索引上的逻辑区间范围（range），就是本文要介绍的内容。
关于 TiDB 如何构建索引，如何存储索引数据，希望读者能够有基本的了解（参考阅读：三篇文章了解 TiDB 技术内幕 - 说计算 ）。
这里是一个例子，展示这里所说的索引范围计算是做什么的，建表语句和查询语句如下：
CREATE TABLE t (a int primary key, b int, c int); select * from t where ((a &amp;gt; 1 and a &amp;lt; 5 and b &amp;gt; 2) or (a &amp;gt; 8 and a &amp;lt; 10 and c &amp;gt; 3)) and d = 5; 计算索引逻辑区间范围的流程如下：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十二）统计信息(上)</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</link>
      <pubDate>Thu, 05 Jul 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-12/</guid>
      <description>在 TiDB 里，SQL 优化的过程可以分为逻辑优化和物理优化两个部分，在物理优化阶段需要为逻辑查询计划中的算子估算运行代价，并选择其中代价最低的一条查询路径作为最终的查询计划。这里非常关键的一点是如何估算查询代价，本文所介绍的统计信息是这个估算过程的核心模块。
这部分内容非常复杂，所以会分成两篇文章来介绍。本篇文章介绍统计信息基本概念、TiDB 的统计信息收集/更新机制以及如何用统计信息来估计算子代价。上篇侧重于介绍原理，下篇会结合原理介绍 TiDB 的源码实现。
统计信息是什么 为了得到查询路径的执行代价，最简单的办法就是实际执行这个查询计划，不过这样子做就失去了优化器的意义。不过，优化器并不需要知道准确的代价，只需要一个估算值，以便能够区分开代价差别较大的执行计划。因此，数据库常常会维护一些实际数据的概括信息，用以快速的估计代价，这便是统计信息。
在 TiDB 中，我们维护的统计信息包括表的总行数，列的等深直方图，Count-Min Sketch，Null 值的个数，平均长度，不同值的数目等等。下面会简单介绍一下直方图和 Count-Min Sketch。
直方图简介 直方图是一种对数据分布情况进行描述的工具，它会按照数据的值大小进行分桶，并用一些简单的数据来描述每个桶，比如落在桶里的值的个数。大多数数据库都会选择用直方图来进行区间查询的估算。根据分桶策略的不同，常见的直方图可以分为等深直方图和等宽直方图。
在 TiDB 中，我们选择了等深直方图，于 1984 年在 Accurate estimation of the number of tuples satisfying a condition 文献中提出。相比于等宽直方图，等深直方图在最坏情况下也可以很好的保证误差。所谓的等深直方图，就是落入每个桶里的值数量尽量相等。举个例子，比方说对于给定的集合 {1.6, 1.9, 1.9, 2.0, 2.4, 2.6, 2.7, 2.7, 2.8, 2.9, 3.4, 3.5}，并且生成 4 个桶，那么最终的等深直方图就会如下图所示，包含四个桶 [1.6, 1.9]，[2.0, 2.6]，[2.7, 2.8]，[2.9, 3.5]，其桶深均为 3。
Count-Min Sketch 简介 Count-Min Sketch 是一种可以处理等值查询，Join 大小估计等的数据结构，并且可以提供很强的准确性保证。自 2003 年在文献 An improved data stream summary: The count-min sketch and its applications 中提出以来，由于其创建和使用的简单性获得了广泛的使用。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十一）Index Lookup Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</link>
      <pubDate>Wed, 27 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-11/</guid>
      <description>什么是 Index Lookup Join Nested Loop Join 在介绍 Index Lookup Join 之前，我们首先看一下什么是 Nested Loop Join（NLJ）。 NLJ 的具体定义可以参考 Wikipedia。NLJ 是最为简单暴力的 Join 算法，其执行过程简述如下：
 遍历 Outer 表，取一条数据 r；
 遍历 Inner 表，对于 Inner 表中的每条数据，与 r 进行 join 操作并输出 join 结果；
 重复步骤 1，2 直至遍历完 Outer 表中的所有数据。
  NLJ 算法实现非常简单并且 join 结果的顺序与 Outer 表的数据顺序一致。
但是存在性能上的问题：执行过程中，对于每一条 OuterRow，我们都需要对 Inner 表进行一次全表扫操作，这将消耗大量时间。
为了减少对于 Inner 表的全表扫次数，我们可以将上述步骤 1 优化为每次从 Outer 表中读取一个 batch 的数据，优化后的算法即 Block Nested-Loop Join（BNJ），BNJ 的具体定义可以参考 Wikipedia。</description>
    </item>
    
    <item>
      <title>十问 TiDB ：关于架构设计的一些思考</title>
      <link>https://pingcap.com/blog-cn/10-questions-tidb-structure/</link>
      <pubDate>Tue, 19 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/10-questions-tidb-structure/</guid>
      <description>“我希望能够把 TiDB 的设计的一些理念能够更好的传达给大家，相信大家理解了背后原因后，就能够把 TiDB 用的更好。”
 做 TiDB 的缘起是从思考一个问题开始的：为什么在数据库领域有这么多永远也躲不开的坑？从 2015 年我们写下第一行代码，3 年以来我们迎面遇到无数个问题，一边思考一边做，尽量用最小的代价来快速奔跑。
作为一个开源项目，TiDB 是我们基础架构工程师和社区一起努力的结果，TiDB 已经发版到 2.0，有了一个比较稳定的形态，大量在生产环境使用的伙伴们。可以负责任的说，我们做的任何决定都经过了非常慎重的思考和实践，是经过内部和社区一起论证产生的结果。它未必是最好的，但是在这个阶段应该是最适合我们的，而且大家也可以看到 TiDB 在快速迭代进化。
这篇文章是关于 TiDB 代表性“为什么”的 TOP 10，希望大家在了解了我们这些背后的选择之后，能更加纯熟的使用 TiDB，让它在适合的环境里更好的发挥价值。
这个世界有很多人，感觉大于思想，疑问多于答案。感恩大家保持疑问，我们承诺回馈我们的思考过程，毕竟有时候很多思考也很有意思。
一、为什么分布式系统并不是银弹 其实并没有什么技术是完美和包治百病的，在存储领域更是如此，如果你的数据能够在一个 MySQL 装下并且服务器的压力不大，或者对复杂查询性能要求不高，其实分布式数据库并不是一个特别好的选择。 选用分布式的架构就意味着引入额外的维护成本，而且这个成本对于特别小的业务来说是不太划算的，即使你说需要高可用的能力，那 MySQL 的主从复制 + GTID 的方案可能也基本够用，这不够的话，还有最近引入的 Group Replication。而且 MySQL 的社区足够庞大，你能 Google 找到几乎一切常见问题的答案。
我们做 TiDB 的初衷并不是想要在小数据量下取代 MySQL，而是尝试去解决基于单机数据库解决不了的一些本质的问题。
有很多朋友问我选择分布式数据库的一个比较合适的时机是什么？我觉得对于每个公司或者每个业务都不太一样，我并不希望一刀切的给个普适的标准（也可能这个标准并不存在），但是有一些事件开始出现的时候：比如是当你发现你的数据库已经到了你每天开始绞尽脑汁思考数据备份迁移扩容，开始隔三差五的想着优化存储空间和复杂的慢查询，或者你开始不自觉的调研数据库中间件方案时，或者人肉在代码里面做 sharding 的时候，这时给自己提个醒，看看 TiDB 是否能够帮助你，我相信大多数时候应该是可以的。
而且另一方面，选择 TiDB 和选择 MySQL 并不是一刀切的有你没他的过程，我们为了能让 MySQL 的用户尽可能减小迁移和改造成本，做了大量的工具能让整个数据迁移和灰度上线变得平滑，甚至从 TiDB 无缝的迁移回来，而且有些小数据量的业务你仍然可以继续使用 MySQL。所以一开始如果你的业务和数据量还小，大胆放心的用 MySQL 吧，MySQL still rocks，TiDB 在未来等你。
二、为什么是 MySQL 和上面提到的一样，并不是 MySQL 不好我们要取代他，而是选择兼容 MySQL 的生态对我们来说是最贴近用户实际场景的选择：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（十）Chunk 和执行框架简介</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</link>
      <pubDate>Thu, 14 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-10/</guid>
      <description>什么是 Chunk TiDB 2.0 中，我们引入了一个叫 Chunk 的数据结构用来在内存中存储内部数据，用于减小内存分配开销、降低内存占用以及实现内存使用量统计/控制，其特点如下：
 只读
 不支持随机写
 只支持追加写
 列存，同一列的数据连续的在内存中存放
  Chunk 本质上是 Column 的集合，它负责连续的在内存中存储同一列的数据，接下来我们看看 Column 的实现。
1. Column Column 的实现参考了 Apache Arrow，Column 的代码在 这里。根据所存储的数据类型，我们有两种 Column：
 定长 Column：存储定长类型的数据，比如 Double、Bigint、Decimal 等
 变长 Column：存储变长类型的数据，比如 Char、Varchar 等
  哪些数据类型用定长 Column，哪些数据类型用变长 Column 可以看函数 addColumnByFieldType 。
Column 里面的字段非常多，这里先简单介绍一下：
 length   用来表示这个 Column 有多少行数据。
 nullCount  用来表示这个 Column 中有多少 NULL 数据。
 nullBitmap  用来存储这个 Column 中每个元素是否是 NULL，需要特殊注意的是我们使用 0 表示 NULL，1 表示非 NULL，和 Apache Arrow 一样。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（九）Hash Join</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</link>
      <pubDate>Wed, 06 Jun 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-9/</guid>
      <description>什么是 Hash Join Hash Join 的基本定义可以参考维基百科：Hash join。简单来说，A 表和 B 表的 Hash Join 需要我们选择一个 Inner 表来构造哈希表，然后对 Outer 表的每一行数据都去这个哈希表中查找是否有匹配的数据。
我们不用 “小表” 和 “大表” 这两个术语是因为：对于类似 Left Outer Join 这种 Outer Join 来说，如果我们使用 Hash Join，不管 Left 表相对于 Right 表而言是大表还是小表，我们都只能使用 Right 表充当 Inner 表并在之上建哈希表，使用 Left 表来当 Outer 表，也就是我们的驱动表。使用 Inner 和 Outer 更准确，没有迷惑性。在 Build 阶段，对 Inner 表建哈希表，在 Probe 阶段，对由 Outer 表驱动执行 Join 过程。
TiDB Hash Join 实现 TiDB 的 Hash Join 是一个多线程版本的实现，主要任务有：
 Main Thread，一个，执行下列任务：</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（八）基于代价的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</link>
      <pubDate>Fri, 04 May 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-8/</guid>
      <description>概述 本文是 TiDB 源码阅读系列文章的第八篇。内文会先简单介绍制定查询计划以及优化的过程，然后用较大篇幅详述在得到逻辑计划后，如何基于统计信息和不同的属性选择等生成各种不同代价的物理计划，通过比较物理计划的代价，最后选择一个代价最小的物理计划，即 Cost-Based Optimization（CBO）的过程。
优化器框架 一般优化器分两个阶段进行优化，即基于规则的优化（Rule-Based-Optimization，简称 RBO）和基于代价的优化（CBO）。
TiDB 主要分为两个模块对计划进行优化：
 逻辑优化，主要依据关系代数的等价交换规则做一些逻辑变换。
 物理优化，主要通过对查询的数据读取、表连接方式、表连接顺序、排序等技术进行优化。
  相比 RBO，CBO 依赖于统计信息的准确性与及时性，执行计划会及时的根据数据变换做对应的调整。
优化器流程 TiDB 一个查询语句的简单流程：一个语句经过 parser 后会得到一个抽象语法树（AST），首先用经过合法性检查后的 AST 生成一个逻辑计划，接着会进行去关联化、谓词下推、聚合下推等规则化优化，然后通过统计数据计算代价选择最优的物理计划，最后执行。流程如下图 1。
 图 1 
物理算子简介 通过之前介绍物理层优化的方式，我们可以知道同一个逻辑算子可能因为它的数据读取、计算方式等不同会生成多个不同的物理算子，例如逻辑上的 Join 算子转换成物理算子可以选择 HashJoin、SortMergeJoin、IndexLookupJoin。
这里会简单介绍一些逻辑算子可选择的物理算子。例如语句：select sum(*) from t join s on t.c = s.c group by a。此语句中逻辑算子有 DataSource、Aggregation、Join 和 Projection，接下来会对其中几个典型的逻辑算子对应的物理算子进行一个简单介绍，如下表：
CBO 流程 基于代价优化的的主要思路是计算所有可能的执行计划的代价，并挑选代价最小的执行计划的路径。那么可以倒推出，首先得到需要采集对应表的统计信息，那么就可以用来计算出每个算子的执行代价，最后将得到每条路径上算子的代价按路径各自累加获取代价最小的路径。具体的代码实现在 plan/optimizer.go 中 dagPhysicalOptimize 函数，本文介绍的流程基本上也都由此函数完成，代码如下： func dagPhysicalOptimize(logic LogicalPlan) (PhysicalPlan, error) { logic.preparePossibleProperties() logic.deriveStats() t, err := logic.</description>
    </item>
    
    <item>
      <title>TiDB 2.0 GA Release</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release/</guid>
      <description>2018 年 4 月 27 日，TiDB 发布 2.0 GA 版。相比 1.0 版本，对 MySQL 兼容性、系统稳定性、优化器和执行器做了很多改进。
TiDB  SQL 优化器
 精简统计信息数据结构，减小内存占用
 加快进程启动时加载统计信息速度
 支持统计信息动态更新 [experimental]
 优化代价模型，对代价估算更精准
 使用 Count-Min Sketch 更精确地估算点查的代价
 支持分析更复杂的条件，尽可能充分的使用索引
 支持通过 STRAIGHT_JOIN 语法手动指定 Join 顺序
 GROUP BY子句为空时使用 Stream Aggregation 算子，提升性能
 支持使用索引计算 Max/Min 函数
 优化关联子查询处理算法，支持将更多类型的关联子查询解关联并转化成 Left Outer Join
 扩大 IndexLookupJoin 的使用范围，索引前缀匹配的场景也可以使用该算法
  SQL 执行引擎
 使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用，显著提升 TPC-H 结果</description>
    </item>
    
    <item>
      <title>详解 | TiDB 2.0 GA is here!</title>
      <link>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</link>
      <pubDate>Fri, 27 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-2.0-ga-release-detail/</guid>
      <description>去年十月份的时候，我们发布了 TiDB 1.0 版本，为此我们日夜兼程奋斗了两年半时间，我们认为 1.0 版本达到了可在生产环境中使用的程度。在接下来的六个月中，我们一方面维护 1.0 版本的稳定性并且增加必要的新特性，另一方面马不停蹄的开发 2.0 版本。经过半年时间，6 个 RC 版本，今天 TiDB 2.0 GA 版本正式发布。
2.0 版本规划 在 2.0 版本的规划阶段，我们对“这个版本需要做什么”进行了深入思考，我们根据现有用户的情况、技术发展趋势以及社区的声音，认为 2.0 版本需要聚焦在以下几点：
 保证 TiDB 的稳定性以及正确性。这两点是一个数据库软件的基础功能，作为业务的基石，任何一点抖动或者错误都可能对业务造成巨大的影响。目前已经有大量的用户在线上使用 TiDB，这些用户的数据量在不断增加、业务也在不断演进。我们非常关注 TiDB 集群如何保持长期稳定运行、如何减小系统的抖动、如何进行智能的调度，为此做了大量的调研和分析。
 提升 TiDB 在大数据量下的查询性能。从我们接触下来的用户来看，很多客户都有少则上百 GB，多则上百 TB 的数据，一方面数据会持续增加，另一方面也希望能对这些数据做实时的查询。所以如果能提升大数据量下的查询性能，对用户会很有帮助。
 优化 TiDB 的易用性和可维护性。TiDB 整套系统的复杂性比较高，运维及使用的难度要大于单机数据库，所以我们希望能提供尽可能方便的方案帮助用户使用 TiDB。比如尽可能简化部署、升级、扩容方式，尽可能容易的定位系统中出现的异常状态。
  围绕上面三点原则，我们做了大量的改进，一些是对外可见（如 OLAP 性能的显著提升、监控项的大量增加以及运维工具的各项优化），还有更多的改进是隐藏在数据库背后，默默的提升整个数据库的稳定性以及正确性。
正确性和稳定性 在 1.0 版本发布之后，我们开始构建和完善自动化测试平台 Schrodinger，彻底告别了之前靠手工部署集群测试的方式。同时我们也新增了非常多的测试用例，做到测试从最底层 RocksDB，到 Raft，再到 Transaction，然后是 SQL 都能覆盖。
在 Chaos 测试上面，我们引入了更多的错误注入工具，例如使用 systemtap 对 I/O 进行 delay 等，也在代码特定的业务的逻辑进行错误注入测试，充分保证 TiDB 在异常条件下面也能稳定运行。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（七）基于规则的优化</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</link>
      <pubDate>Tue, 10 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-7/</guid>
      <description>在 TiDB 里面，SQL 优化的过程可以分为逻辑优化和物理优化两个部分。逻辑优化主要是基于规则的优化，简称 RBO（rule based optimization）。物理优化会为逻辑查询计划中的算子选择某个具体的实现，需要用到一些统计信息，决定哪一种方式代价最低，所以是基于代价的优化 CBO（cost based optimization）。
本篇将主要关注逻辑优化。先介绍 TiDB 中的逻辑算子，然后介绍 TiDB 的逻辑优化规则，包括列裁剪、最大最小消除、投影消除、谓词下推等等。
逻辑算子介绍 在写具体的优化规则之前，先简单介绍查询计划里面的一些逻辑算子。
 DataSource 这个就是数据源，也就是表，select * from t 里面的 t。
 Selection 选择，例如 select xxx from t where xx = 5 里面的 where 过滤条件。
 Projection 投影， select c from t 里面的取 c 列是投影操作。
 Join 连接， select xx from t1, t2 where t1.c = t2.c 就是把 t1 t2 两个表做 Join。
  选择，投影，连接（简称 SPJ） 是最基本的算子。其中 Join 有内连接，左外右外连接等多种连接方式。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（六）Select 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</link>
      <pubDate>Fri, 30 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-6/</guid>
      <description>在先前的 TiDB 源码阅读系列文章（四） 中，我们介绍了 Insert 语句，想必大家已经了解了 TiDB 是如何写入数据，本篇文章介绍一下 Select 语句是如何执行。相比 Insert，Select 语句的执行流程会更复杂，本篇文章会第一次进入优化器、Coprocessor 模块进行介绍。
表结构和语句 表结构沿用上篇文章的：
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Select 语句只会讲解最简单的情况：全表扫描+过滤，暂时不考虑索引等复杂情况，更复杂的情况会在后续章节中介绍。语句为：
SELECT name FROM t WHERE age &amp;gt; 10; 语句处理流程 相比 Insert 的处理流程，Select 的处理流程中有 3 个明显的不同：
 需要经过 Optimize
Insert 是比较简单语句，在查询计划这块并不能做什么事情（对于 Insert into Select 语句这种，实际上只对 Select 进行优化），而 Select 语句可能会无比复杂，不同的查询计划之间性能天差地别，需要非常仔细的进行优化。
 需要和存储引擎中的计算模块交互
Insert 语句只涉及对 Key-Value 的 Set 操作，Select 语句可能要查询大量的数据，如果通过 KV 接口操作存储引擎，会过于低效，必须要通过计算下推的方式，将计算逻辑发送到存储节点，就近进行处理。</description>
    </item>
    
    <item>
      <title>刘寅：TiDB 工具链和生态</title>
      <link>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</link>
      <pubDate>Wed, 28 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-tools-ecosystems/</guid>
      <description>本文为今年年初 PingCAP 商业产品团队负责人刘寅在 TiDB DevCon2018 上分享的 《 TiDB 工具链和生态》实录内容，文内详细介绍了 TiDB 的周边工具以及生态系统。enjoy~
 大家下午好，我叫刘寅。在 PingCAP 主要负责 TiDB 商业工具产品开发，也在做公司 SRE 方面的事情。今天下午我分享的主题是介绍下 TiDB 的周边工具以及生态系统。
今天要讲的内容主要包含这几方面，首先是关于 TiDB 的部署，这是很多使用 TiDB 的用户首先关心的事情。接下来会介绍 TiDB 的数据导入工具和数据迁移同步工具，以及管理配置，数据可视化相关的工具。
TiDB 的架构可能大家都比较清楚了。TiDB 是一个由若干模块组成的分布式系统。这些模块相互依赖协调工作组成一个集群，整体构成了 TiDB 数据库。这样一个架构，对于用户进行部署和运维，其复杂程度相对单机数据库比如 MySQL 来说不那么容易的事情。那让我们来看看如何快速部署一套 TiDB 集群实例。最近我们公开了一个项目 pingcap/tidb-docker-compose，这令我们在一个本地的开发和测试环境上跑一套 TiDB 变得非常简单。只需要用一个命令 docker-compose up 就能快速启动起来。docker-compose 是 Docker 生态中的一个非常便利的工具，它可以在本机方便的把 TiDB 的各个组件，包括它的监控，可视化工具，全部整合在一个 yaml 文件来描述，非常的方便。不仅可以通过我们官方 docker image 镜像启动，也可以支持从本地的 binary 启动。比如当我本机编译了一个特殊版本的 binary，我就可以直接构建本地镜像来启动，甚至还可以支持现场编译源码来启动。所以这对于我们自己开发和测试也是非常方便的。另外我们也做了一个很简化的配置文件，比如我不希望默认跑 3 个 TiKV，我想启 5 个或者更多，简单的改下配置就可以搞定。
对于生产环境的部署和运维，往往面对的是一个成规模的集群，docker-compose 的部署方式就不够了。我们建议采用提供的 Ansible 部署方式。用户首先在一个 Inventory 文件中描述和编排所需的 TiDB 集群拓扑，然后执行我们提供的 ansible-playbook 脚本，就可以快速部署和运维一个生产环境下的 TiDB 集群。我们现在很多的线上用户，也是用了这样的部署方式。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（五）TiDB SQL Parser 的实现</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</link>
      <pubDate>Tue, 20 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-5/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第五篇，主要对 SQL Parser 功能的实现进行了讲解，内容来自社区小伙伴——马震（GitHub ID：mz1999 ）的投稿。
TiDB 源码阅读系列文章的撰写初衷，就是希望能与数据库研究者、爱好者进行深入交流，我们欣喜于如此短的时间内就收到了来自社区的反馈。后续，也希望有更多小伙伴加入到与 TiDB 『坦诚相见』的阵列中来。
 PingCAP 发布了 TiDB 的源码阅读系列文章，让我们可以比较系统的去学习了解TiDB的内部实现。最近的一篇《SQL 的一生》，从整体上讲解了一条 SQL 语句的处理流程，从网络上接收数据，MySQL 协议解析和转换，SQL 语法解析，查询计划的制定和优化，查询计划执行，到最后返回结果。
其中，SQL Parser 的功能是把 SQL 语句按照 SQL 语法规则进行解析，将文本转换成抽象语法树（AST），这部分功能需要些背景知识才能比较容易理解，我尝试做下相关知识的介绍，希望能对读懂这部分代码有点帮助。
TiDB 是使用 goyacc 根据预定义的 SQL 语法规则文件 parser.y 生成 SQL 语法解析器。我们可以在 TiDB 的 Makefile 文件中看到这个过程，先 build goyacc 工具，然后使用 goyacc 根据 parser.y 生成解析器 parser.go：
goyacc: $(GOBUILD) -o bin/goyacc parser/goyacc/main.go parser: goyacc bin/goyacc -o /dev/null parser/parser.y bin/goyacc -o parser/parser.go parser/parser.y 2&amp;gt;&amp;amp;1 ... goyacc 是 yacc 的 Golang 版，所以要想看懂语法规则定义文件 parser.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（四）Insert 语句概览</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</link>
      <pubDate>Tue, 13 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-4/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第四篇。上一篇文章简单介绍了整体流程，无论什么语句，大体上是在这个框架下运行，DDL 语句也不例外。
本篇文章会以 Insert 语句为例进行讲解，帮助读者理解前一篇文章，下一篇文章会介绍 Select 语句的执行流程。这两条是最常用的读、写语句，其他的语句相信读者能触类旁通，可以自行研究或者是等待后续的文章。对于这两类语句，目前也只会针对核心流程进行说明，更复杂的 Join、Insert-Into-OnDuplicate-Update 等会等到后面的文章进行讲解。另外本文会重点介绍每个语句在执行框架下面的具体执行逻辑，请读者阅读前先了解 Insert 语句的行为。
表结构 这里先给一个表结构，下面介绍的 SQL 语句都是在这个表上的操作。
CREATE TABLE t { id VARCHAR(31), name VARCHAR(50), age int, key id_idx (id) }; Insert 语句 INSERT INTO t VALUES (&amp;quot;pingcap001&amp;quot;, &amp;quot;pingcap&amp;quot;, 3); 以这条语句为例，解释 Insert 是如何运行的。
语句处理流程 首先大家回忆一下上一篇文章介绍的框架，一条 SQL 语句经过协议层、Parser、Plan、Executor 这样几个模块处理后，变成可执行的结构，再通过 Next() 来驱动语句的真正执行。对于框架，每类语句都差不多；对于每个核心步骤，每个语句会有自己的处理逻辑。
语法解析 先看 Parser，对于 Insert 语句的解析逻辑在这里，可以看到这条语句会被解析成下面这个结构：
// InsertStmt is a statement to insert new rows into an existing table. // See https://dev.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（三）SQL 的一生</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</link>
      <pubDate>Thu, 08 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-3/</guid>
      <description>概述 上一篇文章讲解了 TiDB 项目的结构以及三个核心部分，本篇文章从 SQL 处理流程出发，介绍哪里是入口，对 SQL 需要做哪些操作，知道一个 SQL 是从哪里进来的，在哪里处理，并从哪里返回。
SQL 有很多种，比如读、写、修改、删除以及管理类的 SQL，每种 SQL 有自己的执行逻辑，不过大体上的流程是类似的，都在一个统一的框架下运转。
框架 我们先从整体上看一下，一条语句需要经过哪些方面的工作。如果大家还记得上一篇文章所说的三个核心部分，可以想到首先要经过协议解析和转换，拿到语句内容，然后经过 SQL 核心层逻辑处理，生成查询计划，最后去存储引擎中获取数据，进行计算，返回结果。这个就是一个粗略的处理框架，本篇文章会把这个框架不断细化。
对于第一部分，协议解析和转换，所有的逻辑都在 server 这个包中，主要逻辑分为两块：一是连接的建立和管理，每个连接对应于一个 Session；二是在单个连接上的处理逻辑。第一点本文暂时不涉及，感兴趣的同学可以翻翻代码，看看连接如何建立、如何握手、如何销毁，后面也会有专门的文章讲解。对于 SQL 的执行过程，更重要的是第二点，也就是已经建立了连接，在这个连接上的操作，本文会详细讲解这一点。
对于第二部分，SQL 层的处理是整个 TiDB 最复杂的部分。这部分为什么复杂？原因有三点：
 SQL 语言本身是一门复杂的语言，语句的种类多、数据类型多、操作符多、语法组合多，这些『多』经过排列组合会变成『很多』『非常多』，所以需要写大量的代码来处理。
 SQL 是一门表意的语言，只是说『要什么数据』，而不说『如何拿数据』，所以需要一些复杂的逻辑选择『如何拿数据』，也就是选择一个好的查询计划。
 底层是一个分布式存储引擎，会面临很多单机存储引擎不会遇到的问题，比如做查询计划的时候要考虑到下层的数据是分片的、网络不通了如何处理等情况，所以需要一些复杂的逻辑处理这些情况，并且需要一个很好的机制将这些处理逻辑封装起来。这些复杂性是看懂源码比较大的障碍，所以本篇文章会尽量排除这些干扰，给大家讲解核心的逻辑是什么。
  这一层有几个核心概念，掌握了这几个也就掌握了这一层的框架，请大家关注下面这几个接口：
 Session
 RecordSet
 Plan
 LogicalPlan
 PhysicalPlan
 Executor
  下面的详细内容中，会讲解这些接口，用这些接口理清楚整个逻辑。
对于第三部分可以认为两块，第一块是 KV 接口层，主要作用是将请求路由到正确的的 KV Server，接收返回消息传给 SQL 层，并在此过程中处理各种异常逻辑；第二块是 KV Server 的具体实现，由于 TiKV 比较复杂，我们可以先看 Mock-TiKV 的实现，这里有所有的 SQL 分布式计算相关的逻辑。 接下来的几节，会对上面的三块详细展开描述。</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（二）初识 TiDB 源码</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</link>
      <pubDate>Fri, 02 Mar 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-2/</guid>
      <description>本文为 TiDB 源码阅读系列文章的第二篇，第一篇文章介绍了 TiDB 整体的架构，知道 TiDB 有哪些模块，分别是做什么的，从哪里入手比较好，哪些可以忽略，哪些需要仔细阅读。
这篇文章是一篇入门文档，难度系数比较低，其中部分内容可能大家在其他渠道已经看过，不过为了内容完整性，我们还是会放在这里。
TiDB 架构 本次 TiDB 源码之旅从这幅简单的架构图开始，这幅图很多人都看过，我们可以用一句话来描述这个图：『TiDB 是一个支持 MySQL 协议，以某种支持事务的分布式 KV 存储引擎为底层存储的 SQL 引擎』。从这句话可以看出有三个重要的事情，第一是如何支持 MySQL 协议，与 Client 交互，第二是如何与底层的存储引擎打交道，存取数据，第三是如何实现 SQL 的功能。本篇文章会先介绍一些 TiDB 有哪些模块及其功能简要介绍，然后以这三点为线索，将这些模块串联起来。
代码简介 TiDB 源码完全托管在 Github 上，从项目主页可以看到所有信息。整个项目使用 Go 语言开发，按照功能模块分了很多 Package，通过一些依赖分析工具，可以看到项目内部包之间的依赖关系。
大部分包都以接口的形式对外提供服务，大部分功能也都集中在某个包中，不过有一些包提供了非常基础的功能，会被很多包依赖，这些包需要特别注意。
项目的 main 文件在 tidb-server/main.go，这里面定义了服务如何启动。整个项目的 Build 方法可以在 Makefile 中找到。
除了代码之外，还有很多测试用例，可以在 xx_test.go 中找到。另外 cmd 目录下面还有几个工具包，用来做性能测试或者是构造测试数据。
模块介绍 TiDB 的模块非常多，这里做一个整体介绍，大家可以看到每个模块大致是做什么用的，想看相关功能的代码是，可以直接找到对应的模块。
   Package Introduction     ast 抽象语法树的数据结构定义，例如 SelectStmt 定义了一条 Select 语句被解析成什么样的数据结构   cmd/benchdb 简单的 benchmark 工具，用于性能优化   cmd/benchfilesort 简单的 benchmark 工具，用于性能优化   cmd/benchkv Transactional KV API benchmark 工具，也可以看做 KV 接口的使用样例   cmd/benchraw Raw KV API benchmark 工具，也可以看做不带事务的 KV 接口的使用样例   cmd/importer 根据表结构以及统计信息伪造数据的工具，用于构造测试数据   config 配置文件相关逻辑   context 主要包括 Context 接口，提供一些基本的功能抽象，很多包以及函数都会依赖于这个接口，把这些功能抽象为接口是为了解决包之间的依赖关系   ddl DDL 的执行逻辑   distsql 对分布式计算接口的抽象，通过这个包把 Executor 和 TiKV Client 之间的逻辑做隔离   domain domain 可以认为是一个存储空间的抽象，可以在其中创建数据库、创建表，不同的 domain 之间，可以存在相同名称的数据库，有点像 Name Space。一般来说单个 TiDB 实例只会创建一个 Domain 实例，其中会持有 information schema 信息、统计信息等。   executor 执行器相关逻辑，可以认为大部分语句的执行逻辑都在这里，比较杂，后面会专门介绍   expression 表达式相关逻辑，包括各种运算符、内建函数   expression/aggregation 聚合表达式相关的逻辑，比如 Sum、Count 等函数   infoschema SQL 元信息管理模块，另外对于 Information Schema 的操作，都会访问这里   kv KV 引擎接口以及一些公用方法，底层的存储引擎需要实现这个包中定义的接口   meta 利用 structure 包提供的功能，管理存储引擎中存储的 SQL 元信息，infoschema/DDL 利用这个模块访问或者修改 SQL 元信息   meta/autoid 用于生成全局唯一自增 ID 的模块，除了用于给每个表的自增 ID 之外，还用于生成全局唯一的 Database ID 和 Table ID   metrics Metrics 相关信息，所有的模块的 Metrics 信息都在这里   model SQL 元信息数据结构，包括 DBInfo / TableInfo / ColumnInfo / IndexInfo 等   mysql MySQL 相关的常量定义   owner TiDB 集群中的一些任务只能由一个实例执行，比如异步 Schema 变更，这个模块用于多个 tidb-server 之间协调产生一个任务执行者。每种任务都会产生自己的执行者。   parser 语法解析模块，主要包括词法解析 (lexer.</description>
    </item>
    
    <item>
      <title>TiDB 源码阅读系列文章（一）序</title>
      <link>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</link>
      <pubDate>Wed, 28 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-source-code-reading-1/</guid>
      <description>在 TiDB DevCon2018 上，我们对外宣布了 TiDB 源码阅读分享活动，承诺对外发布一系列文章以及视频帮助大家理解 TiDB 源码。大家一直很关心这项活动的时间，而我们忙于新版本的开发，一直不得闲。在春节放假期间，终于有时间开始动手写这个系列。
为什么我们要做这件事情？
事情的起因是随着 TiDB 项目逐渐发展，代码日渐复杂，我们发现新入职的同学越来越难上手修改代码。我们萌生了做内部培训的想法，通过录制视频、写教程的方式，加快新同事融入的速度，做了几次之后，我们发现效果不错，除了新同学有不少收获之外，老同志们也了解了之前自己并不熟悉的模块，大家都有收获。我们想到开源社区面临同样的问题，也可以通过这项工作收益，所以萌生了把这个活动做细做大的想法，于是有了这项活动。
TiDB 作为一个开源项目，在开发过程中得到了社区的广泛关注，很多人在试用或者已经在线用 TiDB，并给出了很多很好的建议或者是问题反馈，帮助我们把项目做的更好。对于项目开发是这样，那么对于数据库技术的研究，也是这样。我们非常希望能和对数据库研究者、爱好者交流，我们在过去的两年中组织过近百场技术 Meetup 或者 Talk，在和大家的交流过程中，我们发现国内的数据库技术水平非常好，在交流过程中总能碰撞出火花。通过这项活动，我们希望能和大家做更深入的交流，通过源码阅读，让 TiDB 与大家 『坦诚相见』。
前言 学习一种系统最好的方法是阅读一些经典著作并研究一个开源项目，数据库也不例外。单机数据库领域有很多好的开源项目，MySQL、PostgreSQL 是其中知名度最高的两个，不少人看过这两个项目的代码。我们在刚做数据库的时候也看过不少 MySQL、PG 的代码，从中受益良多。但是分布式数据库方面，好的开源项目并不多，有一些知名的系统并不开源，比如 F1/Spanner，还有一些系统疏于维护或者是从开源变成闭源，比如被 Apple 收购后闭源的 FoundationDB（还好当初 clone 了一份代码 :)，参见 这里，我们在内部或者外部也组织过一些开源系统代码阅读的 Talk，不过并不系统。
TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于整个系统的复杂性，很多人并不能很好的理解整个项目。我们希望通过这一系列文章自顶向下，由浅入深，讲述 TiDB 的技术原理以及实现细节，帮助大家掌握这个项目。
背景知识 本系列文章会聚焦在 TiDB 自身，读者需要有一些基本的知识，包括但不限于：
 Go 语言，不需要精通，但是至少要能读懂代码，知道 Goroutine、Channel、Sync 等组件的使用
 数据库基础知识，了解一个单机数据库由哪些功能、哪些组件
 SQL 基础知识，知道基本的 DDL、DML 语句，事务的基本常识
 基本的后端服务知识，比如如何启动一个后台进程、RPC 是如何工作的
 一些网络、操作系统的常识
 总体而言，读者需要了解基本的数据库知识以及能看懂 Go 语言程序，我相信这一点对于大多数同学来说，并不是问题。
  除了上述比较通用的知识之外，还希望读者能够看一下我之前写过的三篇文章（说存储，讲计算，论调度），了解一些 TiDB 的基本原理。</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Beta Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</link>
      <pubDate>Sat, 24 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-beta-release/</guid>
      <description>2018 年 2 月 24 日，TiDB 发布 1.1 Beta 版。该版本在 1.1 Alpha 版的基础上，对 MySQL 兼容性、系统稳定性做了很多改进。
TiDB  添加更多监控项, 优化日志
 兼容更多 MySQL 语法。
 在 information_schema 中支持显示建表时间
 提速包含 MaxOneRow 算子的查询
 控制 Join 产生的中间结果集大小，进一步减少 Join 的内存使用
 增加 tidb_config session 变量，输出当前 TiDB 配置
 修复 Union 和 Index Join 算子中遇到的 panic 问题
 修复 Sort Merge Join 算子在部分场景下结果错误的问题
 修复 Show Index 语句显示正在添加过程中的索引的问题
 修复 Drop Stats 语句失败的问题</description>
    </item>
    
    <item>
      <title>TiDB 1.1 Alpha Release</title>
      <link>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</link>
      <pubDate>Fri, 19 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-1.1-alpha-release/</guid>
      <description>2018 年 1 月 19 日，TiDB 发布 1.1 Alpha 版。该版本对 MySQL 兼容性、SQL 优化器、系统稳定性、性能做了大量的工作。
TiDB  SQL parser  兼容更多语法  SQL 查询优化器  统计信息减小内存占用 优化统计信息启动时载入的时间 更精确的代价估算 使用 Count-Min Sketch 更精确的估算点查的代价 支持更复杂的条件，更充分使用索引  SQL 执行器  使用 Chunk 结构重构所有执行器算子，提升分析型语句执行性能，减少内存占用 优化 INSERT INGORE 语句性能 下推更多的类型和函数 支持更多的 SQL_MODE 优化 Load Data 性能，速度提升 10 倍 优化 Use Database 性能 支持对物理算子内存使用进行统计  Server  支持 PROXY protocol   PD  增加更多的 API 支持 TLS 给 Simulator 增加更多的 case 调度适应不同的 region size Fix 了一些调度的 bug  TiKV  支持 Raft learner 优化 Raft Snapshot，减少 IO 开销 支持 TLS 优化 RocksDB 配置，提升性能 Coprocessor 支持更多下推操作 增加更多的 Failpoint 以及稳定性测试 case 解决 PD 和 TiKV 之间重连的问题 增强数据恢复工具 TiKV-CTL 的功能 region 支持按 table 进行分裂 支持 delete range 功能 支持设置 snapshot 导致的 IO 上限 完善流控机制  源码地址：https://github.</description>
    </item>
    
    <item>
      <title>使用 Rust 构建分布式 Key-Value Store</title>
      <link>https://pingcap.com/blog-cn/rust-key-value-store/</link>
      <pubDate>Wed, 15 Nov 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/rust-key-value-store/</guid>
      <description>引子 构建一个分布式 Key-Value Store 并不是一件容易的事情，我们需要考虑很多的问题，首先就是我们的系统到底需要提供什么样的功能，譬如：
 一致性：我们是否需要保证整个系统的线性一致性，还是能容忍短时间的数据不一致，只支持最终一致性。
 稳定性：我们能否保证系统 7 x 24 小时稳定运行。系统的可用性是 4 个 9，还有 5 个 9？如果出现了机器损坏等灾难情况，系统能否做的自动恢复。
 扩展性：当数据持续增多，能否通过添加机器就自动做到数据再次平衡，并且不影响外部服务。
 分布式事务：是否需要提供分布式事务支持，事务隔离等级需要支持到什么程度。
  上面的问题在系统设计之初，就需要考虑好，作为整个系统的设计目标。为了实现这些特性，我们就需要考虑到底采用哪一种实现方案，取舍各个方面的利弊等。
后面，我将以我们开发的分布式 Key-Value TiKV 作为实际例子，来说明下我们是如何取舍并实现的。
TiKV TiKV 是一个分布式 Key-Value store，它使用 Rust 开发，采用 Raft 一致性协议保证数据的强一致性，以及稳定性，同时通过 Raft 的 Configuration Change 机制实现了系统的可扩展性。
TiKV 提供了基本的 KV API 支持，也就是通常的 Get，Set，Delete，Scan 这样的 API。TiKV 也提供了支持 ACID 事务的 Transaction API，我们可以使用 Begin 开启一个事务，在事务里面对 Key 进行操作，最后再用 Commit 提交一个事务，TiKV 支持 SI 以及 SSI 事务隔离级别，用来满足用户的不同业务场景。
Rust 在规划好 TiKV 的特性之后，我们就要开始进行 TiKV 的开发。这时候，我们面临的第一个问题就是采用什么样的语言进行开发。当时，摆在我们眼前的有几个选择：</description>
    </item>
    
    <item>
      <title>写在 TiDB 1.0 发布之际 | 预测未来最好的方式就是创造未来</title>
      <link>https://pingcap.com/blog-cn/ga-1.0/</link>
      <pubDate>Tue, 17 Oct 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/ga-1.0/</guid>
      <description>如果只能用一个词来描述此刻的心情，我想说恍如隔世，这样说多少显得有几分矫情，或许内心还是想在能矫情的时候再矫情一次，毕竟当初做这一切的起因是为了梦想。还记得有人说预测未来最好的方式就是创造未来，以前看到这句话总觉得是废话，如今看到这一切在自己身上变成现实的一刻，感受是如此的真切，敲击键盘的手居然有点颤抖，是的，预测未来最好的方式就是创造未来。
还记得刚开始做的时候，只有很少的几个人相信这个事情可以做，毕竟难度比较高，就像有些户外旅行，只有方向，没有路。从零开始到发布 1.0 版本，历时 2 年 6 个月，终于还是做出来了。这是开源精神的胜利，是真正属于工程师们的荣耀。这个过程我们一直和用户保持沟通和密切协作，从最早纯粹的为 OLTP 场景的设计，到后来迭代为 HTAP 的设计，一共经历了 7 次重构，许多看得见的汗水，看不见的心跳，也许这就是相信相信的力量，总有那么一群人顶着世俗的压力，用自己的信念和力量在改变世界。在这个过程中，质疑的声音变少了，越来越多的人从观望，到为我们鼓舞助威，帮助我们快速成长。特别感谢那些从 beta 版本开始一路相随的用户，没有你们的信任，耐心和参与，就没有今天的 PingCAP。
开心的时刻总是特别想对很多帮助和支持我们的童鞋们说声谢谢，没有你们就没有 PingCAP，特别感谢每一位项目的贡献者。也许你已经知道了，我们专门为你们定制了一面荣誉墙，那里的色彩记录了你们的每一次贡献，如果你仍在埋头工作，来不及知道，我想请你过去逛逛，不负好时光。
这个世界还是有人相信未来是可以被创造的。感谢开源精神，让我们这样一个信仰创造未来的团队，可以站在未来的入口，因为相信和努力，获得源源不绝的正向的力量。面对未来，让我们可以摒弃对未知的恐惧和对不完美的妥协。
也感谢那些曾经的诋毁和吐槽，让我们不敢懈怠，砥砺前行。
然而 1.0 版本只是个开始，是新的起点，愿我们一路相扶，不负远途。</description>
    </item>
    
    <item>
      <title>谈谈开源(一)</title>
      <link>https://pingcap.com/blog-cn/talk-about-opensource/</link>
      <pubDate>Mon, 25 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-about-opensource/</guid>
      <description>源码面前，了无秘密 &amp;mdash;- 侯捷
 前言 很多人的『开源』是一个比较时髦且有情怀的词汇，不少公司也把开源当做 KPI 或者是技术宣传的手段。但是在我们看来，大多数人开源做的并不好，大多数开源项目也没有被很好的维护。比如前一段时间微博上流传关于 Tengine 的讨论，一个优秀的开源项目不止是公布源代码就 OK 了，还需要后续大量的精力去维护，包括制定 RoadMap、开发新功能、和社区交流、推动项目在社区中的使用、对使用者提供一定程度的支持，等等。
目前我们在国内没看到什么特别好的文章讲如何运营一个开源项目，或者是如何做一个顶级的开源项目。TiDB 这个项目从创建到现在已经有两年多，从开发之初我们就坚定地走开源路线，陆续开源了 TiDB、TiKV、PD 这三个核心组件，获得了广泛的关注，项目在 GitHub 的 Trending 上面也多次登上首页。在这两年中，我们在这方面积累了一些经验和教训，这里和大家交流一下我们做开源过程中的一些感受，以及参与开源项目（至少是指 TiDB 相关项目）的正确姿势。
什么是开源  Open-source software (OSS) is computer software with its source code made available with a license in which the copyright holder provides the rights to study, change, and distribute the software to anyone and for any purpose.
&amp;mdash;- From Wikipedia
 本文讨论的开源是指开源软件，简而言之，开源就是拥有源代码版权的人，允许其他人在一定许可证所述范围内，访问源代码，并用于一些自己的目的。 最基本的要求就是其他人可以访问源代码，另外获取代码后能做什么，就需要一个专门的许可证来规范（可以是自己写的，也可以用一个别人写好的）。里面一般会规定诸如对修改代码、新增代码、后续工作是否需要开源以及专利相关的事项。 OK，我们写一个 main.</description>
    </item>
    
    <item>
      <title>When TiDB Meets Spark</title>
      <link>https://pingcap.com/blog-cn/tidb-meets-spark/</link>
      <pubDate>Fri, 01 Sep 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-meets-spark/</guid>
      <description>本文整理自 TiSpark 项目发起人马晓宇在 Strata Data Conference 上分享的《When TiDB Meets Spark》演讲实录。
 先介绍我自己，我是 PingCAP 的马晓宇，是 TiDB OLAP 方向的负责人，也是 TiSpark 项目的发起人，主要是做 OLAP 方面的 Feature 和 Product 相关的工作，之前是网易的 Big Data Infra Team Leader，先前的经验差不多都是在 SQL、Hadoop 和所谓大数据相关的一些东西。
今天主要会讲的议程大概这么几项。
首先稍微介绍一下 TiDB 和 TiKV，因为 TiSpark 这个项目是基于它们的，所以你需要知道一下 TiDB 和 TiKV 分别是什么，才能比较好理解我们做的是什么事情。
另外正题是 TiSpark 是什么，然后 TiSpark 的架构，除了 Raw Spark 之外，我们提供了一些什么样的不一样的东西，再然后是 Use Case，最后是项目现在的状态。
首先说什么是 TiDB。你可以认为 TiDB 是现在比较火的 Spanner 的一个开源实现。它具备在线水平扩展、分布式 ACID Transaction、HA、Auto failover 等特性，是一个 NewSQL 数据库。
然后什么是 TiKV，可能我们今天要说很多次了。TiKV 其实是 TiDB 这个产品底下的数据库存储引擎，更形象，更具体一点，这是一个架构图。</description>
    </item>
    
    <item>
      <title>Linearizability 一致性验证</title>
      <link>https://pingcap.com/blog-cn/linearizability/</link>
      <pubDate>Mon, 21 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/linearizability/</guid>
      <description>上篇文章介绍了 TiDB 如何使用 Jepsen 来进行一致性验证，并且介绍了具体的测试案例，但是并没有对 Jepsen 背后的一致性验证算法做过多介绍。这篇文章将会深入 Jepsen 的核心库 knossos，介绍 knossos 库所涉及的 Linearizability（线性化）一致性验证算法。
Linearizability 一致性模型 什么是一致性模型？ 一致性模型确定了编写系统的程序员与系统之间的某种协议，如果程序员遵守了这种协议，那么这个系统就能提供某种一致性。常见的一致性模型有：
 Strict Consistency Linearizability (Atomic Consistency) Sequential Consistency Casual Consistency Serializability ……  需要注意的是这里的系统指并发系统，分布式系统只是其中的一类。
什么是 Linearizability？ 首先我们需要引入*历史*（history）的概念，历史是并发系统中由 invocation 事件和 response 事件组成的有限序列。
  invocation: \&amp;lt;x op(args\*) A\&amp;gt;，x 表示被执行对象的名称；op 表示操作名称，如读和写；args* 表示一系列参数值；A 表示进程的名称。
 response：\&amp;lt;x term(res\*) A\&amp;gt;，term 表示结束（termination）状态；res* 表示一系列结果值。
 如果 invocation 和 response 的 x（对象）和 A（进程）相同，那么我们认为它们是对应操作，并且 complete(H) 表示历史中的最多成对操作。
   当我们的历史 H 满足以下条件时我们把它称为*顺序化*（sequential）历史：</description>
    </item>
    
    <item>
      <title>当 TiDB 遇上 Jepsen</title>
      <link>https://pingcap.com/blog-cn/tidb-jepsen/</link>
      <pubDate>Tue, 15 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-jepsen/</guid>
      <description>本篇文章主要介绍 TiDB 是如何使用分布式一致性验证框架 Jepsen 进行一致性验证的。
什么是 Jepsen Jepsen 是由 Kyle Kingsbury 采用函数式编程语言 Clojure 编写的验证分布式系统一致性的测试框架，作者使用它对许多著名的分布式系统（etcd, cockroachdb&amp;hellip;）进行了“攻击”（一致性验证），并且帮助其中的部分系统找到了 bug。这里一系列的博客展示了作者的验证过程以及对于一致性验证的许多思考。
Jepsen 如何工作 Jepsen 验证系统由 6 个节点组成，一个控制节点（control node），五个被控制节点（默认为 n1, n2, n3, n4, n5），控制节点将所有指令发送到某些或全部被控制节点，这些指令包括底层的 shell 命令到上层的 SQL 语句等等。Jepsen 提供了几个核心 API 用于验证分布式系统：
 DB
DB 封装了所验证的分布式系统下载、部署、启动和关闭命令，核心函数由 setup 和 teardown 组成，在 TiDB 的 Jepsen 测试中，setup 负责下载 TiDB 并且依次启动 Placement Driver、TiKV 和 TiDB；teardown 负责关闭整个 TiDB 系统并且删除日志。
 Client
Client 封装了每一个测试所需要提供的客户，每个 client 提供两个接口：setup 和 invoke，setup 负责对 TiDB 进行连接，而 invoke 则包含了测试中 client 对 TiDB 调用的 sql 语句，具体语句依测试而定。</description>
    </item>
    
    <item>
      <title>TiSpark (Beta) 用户指南</title>
      <link>https://pingcap.com/blog-cn/tispark/</link>
      <pubDate>Wed, 26 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tispark/</guid>
      <description>TiSpark 是 PingCAP 推出的为了解决用户复杂 OLAP 需求的产品。借助 Spark 平台本身的优势，同时融合 TiKV 分布式集群的优势，和 TiDB 一起为用户一站式解决 HTAP （Hybrid Transactional/Analytical Processing）需求。 TiSpark 依赖 TiKV 集群和 PD 的存在。当然，TiSpark 也需要你搭建一个 Spark 集群。本文简单介绍如何部署和使用 TiSpark。本文假设你对 Spark 有基本认知。你可以参阅 Apache Spark 官网 了解 Spark 相关信息。
一、概述 TiSpark 是将 Spark SQL 直接运行在 TiDB 存储引擎 TiKV 上的 OLAP 解决方案。TiSpark 架构图如下：
 TiSpark 深度整合了 Spark Catalyst 引擎, 可以对计算提供精确的控制，使 Spark 能够高效的读取 TiKV 中的数据，提供索引支持以实现高速的点查；
 通过多种计算下推减少 Spark SQL 需要处理的数据大小，以加速查询；利用 TiDB 的内建的统计信息选择更优的查询计划。
 从数据集群的角度看，TiSpark + TiDB 可以让用户无需进行脆弱和难以维护的 ETL，直接在同一个平台进行事务和分析两种工作，简化了系统架构和运维。</description>
    </item>
    
    <item>
      <title>PAX：一个 Cache 友好高效的行列混存方案</title>
      <link>https://pingcap.com/blog-cn/pax/</link>
      <pubDate>Wed, 19 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pax/</guid>
      <description>今年，Spanner 终于发了另一篇 Paper 「Spanner: Becoming a SQL System」，里面提到 Spanner 使用了一种新的存储格式 - Ressi，用来支持 OLTP 和 OLAP。在 Ressi 里面，使用了 PAX 来组织数据。因为 TiDB 定位就是一个 HTAP 系统，所以我也一直在思考在 TiKV 这层如何更好的存储数据，用来满足 HTAP 的需要，既然 Spanner 使用了 PAX，那么就有研究的必要了。
PAX 的论文可以看看 「Weaving Relations for Cache Performance」 或者 「Data Page Layouts for Relational Databases on Deep Memory Hierarchies」。
NSM and DSM 在谈 PAX 之前，NSM 和 DSM 还是绕不开的话题，NSM 就是通常说的行存，对于现阶段很多偏重 OLTP 的数据，譬如 MySQL 等，都采用的这种方式存储的数据。而 DSM，则是通常的说的列存，几乎所有的 OLAP 系统，都采用的这种方式来存储的底层数据。
NSM 会将 record 依次在磁盘 page 里面存放，每个 page 的末尾会存放 record 的 offset，便于快速的定位到实际的 record。如果我们每次需要得到一行 record，或者 scan 所有 records，这种格式非常的高效。但如果我们的查询，仅仅是要拿到 record 里面的一列数据，譬如 select name from R where age &amp;lt; 40，那么对于每次 age 的遍历，除了会将无用的其他数据一起读入，每次读取 record，都可能会引起 cache miss。</description>
    </item>
    
    <item>
      <title>gRPC-rs：从 C 到 Rust</title>
      <link>https://pingcap.com/blog-cn/grpc-rs/</link>
      <pubDate>Tue, 18 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc-rs/</guid>
      <description>介绍 在 上篇文章 中，我们讲到 TiKV 为了支持 gRPC，我们造了个轮子 gRPC-rs，这篇文章简要地介绍一下这个库。首先我们来聊聊什么是 gRPC。gRPC 是 Google 推出的基于 HTTP2 的开源 RPC 框架，希望通过它使得各种微服务之间拥有统一的 RPC 基础设施。它不仅支持常规的平台如 Linux，Windows，还支持移动设备和 IoT，现有十几种语言的实现，现在又多了一种语言 Rust。
gRPC 之所以有如此多的语言支持，是因为它有一个 C 写的核心库(gRPC core)，因此只要某个语言兼容 C ABI，那么就可以通过封装，写一个该语言的 gRPC 库。Rust 对 C 有良好的支持，gRPC-rs 就是对 gRPC core ABI 的 Rust 封装。
Core 能异步处理 RPC 请求，在考虑到 Rust 中已有较为成熟的异步框架 Futures，我们决定将 API 设计成 Future 模式。
gRPC-rs 架构图
我们将根据架构图从底向上地讲一下，在 上一篇文章 中已经讨论过传输层和协议，在这就不再赘述。
gRPC Core Core 中有几个比较重要的对象：
 Call 以及 4 种类型 RPC： Call 代表了一次 RPC，可以派生出四种类型 RPC，</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 重构内建函数进度报告</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</link>
      <pubDate>Fri, 14 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function-report/</guid>
      <description>6 月 22 日，TiDB 发布了一篇如何十分钟成为 TiDB Contributor 系列的第二篇文章，向大家介绍如何为 TiDB 重构 built-in 函数。
截止到目前，得到了来自社区的积极支持与热情反馈，TiDB 参考社区 contributors 的建议，对计算框架进行了部分修改以降低社区同学参与的难度。
本文完成以下2 项工作，希望帮助社区更好的参与进 TiDB 的项目中来:
 对尚未重写的 built-in 函数进行陈列 对继上篇文章后，计算框架所进行的修改，进行详细介绍  一. 尚未重写的 built-in 函数陈列如下： 共计 165 个 在 expression 目录下运行 grep -rn &amp;quot;^\tbaseBuiltinFunc$&amp;quot; -B 1 * | grep &amp;quot;Sig struct {&amp;quot; | awk -F &amp;quot;Sig&amp;quot; &#39;{print $1}&#39; | awk -F &amp;quot;builtin&amp;quot; &#39;{print $3}&#39; &amp;gt; ~/Desktop/func.txt 命令可以获得所有未实现的 built-in 函数
   0 1 2 3 4     Coalesce Uncompress Log10 Default UnaryOp   Greatest UncompressedLength Rand InetAton IsNull   Least ValidatePasswordStrength Pow InetNtoa In   Interval Database Round Inet6Aton Row   CaseWhen FoundRows Conv Inet6Ntoa SetVar   If CurrentUser CRC32 IsFreeLock GetVar   IfNull User Sqrt IsIPv4 Values   NullIf ConnectionID Arithmetic IsIPv4Prefixed BitCount   AesDecrypt LastInsertID Acos IsIPv6 Reverse   AesEncrypt Version Asin IsUsedLock Convert   Compress Benchmark Atan MasterPosWait Substring   Decode Charset Cot NameConst SubstringIndex   DesDecrypt Coercibility Exp ReleaseAllLocks Locate   DesEncrypt Collation PI UUID Hex   Encode RowCount Radians UUIDShort UnHex   Encrypt Regexp Truncate AndAnd Trim   OldPassword Abs Sleep OrOr LTrim   RandomBytes Ceil Lock LogicXor RTrim   SHA1 Floor ReleaseLock BitOp Rpad   SHA2 Log AnyValue IsTrueOp BitLength   Char Format FromDays DayOfWeek Timestamp   CharLength FromBase64 Hour DayOfYear AddTime   FindInSet InsertFunc Minute Week ConvertTz   Field Instr Second WeekDay MakeTime   MakeSet LoadFile MicroSecond WeekOfYear PeriodAdd   Oct Lpad Month Year PeriodDiff   Quote Date MonthName YearWeek Quarter   Bin DateDiff Now FromUnixTime SecToTime   Elt TimeDiff DayName GetFormat SubTime   ExportSet DateFormat DayOfMonth StrToDate TimeFormat   UTCTim ToSeconds TimestampDiff DateArith Extract   UnixTimestamp UTCTimestamp UTCDate Time CurrentTime   ToDays TimestampAdd TimeToSec CurrentDate SysDate    二.</description>
    </item>
    
    <item>
      <title>TiDB Best Practice</title>
      <link>https://pingcap.com/blog-cn/tidb-best-practice/</link>
      <pubDate>Wed, 05 Jul 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-best-practice/</guid>
      <description>本文档用于总结在使用 TiDB 时候的一些最佳实践，主要涉及 SQL 使用、OLAP/OLTP 优化技巧，特别是一些 TiDB 专有的优化开关。 建议先阅读讲解 TiDB 原理的三篇文章(讲存储，说计算，谈调度)，再来看这篇文章。
前言 数据库是一个通用的基础组件，在开发过程中会考虑到多种目标场景，在具体的业务场景中，需要根据业务的实际情况对数据的参数或者使用方式进行调整。
TiDB 是一个兼容 MySQL 协议和语法的分布式数据库，但是由于其内部实现，特别是支持分布式存储以及分布式事务，使得一些使用方法和 MySQL 有所区别。
基本概念 TiDB 的最佳实践与其实现原理密切相关，建议读者先了解一些基本的实现机制，包括 Raft、分布式事务、数据分片、负载均衡、SQL 到 KV 的映射方案、二级索引的实现方法、分布式执行引擎。下面会做一点简单的介绍，更详细的信息可以参考 PingCAP 公众号以及知乎专栏的一些文章。
Raft Raft 是一种一致性协议，能提供强一致的数据复制保证，TiDB 最底层用 Raft 来同步数据。每次写入都要写入多数副本，才能对外返回成功，这样即使丢掉少数副本，也能保证系统中还有最新的数据。比如最大 3 副本的话，每次写入 2 副本才算成功，任何时候，只丢失一个副本的情况下，存活的两个副本中至少有一个具有最新的数据。
相比 Master-Slave 方式的同步，同样是保存三副本，Raft 的方式更为高效，写入的延迟取决于最快的两个副本，而不是最慢的那个副本。所以使用 Raft 同步的情况下，异地多活成为可能。在典型的两地三中心场景下，每次写入只需要本数据中心以及离得近的一个数据中心写入成功就能保证数据的一致性，而并不需要三个数据中心都写成功。但是这并不意味着在任何场景都能构建跨机房部署的业务，当写入量比较大时候，机房之间的带宽和延迟成为关键因素，如果写入速度超过机房之间的带宽，或者是机房之间延迟过大，整个 Raft 同步机制依然无法很好的运转。
分布式事务 TiDB 提供完整的分布式事务，事务模型是在 Google Percolator 的基础上做了一些优化。具体的实现大家可以参考这篇文章。这里只说两点：
 乐观锁
TiDB 的事务模型采用乐观锁，只有在真正提交的时候，才会做冲突检测，如果有冲突，则需要重试。这种模型在冲突严重的场景下，会比较低效，因为重试之前的操作都是无效的，需要重复做。举一个比较极端的例子，就是把数据库当做计数器用，如果访问的并发度比较高，那么一定会有严重的冲突，导致大量的重试甚至是超时。但是如果访问冲突并不十分严重，那么乐观锁模型具备较高的效率。所以在冲突严重的场景下，推荐在系统架构层面解决问题，比如将计数器放在 Redis 中。
 事务大小限制
由于分布式事务要做两阶段提交，并且底层还需要做 Raft 复制，如果一个事务非常大，会使得提交过程非常慢，并且会卡住下面的 Raft 复制流程。为了避免系统出现被卡住的情况，我们对事务的大小做了限制：
 单条 KV entry 不超过 6MB KV entry 的总条数不超过 30W KV entry 的总大小不超过 100MB  在 Google 的 Cloud Spanner 上面，也有类似的限制。</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（2）- 火焰图</title>
      <link>https://pingcap.com/blog-cn/flame-graph/</link>
      <pubDate>Mon, 26 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/flame-graph/</guid>
      <description>在 前一篇 文章，我们简单提到了 perf，实际 perf 能做的事情远远不止这么少，这里就要好好介绍一下，我们在 TiKV 性能调优上面用的最多的工具 - 火焰图。
火焰图，也就是 FlameGraph，是超级大牛 Brendan Gregg 捣鼓出来的东西，主要就是将 profile 工具生成的数据进行可视化处理，方便开发人员查看。我第一次知道火焰图，应该是来自 OpenResty 的章亦春介绍，大家可以详细去看看这篇文章《动态追踪技术漫谈》。
之前，我的所有工作在很长一段时间几乎都是基于 Go 的，而 Go 原生提供了很多相关的 profile 工具，以及可视化方法，所以我没怎么用过火焰图。但开始用 Rust 开发 TiKV 之后，我就立刻傻眼了，Rust 可没有官方的工具来做这些事情，怎么搞？自然，我们就开始使用火焰图了。
使用火焰图非常的简单，我们仅仅需要将代码 clone 下来就可以了，我通常喜欢将相关脚本扔到 /opt/FlameGraph 下面，后面也会用这个目录举例说明。
一个简单安装的例子：
wget https://github.com/brendangregg/FlameGraph/archive/master.zip unzip master.zip sudo mv FlameGraph-master/ /opt/FlameGraph CPU 对于 TiKV 来说，性能问题最开始关注的就是 CPU，毕竟这个是一个非常直观的东西。
当我们发现 TiKV CPU 压力很大的时候，通常会对 TiKV 进行 perf，如下：
perf record -F 99 -p tikv_pid -g -- sleep 60 perf script &amp;gt; out.</description>
    </item>
    
    <item>
      <title>十分钟成为 Contributor 系列 | 为 TiDB 重构 built-in 函数</title>
      <link>https://pingcap.com/blog-cn/reconstruct-built-in-function/</link>
      <pubDate>Thu, 22 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/reconstruct-built-in-function/</guid>
      <description>这是十分钟成为 TiDB Contributor 系列的第二篇文章，让大家可以无门槛参与大型开源项目，感谢社区为 TiDB 带来的贡献，也希望参与 TiDB Community 能为你的生活带来更多有意义的时刻。
为了加速表达式计算速度，最近我们对表达式的计算框架进行了重构，这篇教程为大家分享如何利用新的计算框架为 TiDB 重写或新增 built-in 函数。对于部分背景知识请参考这篇文章，本文将首先介绍利用新的表达式计算框架重构 built-in 函数实现的流程，然后以一个函数作为示例进行详细说明，最后介绍重构前后表达式计算框架的区别。
重构 built-in 函数整体流程  在 TiDB 源码 expression 目录下选择任一感兴趣的函数，假设函数名为 XX
 重写 XXFunctionClass.getFunction() 方法
 该方法参照 MySQL 规则，根据 built-in 函数的参数类型推导函数的返回值类型 根据参数的个数、类型、以及函数的返回值类型生成不同的函数签名，关于函数签名的详细介绍见文末附录  实现该 built-in 函数对应的所有函数签名的 evalYY() 方法，此处 YY 表示该函数签名的返回值类型
 添加测试：
 在 expression 目录下，完善已有的 TestXX() 方法中关于该函数实现的测试 在 executor 目录下，添加 SQL 层面的测试  运行 make dev，确保所有的 test cast 都能跑过
  示例 这里以重写 LENGTH() 函数的 PR 为例，进行详细说明</description>
    </item>
    
    <item>
      <title>深入了解 gRPC：协议</title>
      <link>https://pingcap.com/blog-cn/grpc/</link>
      <pubDate>Sun, 18 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/grpc/</guid>
      <description>经过很长一段时间的开发，TiDB 终于发了 RC3。RC3 版本对于 TiKV 来说最重要的功能就是支持了 gRPC，也就意味着后面大家可以非常方便的使用自己喜欢的语言对接 TiKV 了。
gRPC 是基于 HTTP/2 协议的，要深刻理解 gRPC，理解下 HTTP/2 是必要的，这里先简单介绍一下 HTTP/2 相关的知识，然后再介绍下 gRPC 是如何基于 HTTP/2 构建的。
HTTP/1.x HTTP 协议可以算是现阶段 Web 上面最通用的协议了，在之前很长一段时间，很多应用都是基于 HTTP/1.x 协议，HTTP/1.x 协议是一个文本协议，可读性非常好，但其实并不高效，笔者主要碰到过几个问题：
Parser 如果要解析一个完整的 HTTP 请求，首先我们需要能正确的读出 HTTP header。HTTP header 各个 fields 使用 \r\n 分隔，然后跟 body 之间使用 \r\n\r\n 分隔。解析完 header 之后，我们才能从 header 里面的 content-length 拿到 body 的 size，从而读取 body。
这套流程其实并不高效，因为我们需要读取多次，才能将一个完整的 HTTP 请求给解析出来，虽然在代码实现上面，有很多优化方式，譬如：
 一次将一大块数据读取到 buffer 里面避免多次 IO read 读取的时候直接匹配 \r\n 的方式流式解析  但上面的方式对于高性能服务来说，终归还是会有开销。其实最主要的问题在于，HTTP/1.</description>
    </item>
    
    <item>
      <title>来自 PingCAP CEO 的信：说在 B 轮融资完成之际</title>
      <link>https://pingcap.com/blog-cn/series-B-funding/</link>
      <pubDate>Tue, 13 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/series-B-funding/</guid>
      <description>平时技术说得多，今天说点走心的。
从决定出来创业到现在，刚好两年多一点，如果把 PingCAP 比喻成一个孩子的话， 刚是过了蹒跚学步的时期，前方有更大更美好的世界等我们去探索。这两年时间，在一片质疑声之中 ，TiDB 还算顽强的从无到有成长了起来。其实这一切的初心也很简单，最开始只不过是几个不愿妥协的分布式系统工程师对心目中&amp;rsquo;完美&amp;rsquo;的数据库的探索。很欣喜的看到 TiDB 的日渐成熟，周边工具和社区渐渐壮大，我感到由衷的自豪，在这个过程中，也一次又一次的挑战着技术和各自能力的边界，很庆幸能和自己的产品一起成长。
坚持做正确的事，哪怕这看起来是一条更困难的路。TiDB 从诞生的第一天起便决定开源，虽然更多的是商业上的考量，不过里面也有一点点读书人兼济天下的情怀和对传统 Hacker 精神的贯彻。在我们之前，很多人认为分布式 OLTP 和 OLAP 融合几乎是不可能的事情，也有无数的人，其中不乏亲朋好友，劝我们说在国内做这个事情几乎难于登天，而且没有成功的先例。不过我们还是相信一个朴素道理，有价值的技术一定会有它的舞台，另外，任何事情如果没有尝试就打退堂鼓也不是我们的风格。如果没有成功的先例，那就一起来创造先例，做开创者是我们每个人的梦想。说实话，从技术上来说，这个领域是一个非常前沿的领域，大多数时候我们面前是无人区，也很幸运，目前看来技术上和预想的没有出现大的偏差，整个产品和团队也在稳步的前进。
整个团队也从一开始的 3 个人，到今天 63 个志同道合的伙伴结伴前行，又一次很幸运，能凑齐这么一个具有很强战斗力和国际视野的团队，挑战计算机领域最困难和最前沿的课题之一，前方还有无数个迷人的问题等待着被解决，有时候也只能摸索着前进，不过这正是这个事情有意思的地方。谢谢你们，和你们一同工作，是我的荣幸。
到今天，我们很自豪的宣布，已经有数十家客户将 TiDB 使用在各自的生产环境中解决问题，感谢我们早期的铁杆用户和可爱的社区开发者，是你们让 TiDB 一点点的变得更加稳定成熟，随着社区的不断变大，TiDB 正以惊人的速度正向迭代，这就是开源的力量。
最后，PingCAP 也刚顺利的完成了 1500 万美金的 B 轮融资，感谢这轮的领投方华创资本，以及跟投方经纬中国，云启资本，峰瑞资本，险峰华兴。我们的征途是星辰大海，感谢有你们的一路支持。
刘奇、黄东旭、崔秋
PingCAP
2017-6-13</description>
    </item>
    
    <item>
      <title>使用 Ansible 安装部署 TiDB</title>
      <link>https://pingcap.com/blog-cn/deployment-by-ansible/</link>
      <pubDate>Thu, 08 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/deployment-by-ansible/</guid>
      <description>背景知识 TiDB 作为一个分布式数据库，在多个节点分别配置安装服务会相当繁琐，为了简化操作以及方便管理，使用自动化工具来批量部署成为了一个很好的选择。
Ansible 是基于 Python 研发的自动化运维工具，糅合了众多老牌运维工具的优点实现了批量操作系统配置、批量程序的部署、批量运行命令等功能，而且使用简单，仅需在管理工作站上安装 Ansible 程序配置被管控主机的 IP 信息，被管控的主机无客户端。基于以上原因，我们选用自动化工具 Ansible 来批量的安装配置以及部署 TiDB。
下面我们来介绍如何使用 Ansible 来部署 TiDB。
TiDB 安装环境配置如下 操作系统使用 CentOS7.2 或者更高版本，文件系统使用 EXT4。
 说明：低版本的操作系统(例如 CentOS6.6 )和 XFS 文件系统会有一些内核 Bug，会影响性能，我们不推荐使用。
    IP Services     192.168.1.101 PD Prometheus Grafana Pushgateway Node_exporter   192.168.1.102 PD TiDB Node_exporter   192.168.1.103 PD TiDB Node_exporter   192.168.1.104 TiKV Node_exporter   192.168.1.105 Tikv Node_exporter   192.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 谈调度</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-3/</link>
      <pubDate>Tue, 06 Jun 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-3/</guid>
      <description>为什么要进行调度 先回忆一下第一篇文章提到的一些信息，TiKV 集群是 TiDB 数据库的分布式 KV 存储引擎，数据以 Region 为单位进行复制和管理，每个 Region 会有多个 Replica（副本），这些 Replica 会分布在不同的 TiKV 节点上，其中 Leader 负责读/写，Follower 负责同步 Leader 发来的 raft log。了解了这些信息后，请思考下面这些问题：
 如何保证同一个 Region 的多个 Replica 分布在不同的节点上？更进一步，如果在一台机器上启动多个 TiKV 实例，会有什么问题？ TiKV 集群进行跨机房部署用于容灾的时候，如何保证一个机房掉线，不会丢失 Raft Group 的多个 Replica？ 添加一个节点进入 TiKV 集群之后，如何将集群中其他节点上的数据搬过来? 当一个节点掉线时，会出现什么问题？整个集群需要做什么事情？如果节点只是短暂掉线（重启服务），那么如何处理？如果节点是长时间掉线（磁盘故障，数据全部丢失），需要如何处理？ 假设集群需要每个 Raft Group 有 N 个副本，那么对于单个 Raft Group 来说，Replica 数量可能会不够多（例如节点掉线，失去副本），也可能会过于多（例如掉线的节点又回复正常，自动加入集群）。那么如何调节 Replica 个数？ 读/写都是通过 Leader 进行，如果 Leader 只集中在少量节点上，会对集群有什么影响？ 并不是所有的 Region 都被频繁的访问，可能访问热点只在少数几个 Region，这个时候我们需要做什么？ 集群在做负载均衡的时候，往往需要搬迁数据，这种数据的迁移会不会占用大量的网络带宽、磁盘 IO 以及 CPU？进而影响在线服务？  这些问题单独拿出可能都能找到简单的解决方案，但是混杂在一起，就不太好解决。有的问题貌似只需要考虑单个 Raft Group 内部的情况，比如根据副本数量是否足够多来决定是否需要添加副本。但是实际上这个副本添加在哪里，是需要考虑全局的信息。整个系统也是在动态变化，Region 分裂、节点加入、节点失效、访问热点变化等情况会不断发生，整个调度系统也需要在动态中不断向最优状态前进，如果没有一个掌握全局信息，可以对全局进行调度，并且可以配置的组件，就很难满足这些需求。因此我们需要一个中心节点，来对系统的整体状况进行把控和调整，所以有了 PD 这个模块。</description>
    </item>
    
    <item>
      <title>【Infra Meetup No.45】Rust in TiKV</title>
      <link>https://pingcap.com/blog-cn/rust-in-tikv/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/rust-in-tikv/</guid>
      <description>本文整理自 4 月 16 日 Rust 专场 Meetup 上，我司首席架构师唐刘同学的现场分享，共享给大家。enjoy~
 Hello everyone, today I will talk about how we use Rust in TiKV.
Before we begin, let me introduce myself. My name is TangLiu, the Chief Architect of PingCAP. Before I joined PingCAP, I had worked at Kingsoft and Tencent. I love open source and have developed some projects like LedisDB, go-mysql, etc…
At first, I will explain the reason why we chose Rust to develop TiKV, then show you the architecture of TiKV briefly and the key technologies.</description>
    </item>
    
    <item>
      <title>工欲性能调优，必先利其器（1）</title>
      <link>https://pingcap.com/blog-cn/iostat-perf-strace/</link>
      <pubDate>Wed, 31 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/iostat-perf-strace/</guid>
      <description>使用 iostat 定位磁盘问题 在一个性能测试集群，我们选择了 AWS c3.4xlarge 机型，主要是为了在一台机器的两块盘上面分别跑 TiKV。在测试一段时间之后，我们发现有一台 TiKV 响应很慢，但是 RocksDB 并没有相关的 Stall 日志，而且慢查询也没有。
于是我登上 AWS 机器，使用 iostat -d -x -m 5 命令查看，得到如下输出：
Device: rrqm/s wrqm/s r/s w/s rMB/s wMB/s avgrq-sz avgqu-sz await r_await w_await svctm %util xvda 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 xvdb 8.00 12898.00 543.00 579.00 31.66 70.15 185.84 51.93 54.39 7.03 98.79 0.60 66.80 xvdc 0.00 0.00 206.00 1190.</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说计算</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-2/</link>
      <pubDate>Wed, 24 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-2/</guid>
      <description>关系模型到 Key-Value 模型的映射 在这我们将关系模型简单理解为 Table 和 SQL 语句，那么问题变为如何在 KV 结构上保存 Table 以及如何在 KV 结构上运行 SQL 语句。 假设我们有这样一个表的定义：
CREATE TABLE User { ID int, Name varchar(20), Role varchar(20), Age int, PRIMARY KEY (ID)， Key idxAge (age) }; SQL 和 KV 结构之间存在巨大的区别，那么如何能够方便高效地进行映射，就成为一个很重要的问题。一个好的映射方案必须有利于对数据操作的需求。那么我们先看一下对数据的操作有哪些需求，分别有哪些特点。
对于一个 Table 来说，需要存储的数据包括三部分：
 表的元信息 Table 中的 Row 索引数据  表的元信息我们暂时不讨论，会有专门的章节来介绍。 对于 Row，可以选择行存或者列存，这两种各有优缺点。TiDB 面向的首要目标是 OLTP 业务，这类业务需要支持快速地读取、保存、修改、删除一行数据，所以采用行存是比较合适的。
对于 Index，TiDB 不止需要支持 Primary Index，还需要支持 Secondary Index。Index 的作用的辅助查询，提升查询性能，以及保证某些 Constraint。查询的时候有两种模式，一种是点查，比如通过 Primary Key 或者 Unique Key 的等值条件进行查询，如 select name from user where id=1; ，这种需要通过索引快速定位到某一行数据；另一种是 Range 查询，如 select name from user where age &amp;gt; 30 and age &amp;lt; 35;，这个时候需要通过idxAge索引查询 age 在 30 和 35 之间的那些数据。Index 还分为 Unique Index 和 非 Unique Index，这两种都需要支持。</description>
    </item>
    
    <item>
      <title>三篇文章了解 TiDB 技术内幕 - 说存储</title>
      <link>https://pingcap.com/blog-cn/tidb-internal-1/</link>
      <pubDate>Mon, 15 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-internal-1/</guid>
      <description>引言 数据库、操作系统和编译器并称为三大系统，可以说是整个计算机软件的基石。其中数据库更靠近应用层，是很多业务的支撑。这一领域经过了几十年的发展，不断的有新的进展。
很多人用过数据库，但是很少有人实现过一个数据库，特别是实现一个分布式数据库。了解数据库的实现原理和细节，一方面可以提高个人技术，对构建其他系统有帮助，另一方面也有利于用好数据库。
研究一门技术最好的方法是研究其中一个开源项目，数据库也不例外。单机数据库领域有很多很好的开源项目，其中 MySQL 和 PostgreSQL 是其中知名度最高的两个，不少同学都看过这两个项目的代码。但是分布式数据库方面，好的开源项目并不多。 TiDB 目前获得了广泛的关注，特别是一些技术爱好者，希望能够参与这个项目。由于分布式数据库自身的复杂性，很多人并不能很好的理解整个项目，所以我希望能写一些文章，自顶向上，由浅入深，讲述 TiDB 的一些技术原理，包括用户可见的技术以及大量隐藏在 SQL 界面后用户不可见的技术点。
保存数据 数据库最根本的功能是能把数据存下来，所以我们从这里开始。
保存数据的方法很多，最简单的方法是直接在内存中建一个数据结构，保存用户发来的数据。比如用一个数组，每当收到一条数据就向数组中追加一条记录。这个方案十分简单，能满足最基本，并且性能肯定会很好，但是除此之外却是漏洞百出，其中最大的问题是数据完全在内存中，一旦停机或者是服务重启，数据就会永久丢失。
为了解决数据丢失问题，我们可以把数据放在非易失存储介质（比如硬盘）中。改进的方案是在磁盘上创建一个文件，收到一条数据，就在文件中 Append 一行。OK，我们现在有了一个能持久化存储数据的方案。但是还不够好，假设这块磁盘出现了坏道呢？我们可以做 RAID （Redundant Array of Independent Disks），提供单机冗余存储。如果整台机器都挂了呢？比如出现了火灾，RAID 也保不住这些数据。我们还可以将存储改用网络存储，或者是通过硬件或者软件进行存储复制。到这里似乎我们已经解决了数据安全问题，可以松一口气了。But，做复制过程中是否能保证副本之间的一致性？也就是在保证数据不丢的前提下，还要保证数据不错。保证数据不丢不错只是一项最基本的要求，还有更多令人头疼的问题等待解决：
 能否支持跨数据中心的容灾？ 写入速度是否够快？ 数据保存下来后，是否方便读取？ 保存的数据如何修改？如何支持并发的修改？ 如何原子地修改多条记录？  这些问题每一项都非常难，但是要做一个优秀的数据存储系统，必须要解决上述的每一个难题。 为了解决数据存储问题，我们开发了 TiKV 这个项目。接下来我向大家介绍一下 TiKV 的一些设计思想和基本概念。
Key-Value 作为保存数据的系统，首先要决定的是数据的存储模型，也就是数据以什么样的形式保存下来。TiKV 的选择是 Key-Value 模型，并且提供有序遍历方法。简单来讲，可以将 TiKV 看做一个巨大的 Map，其中 Key 和 Value 都是原始的 Byte 数组，在这个 Map 中，Key 按照 Byte 数组总的原始二进制比特位比较顺序排列。 大家这里需要对 TiKV 记住两点：
 这是一个巨大的 Map，也就是存储的是 Key-Value pair 这个 Map 中的 Key-Value pair 按照 Key 的二进制顺序有序，也就是我们可以 Seek 到某一个 Key 的位置，然后不断的调用 Next 方法以递增的顺序获取比这个 Key 大的 Key-Value  讲了这么多，有人可能会问了，这里讲的存储模型和 SQL 中表是什么关系？在这里有一件重要的事情要说四遍：</description>
    </item>
    
    <item>
      <title>基于 Tile 连接 Row-Store 和 Column-Store</title>
      <link>https://pingcap.com/blog-cn/tile-row-store/</link>
      <pubDate>Sun, 14 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tile-row-store/</guid>
      <description>在之前的 Kudu 的文章里面，我已经提到过，行列混存是一个非常有意思的研究方向，因为不同的存储方式有不同的针对应用场景，但作为技术人员，折腾是天性，所以大家都在研究如何融合行存和列存，让一个服务能尽量满足大部分应用需求，而这也是 TiDB 在努力的方向。
在 Kudu Paper 里面说到，Kudu 首先在 mem 里面使用行存，但刷到硬盘之后，则使用的是列存，这当然是一个可以尝试的方式，但我觉得应该还有更多种的解决方式，于是找到了 CMU 的 Peloton 以及相关的 Paper，觉得有必要研究记录一下。
Storage Model 很多时候，我喜欢用行存和列存，但看 Paper 的时候，发现都喜欢使用 NSM 和 DSM 来说明，这里就简单说明一下。
NSM NSM 是 N-ary storage model 的简称，当然就是通常的行存了。NSM 主要针对 OLTP 场景，因为需要高性能的随机写入，NSM 的存储方式如下：
NSM 不适用需要读取大量数据，并分析特定 column 的场景，因为 NSM 需要把整个 record 给读出来，在拿到对应的 column 数据分析，数据数据量很大，整个开销会很大。
DSM DSM 是 decomposition storage model 的简称，也就是列存。DSM 主要针对 OLAP 场景，因为需要对一些特定的 column 进行快速扫描分析，DSM 的存储方式如下：
DSM 当然就不适用与需要频繁随机更新的情况，因为任何写入，DSM 需要将 record 分开写入到不同的地方，写开销会很大。
FSM 为了解决这个问题，就有了一个 FSM flexible storage model 来融合 NSM 和 DSM，在 Peloton 里面，它把这套系统叫做 HTAP (Hybrid Transactional/Analytical Processing)，</description>
    </item>
    
    <item>
      <title>Kudu - 一个融合低延迟写入和高性能分析的存储系统</title>
      <link>https://pingcap.com/blog-cn/kudu/</link>
      <pubDate>Mon, 08 May 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/kudu/</guid>
      <description>Kudu 是一个基于 Raft 的分布式存储系统，它致力于融合低延迟写入和高性能分析这两种场景，并且能很好的嵌入到 Hadoop 生态系统里面，跟其他系统譬如 Cloudera Impala，Apache Spark 等对接。
Kudu 很类似 TiDB。最开始，TiDB 是为了 OLTP 系统设计的，但后来发现我们 OLAP 的功能也越来越强大，所以就有了融合 OLTP 和 OLAP 的想法，当然这条路并不是那么容易，我们还有很多工作要做。因为 Kudu 的理念跟我们类似，所以我也很有兴趣去研究一下它，这里主要是依据 Kudu 在 2015 发布的 paper，因为 Kudu 是开源的，并且在不断的更新，所以现在代码里面一些实现可能还跟 paper 不一样了，但这里仅仅先说一下我对 paper 的理解，实际的代码我后续研究了在详细说明。
为什么需要 Kudu？ 结构化数据存储系统在 Hadoop 生态系统里面，通常分为两类：
 静态数据，数据通常都是使用二进制格式存放到 HDFS 上面，譬如 Apache Avro，Apache Parquet。但无论是 HDFS 还是相关的系统，都是为高吞吐连续访问数据这些场景设计的，都没有很好的支持单独 record 的更新，或者是提供好的随机访问的能力。
 动态数据，数据通常都是使用半结构化的方式存储，譬如 Apache HBase，Apache Cassandra。这些系统都能低延迟的读写单独的 record，但是对于一些像 SQL 分析这样需要连续大量读取数据的场景，显得有点捉紧见拙。
  上面的两种系统，各有自己的侧重点，一类是低延迟的随机访问特定数据，而另一类就是高吞吐的分析大量数据。之前，我们并没有这样的系统可以融合上面两种情况，所以通常的做法就是使用 pipeline，譬如我们非常熟悉的 Kafka，通常我们会将数据快速写到 HBase 等系统里面，然后通过 pipeline，在导出给其它分析系统。虽然我们在一定层面上面，我们其实通过 pipeline 来对整个系统进行了解耦，但总归要维护多套系统。而且数据更新之后，并不能直接实时的进行分析处理，有延迟的开销。所以在某些层面上面，并不是一个很好的解决方案。</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：Cloud-Native 的分布式数据库架构与实践</title>
      <link>https://pingcap.com/blog-cn/talk-cloud-native/</link>
      <pubDate>Sat, 22 Apr 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-cloud-native/</guid>
      <description>4 月 19 日，我司 CTO 黄东旭同学在全球云计算开源大会上，发表了《Cloud-Native 的分布式数据库架构与实践》主题演讲，以下为演讲实录。
实录 大家好，今天我的题目是 Cloud-Native 与分布式数据库的实践。先简单的介绍一下自己，我是 PingCAP 的联合创始人和 CTO，过去一直在做基础软件领域的工程师，基本上做的所有的东西都是开源。在分享之前我想说一下为什么现在各行各业或者整个技术软件社区一直在重复的再造数据库，现在数据库到底怎么了，为什么这么百花齐放？
 首先随着业务的多种多样，还有不管是传统行业还是互联网行业，业务的迭代速度越来越互联网化，使得整个数据量其实是一直在往上走的；
 第二就是随着 IOT 的设备还有包括像手机、移动互联网蓬勃的发展，终端其实也不再仅仅是传统的 PC 客户端的数据的接入；
 第三方面随着现在 AI 或者大数据分析一些模型或者理论上的突破，使得在大数据上进行计算的手段越来越多样，还有在物理上一些硬件的新的带有保护的内存，各种各样新的物理的设备，越来越多的硬件或者物理上的存储成本持续的降低，使得我们的数据库需要要面对更多的挑战。
  关联数据库理论是上世纪七十年代做出来的东西，现在四十年过去不管是物理的环境还是计算模型都是完全不一样的阶段，还抱着过去这种观念可能并不是一个面向未来的设计。而且今天我的题目是 Cloud-Native，有一个比较大胆的假设，大家在过去三十年的计算平台基本都是在一台 PC 或者一个服务器或者一个手机这样的独立的计算平台，但是未来我觉得一切的服务都应该是分布式的。因为我觉得摩尔定律已经失效了，所以未来的操作系统会是一个大规模分布式的操作系统，在上面跑的任何的进程，任何的服务都应该是分布式的，在这个假设下怎么去做设计，云其实是这个假设最好的载体。怎么在这个假设上去设计面向云的技术软件，其实是最近我一直在思考的一个问题。其实在这个时代包括面向云的软件，对业务开发来说尽量还是不要太多的改变过去的开发习惯。你看最近大数据的发展趋势，从最传统的关系数据库到过去十年相比，整个改变了用户的编程模型，但是改变到底是好的还是不好的，我个人觉得其实并不是太好。最近这两年大家会看到整个学术圈各种各样的论文都在回归，包括 DB 新时代的软件都会把扩展性和分布式放在第一个要素。
大家可能听到主题会有点蒙，叫 Cloud-Native，Cloud-Native 是什么？其实很早的过去也不是没有人做过这种分布式系统的尝试，最早是 IBM 提出面向服务的软件架构设计，最近热门的 SOA、Micro Service 把自己的服务拆分成小的服务，到现在谷歌一直对外输出一个观点就是 Cloud-Native，就是未来大家的业务看上去的分布式会变成一个更加透明的概念，就是你怎么让分布式的复杂性消失在云的基础设施后，这是 Cloud-Native 更加关心的事情。
这个图是 CNCF 的一个基金会，也是谷歌支持的基金会上扒过来的图。这里面有一个简单的定义，就是 SCALE 作为一等公民，面向 Cloud-Native 的业务必须是弹性伸缩的，不仅能伸也得能缩；第二就是在对于这种 Cloud-Native 业务来说是面向 Micro service 友好；第三就是部署更加的去人工化。
最近大家可能也看到很多各种各样容器化的方案，背后代表的意义是什么？就是整个运维和部署脱离人工，大家可以想象过去十几二十年来，一直以来运维的手段是什么样的。我找了一个运维，去买服务器，买服务器装系统，在上面部署业务。但是现在 Cloud-Native 出现变得非常的自动化，就相当于把人的功能变得更低，这是很有意义的，因为理想中的世界或者未来的世界应该怎么样，一个业务可能会有成百上千的物理节点，如果是人工的去做运维和部署是根本不可能做得到的，所以其实构建整个 Cloud-Native 的基础设施的两个条件：第一个就是存储本身的云化；第二就是运维要和部署的方式必须是云化的。
我就从这两个点说一下我们 TiDB 在上面的一些工作和一些我的思考。
存储本身的云化有几个基本条件，大家过去认为是高可用，主要停留在双活。其实仔细去思考的话，主备的方案是很难保证数据在完全不需要人工的介入情况下数据的一致性可用性的，所以大家会发现最近这几年出来的分布式存储系统的可用性的协议跟复制协议基本都会用类似 Raft/Paxos 基于选取的一致性算法，不会像过去做这种老的复制的方案。
第二就是整个分片的策略，作为分布式系统数据一定是会分片的，数据分片是来做分布式存储唯一的思路，自动分片一定会取代传统的人工分片来去支撑业务。比如传统分片，当你的数据量越来越大，你只能做分库分表或者用中间件，不管你分库分表还是中间件都必须制订自己人工的分辨规则，但是其实在一个真正面向 Cloud 的数据库设计里，任何一种人的介入的东西都是不对的。</description>
    </item>
    
    <item>
      <title>如何从零开始参与大型开源项目</title>
      <link>https://pingcap.com/blog-cn/how-to-contribute/</link>
      <pubDate>Mon, 27 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-contribute/</guid>
      <description>写在前面的话 上世纪 70 年代，IBM 发明了关系型数据库。但是随着现在移动互联网的发展，接入设备越来越多，数据量越来越大，业务越来越复杂，传统的数据库显然已经不能满足海量数据存储的需求。虽然目前市场上也不乏分布式数据库模型，但没有品位的文艺青年不是好工程师，我们觉得，不，这些方案都不是我们想要的，它们不够美，鲜少能够把分布式事务与弹性扩展做到完美。
受 Google Spanner/F1 的启发，一款从一开始就选择了开源道路的 TiDB 诞生了。 它是一款代表未来的新型分布式 NewSQL 数据库，它可以随着数据增长而无缝水平扩展，只需要通过增加更多的机器来满足业务增长需求，应用层可以不用关心存储的容量和吞吐，用东旭的话说就是「他自己会生长」。
在开源的世界里，TiDB 和 TiKV 吸引了更多的具有极客气质的开发者，目前已经拥有超过 9000 个 star 和 100 个 Contributor，这已然是一个世界顶级开源项目的水准。而成就了这一切的，则是来自社区的力量。
最近我们收到了很多封这样的邮件和留言，大家说：
 “谢谢你们，使得旁人也能接触大型开源项目。本身自己是 DBA，对数据库方面较干兴趣，也希望自己能逐步深入数据库领域，深入TiDB，为 TiDB 社区贡献更多、更有价值的力量。”
 “我是一个在校学生，刚刚收到邮件说我成为了 TiDB 的 Contributor，这让我觉得当初没听父母的话坚持了自己喜欢的计算机技术，是个正确的选择，但我还需要更多的历练，直到能完整地展现、表达我的思维。”
  这让我感触颇多，因为，应该是我们感谢你们才是啊，没有社区，一个开源项目就成不了一股清泉甚至一汪海洋。
公司的小姑娘说，她觉得还有很多的人想要参与进来的，可工程师团队欠缺平易近人的表达，这个得改。
于是便有了这篇文章以及未来的多篇文章和活动，我们欢迎所有的具有气质的开发者能和 TiDB 一起成长，一起见证数据库领域的革新，改变世界这事儿有时候也不那么难。
我要重点感谢今天这篇文章的作者，来自社区的朱武（GitHub ID: viile ）、小卢（GitHub ID: lwhhhh ）和杨文（GitHub ID: yangwenmai），当在 TiDB Contributor Club 里提到想要做这件事的时候，是他们踊跃地加入了 TiDB Tech Writer 的队伍，高效又专业地完成了下文的编辑，谢谢你们。
一个典型的开源项目是由什么组成的 The Community（社区）  一个项目经常会有一个围绕着它的社区，这个社区由各个承担不同角色的用户组成。
 项目的拥有者：在他们账号中创建项目并拥有它的用户或者组织。
 维护者和合作者：主要做项目相关的工作和推动项目发展，通常情况下拥有者和维护者是同一个人，他们拥有仓库的写入权限。</description>
    </item>
    
    <item>
      <title>十分钟成为 TiDB Contributor 系列 | 添加內建函数</title>
      <link>https://pingcap.com/blog-cn/add-a-built-in-function/</link>
      <pubDate>Tue, 14 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/add-a-built-in-function/</guid>
      <description>背景知识 SQL 语句发送到 TiDB 后首先会经过 parser，从文本 parse 成为 AST（抽象语法树），通过 Query Optimizer 生成执行计划，得到一个可以执行的 plan，通过执行这个 plan 即可得到结果，这期间会涉及到如何获取 table 中的数据，如何对数据进行过滤、计算、排序、聚合、滤重以及如何对表达式进行求值。 对于一个 builtin 函数，比较重要的是进行语法解析以及如何求值。其中语法解析部分需要了解如何写 yacc 以及如何修改 TiDB 的词法解析器，较为繁琐，我们已经将这部分工作提前做好，大多数 builtin 函数的语法解析工作已经做完。 对 builtin 函数的求值需要在 TiDB 的表达式求值框架下完成，每个 builtin 函数被认为是一个表达式，用一个 ScalarFunction 来表示，每个 builtin 函数通过其函数名以及参数，获取对应的函数类型以及函数签名，然后通过函数签名进行求值。 总体而言，上述流程对于不熟悉 TiDB 的朋友而言比较复杂，我们对这部分做了些工作，将一些流程性、较为繁琐的工作做了统一处理，目前已经将大多数未实现的 buitlin 函数的语法解析以及寻找函数签名的工作完成，但是函数实现部分留空。换句话说，只要找到留空的函数实现，将其补充完整，即可作为一个 PR。
添加 builtin 函数整体流程  找到未实现的函数
在 TiDB 源码中的 expression 目录下搜索 errFunctionNotExists，即可找到所有未实现的函数，从中选择一个感兴趣的函数，比如 SHA2 函数：
func (b *builtinSHA2Sig) eval(row []types.Datum) (d types.Datum, err error) { return d, errFunctionNotExists.GenByArgs(&amp;#34;SHA2&amp;#34;) } 实现函数签名</description>
    </item>
    
    <item>
      <title>TiKV 功能介绍 - Raft 的优化</title>
      <link>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</link>
      <pubDate>Tue, 07 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/optimizing-raft-in-tikv/</guid>
      <description>在分布式领域，为了保证数据的一致性，通常都会使用 Paxos 或者 Raft 来实现。但 Paxos 以其复杂难懂著称，相反 Raft 则是非常简单易懂，所以现在很多新兴的数据库都采用 Raft 作为其底层一致性算法，包括我们的 TiKV。
当然，Raft 虽然简单，但如果单纯的按照 Paper 的方式去实现，性能是不够的。所以还需要做很多的优化措施。本文假定用户已经熟悉并了解过 Raft 算法，所以对 Raft 不会做过多说明。
Simple Request Flow 这里首先介绍一下一次简单的 Raft 流程：
 Leader 收到 client 发送的 request。 Leader 将 request append 到自己的 log。 Leader 将对应的 log entry 发送给其他的 follower。 Leader 等待 follower 的结果，如果大多数节点提交了这个 log，则 apply。 Leader 将结果返回给 client。 Leader 继续处理下一次 request。  可以看到，上面的流程是一个典型的顺序操作，如果真的按照这样的方式来写，那性能是完全不行的。
Batch and Pipeline 首先可以做的就是 batch，大家知道，在很多情况下面，使用 batch 能明显提升性能，譬如对于 RocksDB 的写入来说，我们通常不会每次写入一个值，而是会用一个 WriteBatch 缓存一批修改，然后在整个写入。 对于 Raft 来说，Leader 可以一次收集多个 requests，然后一批发送给 Follower。当然，我们也需要有一个最大发送 size 来限制每次最多可以发送多少数据。</description>
    </item>
    
    <item>
      <title>TiDB 的正确使用姿势</title>
      <link>https://pingcap.com/blog-cn/how-to-use-tidb/</link>
      <pubDate>Sat, 04 Mar 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-to-use-tidb/</guid>
      <description>最近这几个月，特别是 TiDB RC1 发布后，越来越多的用户已经开始测试起来，也有很多朋友已经在生产环境中使用，我们这边也陆续的收到了很多用户的测试和使用反馈。非常感谢各位小伙伴和早期用户的厚爱，而且看了这么多场景后，也总结出了一些 TiDB 的使用实践 (其实 Spanner 的最佳实践大部分在 TiDB 中也是适用的，MySQL 最佳实践也是），也是借着 Google Cloud Spanner 发布的东风，看了一下 Spanner 官方的一些最佳实践文档，写篇文章讲讲 TiDB 以及分布式关系型数据库的一些正确的使用姿势，当然，时代也在一直发展，TiDB 也在不停的进化，这篇文章基本上只代表近期的一些观察。
 首先谈谈 Schema 设计的一些比较好的经验。由于 TiDB 是一个分布式的数据库，可能在表结构设计的时候需要考虑的事情和传统的单机数据库不太一样，需要开发者能够带着「这个表的数据会分散在不同的机器上」这个前提，才能做更好的设计。
和 Spanner 一样，TiDB 中的一张表的行（Rows）是按照主键的字节序排序的（整数类型的主键我们会使用特定的编码使其字节序和按大小排序一致），即使在 CREATE TABLE 语句中不显式的创建主键，TiDB 也会分配一个隐式的。 有四点需要记住： 1. 按照字节序的顺序扫描的效率是比较高的； 2. 连续的行大概率会存储在同一台机器的邻近位置，每次批量的读取和写入的效率会高； 3. 索引是有序的（主键也是一种索引），一行的每一列的索引都会占用一个 KV Pair，比如，某个表除了主键有 3 个索引，那么在这个表中插入一行，对应在底层存储就是 4 个 KV Pairs 的写入：数据行以及 3 个索引行。 4. 一行的数据都是存在一个 KV Pair 中，不会被切分，这点和类 BigTable 的列式存储很不一样。
表的数据在 TiDB 内部会被底层存储 TiKV 切分成很多 64M 的 Region（对应 Spanner 的 Splits 的概念），每个 Region 里面存储的都是连续的行，Region 是 TiDB 进行数据调度的单位，随着一个 Region 的数据量越来越大和时间的推移，Region 会分裂/合并，或者移动到集群中不同的物理机上，使得整个集群能够水平扩展。</description>
    </item>
    
    <item>
      <title>Spanner - CAP, TrueTime and Transaction</title>
      <link>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/Spanner-cap-truetime-transaction/</guid>
      <description>最近非常关注的一件事情就是 Google Spanner Cloud 的发布，这应该算是 NewSQL 又一个里程碑的事件。NewSQL 的概念应该就是在 12 年 Google Spanner 以及 F1 的论文发表之后，才开始慢慢流行，然后就开始有企业尝试根据 paper 做自己的 NewSQL，譬如国外的 CockroachDB 以及国内我们 PingCAP。
Spanner 的论文在很早就发布了，国内也有很多中文翻译，这里笔者只是想聊聊自己对 Spanner 的理解，以及 Spanner 的一些关键技术的实现，以及跟我们自己的 TiDB 的相关对比。
CAP 在分布式领域，CAP 是一个完全绕不开的东西，大家应该早就非常熟悉，这里笔者只是简单的再次说明一下：
 C：一致性，也就是通常说的线性一致性，假设在 T 时刻写入了一个值，那么在 T 之后的读取一定要能读到这个最新的值。 A：完全 100% 的可用性，也就是无论系统发生任何故障，都仍然能对外提供服务。 P：网络分区容忍性。  在分布式环境下面，P 是铁定存在的，也就是只要我们有多台机器，那么网络隔离分区就一定不可避免，所以在设计系统的时候我们就要选择到底是设计的是 AP 系统还是 CP 系统，但实际上，我们只要深入理解下 CAP，就会发现其实有时候系统设计上面没必要这么纠结，主要表现在：
 网络分区出现的概率很低，所以我们没必要去刻意去忽略 C 或者 A。多数时候，应该是一个 CA 系统。 CAP 里面的 A 是 100% 的可用性，但实际上，我们只需要提供 high availability，也就是仅仅需要满足 99.99% 或者 99.999% 等几个 9 就可以了。  Spanner 是一个 CP + HA 系统，官方文档说的可用性是优于 5 个 9 ，稍微小于 6 个 9，也就是说，Spanner 在系统出现了大的故障的情况下面，大概 31s+ 的时间就能够恢复对外提供服务，这个时间是非常短暂的，远远比很多外部的系统更加稳定。然后鉴于 Google 强大的自建网络，P 很少发生，所以 Spanner 可以算是一个 CA 系统。</description>
    </item>
    
    <item>
      <title>TiKV 功能介绍 - Lease Read</title>
      <link>https://pingcap.com/blog-cn/lease-read/</link>
      <pubDate>Tue, 21 Feb 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/lease-read/</guid>
      <description>Raft log read TiKV 是一个要保证线性一致性的分布式 KV 系统，所谓线性一致性，一个简单的例子就是在 t1 的时间我们写入了一个值，那么在 t1 之后，我们的读一定能读到这个值，不可能读到 t1 之前的值。
因为 Raft 本来就是一个为了实现分布式环境下面线性一致性的算法，所以我们可以通过 Raft 非常方便的实现线性 read，也就是将任何的读请求走一次 Raft log，等这个 log 提交之后，在 apply 的时候从状态机里面读取值，我们就一定能够保证这个读取到的值是满足线性要求的。
当然，大家知道，因为每次 read 都需要走 Raft 流程，所以性能是非常的低效的，所以大家通常都不会使用。
我们知道，在 Raft 里面，节点有三个状态，leader，candidate 和 follower，任何 Raft 的写入操作都必须经过 leader，只有 leader 将对应的 raft log 复制到 majority 的节点上面，我们才会认为这一次写入是成功的。所以我们可以认为，如果当前 leader 能确定一定是 leader，那么我们就可以直接在这个 leader 上面读取数据，因为对于 leader 来说，如果确认一个 log 已经提交到了大多数节点，在 t1 的时候 apply 写入到状态机，那么在 t1 之后后面的 read 就一定能读取到这个新写入的数据。
那么如何确认 leader 在处理这次 read 的时候一定是 leader 呢？在 Raft 论文里面，提到了两种方法。</description>
    </item>
    
    <item>
      <title>TiKV 功能介绍 - PD Scheduler</title>
      <link>https://pingcap.com/blog-cn/pd-scheduler/</link>
      <pubDate>Mon, 23 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/pd-scheduler/</guid>
      <description>在前面的文章里面，我们介绍了 PD 一些常用功能，以及它是如何跟 TiKV 进行交互的，这里，我们重点来介绍一下 PD 是如何调度 TiKV 的。
介绍 假设我们只有一个 TiKV，那么根本就无需调度了，因为数据只可能在这一台机器上面，client 也只可能跟这一个 TiKV 进行交互。但我们知道，在分布式存储领域，这样的情况不可能一直持续，因为数据量的增量一定会超过当前机器的物理存储极限，必然我们需要将一部分数据迁移到其他机器上面去。
在之前的文章里面，我们介绍过，TiKV 是通过 range 的方式将数据进行切分的。我们使用 Region 来表示一个数据 range，每个 Region 有多个副本 peer，通常为了安全，我们会使用至少三个副本。
最开始系统初始化的时候，我们只有一个 region，当数据量持续增大，超过了 Region 设置的最大 size（64MB） 阈值的时候，region 就会分裂，生成两个新的 region。region 是 PD 调度 TiKV 的基本单位。当我们新增加一个 TiKV 的时候，PD 就会将原来TiKV 里面的一些 Region 调度到这个新增的 TiKV 上面，这样就能保证整个数据均衡的分布在多个 TiKV 上面。因为一个 Region 通常是 64MB，其实将一个 Region 从一个 TiKV 移动到另一个 TiKV，数据量的变更其实不大，所以我们可以直接使用 Region 的数量来大概的做数据的平衡。譬如，现在假设有六个 TiKV，我们有一百个 region，每个 Region 三个副本 peer，总共三百个 Region peer，我们只要保证每个 TiKV 有五十个左右的 Region peer，就大概知道数据是平衡了。</description>
    </item>
    
    <item>
      <title>TiKV 功能介绍 - Placement Driver</title>
      <link>https://pingcap.com/blog-cn/placement-driver/</link>
      <pubDate>Sun, 08 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/placement-driver/</guid>
      <description>介绍 Placement Driver (后续以 PD 简称) 是 TiDB 里面全局中心总控节点，它负责整个集群的调度，负责全局 ID 的生成，以及全局时间戳 TSO 的生成等。PD 还保存着整个集群 TiKV 的元信息，负责给 client 提供路由功能。
作为中心总控节点，PD 通过集成 etcd ，自动的支持 auto failover，无需担心单点故障问题。同时，PD 也通过 etcd 的 raft，保证了数据的强一致性，不用担心数据丢失的问题。
在架构上面，PD 所有的数据都是通过 TiKV 主动上报获知的。同时，PD 对整个 TiKV 集群的调度等操作，也只会在 TiKV 发送 heartbeat 命令的结果里面返回相关的命令，让 TiKV 自行去处理，而不是主动去给 TiKV 发命令。这样设计上面就非常简单，我们完全可以认为 PD 是一个无状态的服务（当然，PD 仍然会将一些信息持久化到 etcd），所有的操作都是被动触发，即使 PD 挂掉，新选出的 PD leader 也能立刻对外服务，无需考虑任何之前的中间状态。
初始化 PD 集成了 etcd，所以通常，我们需要启动至少三个副本，才能保证数据的安全。现阶段 PD 有集群启动方式，initial-cluster 的静态方式以及 join 的动态方式。
在继续之前，我们需要了解下 etcd 的端口，在 etcd 里面，默认要监听 2379 和 2380 两个端口。2379 主要是 etcd 用来处理外部请求用的，而 2380 则是 etcd peer 之间相互通信用的。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - multi-raft 设计与实现</title>
      <link>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</link>
      <pubDate>Tue, 03 Jan 2017 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/the-design-and-implementation-of-multi-raft/</guid>
      <description>本文档主要面向 TiKV 社区开发者，主要介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读文档之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本文档并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
本文为本系列文章第二节。
Placement Driver 在继续之前，我们先简单介绍一下 Placement Driver(PD)。PD 是 TiKV 的全局中央控制器，存储整个 TiKV 集群的元数据信息，负责整个 TiKV 集群的调度，全局 ID 的生成，以及全局 TSO 授时等。
PD 是一个非常重要的中心节点，它通过集成 etcd，自动的支持了分布式扩展以及 failover，解决了单点故障问题。关于 PD 的详细介绍，后续我们会新开一篇文章说明。
在 TiKV 里面，跟 PD 的交互是放在源码的 pd 目录下，现在跟 PD 的交互都是通过自己定义的 RPC 实现，协议非常简单，在 pd/mod.rs 里面我们直接提供了用于跟 PD 进行交互的 Client trait，以及实现了 RPC Client。</description>
    </item>
    
    <item>
      <title>TiKV 源码解析系列 - 如何使用 Raft</title>
      <link>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</link>
      <pubDate>Mon, 26 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tikv-how-to-use-raft/</guid>
      <description>本系列文章主要面向 TiKV 社区开发者，重点介绍 TiKV 的系统架构，源码结构，流程解析。目的是使得开发者阅读之后，能对 TiKV 项目有一个初步了解，更好的参与进入 TiKV 的开发中。
需要注意，TiKV 使用 Rust 语言编写，用户需要对 Rust 语言有一个大概的了解。另外，本系列文章并不会涉及到 TiKV 中心控制服务 Placement Driver(PD) 的详细介绍，但是会说明一些重要流程 TiKV 是如何与 PD 交互的。
TiKV 是一个分布式的 KV 系统，它采用 Raft 协议保证数据的强一致性，同时使用 MVCC + 2PC 的方式实现了分布式事务的支持。
 架构 TiKV 的整体架构比较简单，如下：
Placement Driver : Placement Driver (PD) 负责整个集群的管理调度。
Node : Node 可以认为是一个实际的物理机器，每个 Node 负责一个或者多个 Store。
Store : Store 使用 RocksDB 进行实际的数据存储，通常一个 Store 对应一块硬盘。
Region : Region 是数据移动的最小单元，对应的是 Store 里面一块实际的数据区间。每个 Region会有多个副本（replica），每个副本位于不同的 Store ，而这些副本组成了一个 Raft group。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 信心的毁灭与重建</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-3/</link>
      <pubDate>Wed, 07 Dec 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-3/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为下篇。
 -接中篇- ScyllaDB 有一个开源的东西，是专门用来给文件系统做 Failure Injection 的, 名字叫做 CharybdeFS。如果你想测试你的系统，就是文件系统在哪不断出问题，比如说写磁盘失败了，驱动程序分配内存失败了，文件已经存在等等，它都可以测模拟出来。
CharybdeFS: A new fault-injecting file system for software testing
Simulate the following errors:
 disk IO error (EIO) driver out of memory error (ENOMEM) file already exists (EEXIST) disk quota exceeded (EDQUOT)  再来看看 Cloudera，下图是整个 Cloudera 的一个 Failure Injection 的结构。
一边是 Tools，一边是它的整个的 Level 划分。比如说整个 Cluster， Cluster 上面有很多 Host，Host 上面又跑了各种 Service，整个系统主要用于测试 HDFS， HDFS 也是很努力的在做有效的测试。然后每个机器上部署一个 AgenTEST，就用来注射那些可能出现的错误。</description>
    </item>
    
    <item>
      <title>Percolator 和 TiDB 事务算法</title>
      <link>https://pingcap.com/blog-cn/percolator-and-txn/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/percolator-and-txn/</guid>
      <description>本文先概括的讲一下 Google Percolator 的大致流程。Percolator 是 Google 的上一代分布式事务解决方案，构建在 BigTable 之上，在 Google 内部 用于网页索引更新的业务，原始的论文在此。原理比较简单，总体来说就是一个经过优化的二阶段提交的实现，进行了一个二级锁的优化。TiDB 的事务模型沿用了 Percolator 的事务模型。 总体的流程如下：
读写事务 1) 事务提交前，在客户端 buffer 所有的 update/delete 操作。 2) Prewrite 阶段:
首先在所有行的写操作中选出一个作为 primary，其他的为 secondaries。
PrewritePrimary: 对 primaryRow 写入 L 列(上锁)，L 列中记录本次事务的开始时间戳。写入 L 列前会检查:
 是否已经有别的客户端已经上锁 (Locking)。 是否在本次事务开始时间之后，检查 W 列，是否有更新 [startTs, +Inf) 的写操作已经提交 (Conflict)。  在这两种种情况下会返回事务冲突。否则，就成功上锁。将行的内容写入 row 中，时间戳设置为 startTs。
将 primaryRow 的锁上好了以后，进行 secondaries 的 prewrite 流程:
 类似 primaryRow 的上锁流程，只不过锁的内容为事务开始时间及 primaryRow 的 Lock 的信息。 检查的事项同 primaryRow 的一致。  当锁成功写入后，写入 row，时间戳设置为 startTs。</description>
    </item>
    
    <item>
      <title>TiKV 的 MVCC（Multi-Version Concurrency Control）机制</title>
      <link>https://pingcap.com/blog-cn/mvcc-in-tikv/</link>
      <pubDate>Tue, 22 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mvcc-in-tikv/</guid>
      <description>并发控制简介 事务隔离在数据库系统中有着非常重要的作用，因为对于用户来说数据库必须提供这样一个“假象”：当前只有这么一个用户连接到了数据库中，这样可以减轻应用层的开发难度。但是，对于数据库系统来说，因为同一时间可能会存在很多用户连接，那么许多并发问题，比如数据竞争（data race），就必须解决。在这样的背景下，数据库管理系统（简称 DBMS）就必须保证并发操作产生的结果是安全的，通过可串行化（serializability）来保证。
虽然 Serilizability 是一个非常棒的概念，但是很难能够有效的实现。一个经典的方法就是使用一种两段锁（2PL）。通过 2PL，DBMS 可以维护读写锁来保证可能产生冲突的事务按照一个良好的次序（well-defined) 执行，这样就可以保证 Serializability。但是，这种通过锁的方式也有一些缺点：
 读锁和写锁会相互阻滞（block）。 大部分事务都是只读（read-only）的，所以从事务序列（transaction-ordering）的角度来看是无害的。如果使用基于锁的隔离机制，而且如果有一段很长的读事务的话，在这段时间内这个对象就无法被改写，后面的事务就会被阻塞直到这个事务完成。这种机制对于并发性能来说影响很大。  多版本并发控制（Multi-Version Concurrency Control，以下简称 MVCC） 以一种优雅的方式来解决这个问题。在 MVCC 中，每当想要更改或者删除某个数据对象时，DBMS 不会在原地去删除或这修改这个已有的数据对象本身，而是创建一个该数据对象的新的版本，这样的话同时并发的读取操作仍旧可以读取老版本的数据，而写操作就可以同时进行。这个模式的好处在于，可以让读取操作不再阻塞，事实上根本就不需要锁。这是一种非常诱人的特型，以至于在很多主流的数据库中都采用了 MVCC 的实现，比如说 PostgreSQL，Oracle，Microsoft SQL Server 等。
TiKV 中的 MVCC 让我们深入到 TiKV 中的 MVCC，了解 MVCC 在 TiKV 中是如何 实现 的。
1. Timestamp Oracle(TSO) 因为TiKV 是一个分布式的储存系统，它需要一个全球性的授时服务，下文都称作 TSO（Timestamp Oracle），来分配一个单调递增的时间戳。 这样的功能在 TiKV 中是由 PD 提供的，在 Google 的 Spanner 中是由多个原子钟和 GPS 来提供的。
2. Storage 从源码结构上来看，想要深入理解 TiKV 中的 MVCC 部分，src/storage 是一个非常好的入手点。 Storage 是实际上接受外部命令的结构体。</description>
    </item>
    
    <item>
      <title>解析 TiDB 在线数据同步工具 Syncer</title>
      <link>https://pingcap.com/blog-cn/tidb-syncer/</link>
      <pubDate>Mon, 21 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-syncer/</guid>
      <description>TiDB 是一个完全分布式的关系型数据库，从诞生的第一天起，我们就想让它来兼容 MySQL 语法，希望让原有的 MySQL 用户 (不管是单机的 MySQL，还是多机的 MySQL Sharding) 都可以在基本不修改代码的情况下，除了可以保留原有的 SQL 和 ACID 事务之外，还可以享受到分布式带来的高并发，高吞吐和 MPP 的高性能。
对于用户来说，简单易用是他们试用的最基本要求，得益于社区和 PingCAP 小伙伴们的努力，我们提供基于 Binary 和 基于 Kubernetes 的两种不同的一键部署方案来让用户可以在几分钟就可以部署起来一个分布式的 TiDB 集群，从而快速地进行体验。 当然，对于用户来说，最好的体验方式就是从原有的 MySQL 数据库同步一份数据镜像到 TiDB 来进行对比测试，不仅简单直观，而且也足够有说服力。实际上，我们已经提供了一整套的工具来辅助用户在线做数据同步，具体的可以参考我们之前的一篇文章：TiDB 作为 MySQL Slave 实现实时数据同步, 这里就不再展开了。后来有很多社区的朋友特别想了解其中关键的 Syncer 组件的技术实现细节，于是就有了这篇文章。
首先我们看下 Syncer 的整体架构图, 对于 Syncer 的作用和定位有一个直观的印象。
从整体的架构可以看到，Syncer 主要是通过把自己注册为一个 MySQL Slave 的方式，和 MySQL Master 进行通信，然后不断读取 MySQL Binlog，进行 Binlog Event 解析，规则过滤和数据同步。从工程的复杂度上来看，相对来说还是非常简单的，相对麻烦的地方主要是 Binlog Event 解析和各种异常处理，也是容易掉坑的地方。
为了完整地解释 Syncer 的在线同步实现，我们需要有一些额外的内容需要了解。
MySQL Replication 我们先看看 MySQL 原生的 Replication 复制方案，其实原理上也很简单：</description>
    </item>
    
    <item>
      <title>MPP and SMP in TiDB</title>
      <link>https://pingcap.com/blog-cn/mpp-smp-tidb/</link>
      <pubDate>Tue, 15 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/mpp-smp-tidb/</guid>
      <description>今天主要是想把我们 TiDB 做 SQL 性能优化的一些经验和一些思考，就此跟大家探讨一下。题目写的比较大，但是内容还是比较简单。我们做 TiDB 的 SQL 层时，一开始做的很简单，就是通过最简单的 KV 接口(Get/Set/Seek)去存数据、取数据，做一些非常直白、简单的计算。然而后来我们发现，这个方案在性能上不可接受，可能行不通，我们就重新思考了这个事情。
TiDB 的目标是做一个 NewSQL 的 database ，什么是 NewSQL？从 Wikipedia 上我们看到 NewSQL 的定义『NewSQL is a class of modern relational database management systems that seek to provide the same scalable performance of NoSQL systems for online transaction processing (OLTP) read-write workloads while still maintaining the ACID guarantees of a traditional database system.』。首先NewSQL Database 需要能存储海量数据，这点就像一些 NoSQL 数据库一样。然后，能够提供事务的功能。所以 NewSQL 中的计算，主要有两个特点。第一个，就是数据是海量的，这跟 MySQL 传统数据有可能不一样，他们当然可以通过一些 sharding 的方式来进行处理，但是 sharding 之后会损失，比如说你不能跨节点做 Join，没有跨节点事务等。二是，在海量数据情况下，我们还需要对数据进行随时的取用，因为数据存在那，你算不出来就是对用户没有价值、没有意义的，所以我们需要在海量数据的前提下，能够随时把它计算出来。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 错误注入</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-2/</link>
      <pubDate>Thu, 10 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-2/</guid>
      <description>本话题系列文章整理自 PingCAP Infra Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为中篇。
 -接上篇- 当然测试可能会让你代码变得没有那么漂亮，举个例子：
这是知名的 Kubernetes 的代码，就是说它有一个 DaemonSetcontroller，这 controller 里面注入了三个测试点，比如这个地方注入了一个 handler ，你可以认为所有的注入都是 interface。比如说你写一个简单的 1+1=2 的程序，假设我们写一个计算器，这个计算器的功能就是求和，那这就很难注入错误。所以你必须要在你正确的代码里面去注入测试逻辑。再比如别人 call 你的这个 add 的 function，然后你是不是有一个 error？这个 error 的问题是它可能永远不会返回一个 error，所以你必须要人肉的注进去，然后看应用程序是不是正确的行为。说完了加法，再说我们做一个除法。除法大家知道可能有处理异常，那上面是不是能正常处理呢？上面没有，上面写着一个比如说 6 ÷ 3，然后写了一个 test，coverage 100%，但是一个除零异常，系统就崩掉了，所以这时候就需要去注入错误。大名鼎鼎的 Kubernetes 为了测试各种异常逻辑也采用类似的方式，这个结构体不算长，大概是十几个成员，然后里面就注入了三个点，可以在里面注入错误。
那么在设计 TiDB 的时候，我们当时是怎么考虑 test 这个事情的？首先一个百万级的 test 不可能由人肉来写，也就是说你如果重新定义一个自己的所谓的 SQL 语法，或者一个 query language，那这个时候你需要构建百万级的 test，即使全公司去写，写个两年都不够，所以这个事情显然是不靠谱的。但是除非说我的 query language 特别简单，比如像 MongoDB 早期的那种，那我一个“大于多少”的这种，或者 equal 这种条件查询特别简单的，那你确实是不需要构建这种百万级的 test。但是如果做一个 SQL 的 database 的话，那是需要构建这种非常非常复杂的 test 的。这时候这个 test 又不能全公司的人写个两年，对吧？所以有什么好办法呢？MySQL 兼容的各种系统都是可以用来 test 的，所以我们当时兼容 MySQL 协议，那意味着我们能够取得大量的 MySQL test。不知道有没有人统计过 MySQL 有多少个 test，产品级的 test 很吓人的，千万级。然后还有很多 ORM， 支持 MySQL 的各种应用都有自己的测试。大家知道，每个语言都会 build 自己的 ORM，然后甚至是一个语言的 ORM 都有好几个。比如说对于 MySQL 可能有排第一的、排第二的，那我们可以把这些全拿过来用来测试我们的系统。</description>
    </item>
    
    <item>
      <title>TiDB 作为 MySQL Slave 实现实时数据同步</title>
      <link>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</link>
      <pubDate>Thu, 03 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-as-mysql-slave/</guid>
      <description>由于 TiDB 本身兼容绝大多数的 MySQL 语法，所以对于绝大多数业务来说，最安全的切换数据库方式就是将 TiDB 作为现有数据库的从库接在主 MySQL 库的后方，这样对业务方实现完全没有侵入性下使用 TiDB 对现有的业务进行备份，应对未来数据量或者并发量增长带来的单点故障风险，如需上线 TiDB，也只需要简单的将业务的主 MySQL 地址指向 TiDB 即可。
下面我们详细介绍了如何将 MySQL 的数据迁移到 TiDB，并将 TiDB 作为 MySQL 的 Slave 进行数据同步。
这里我们假定 MySQL 以及 TiDB 服务信息如下:
+------------------+-------------+----------------------------------------+ | Name | Address | Port | User | Password | +------------------+-------------+----------------------------------------+ | MySQL | 127.0.0.1 | 3306 | root | | | TiDB | 127.0.0.1 | 4000 | root | | +------------------+-------------+--------+-----------+-------------------+ 使用 checker 进行 Schema 检查 在迁移之前，我们可以使用 TiDB 的 checker 工具，checker 是我们开发的一个小工具，用于检测目标 MySQL 库中的表的表结构是否支持无缝的迁移到 TiDB，TiDB 支持绝大多数的 MySQL 常用的原生数据类型，所以大多数情况 checker 的返回应该是 ok。如果 check 某个 table schema 失败，表明 TiDB 当前并不支持，我们不能对该 table 里面的数据进行迁移。checker 包含在 TiDB 工具集里面，我们可以直接下载。</description>
    </item>
    
    <item>
      <title>分布式系统测试那些事儿 - 理念</title>
      <link>https://pingcap.com/blog-cn/distributed-system-test-1/</link>
      <pubDate>Tue, 01 Nov 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/distributed-system-test-1/</guid>
      <description>本话题系列文章整理自 PingCAP NewSQL Meetup 第 26 期刘奇分享的《深度探索分布式系统测试》议题现场实录。文章较长，为方便大家阅读，会分为上中下三篇，本文为上篇。
 今天主要是介绍分布式系统测试。对于 PingCAP 目前的现状来说，我们是觉得做好分布式系统测试比做一个分布式系统更难。就是你把它写出来不是最难的，把它测好才是最难的。大家肯定会觉得有这么夸张吗？那我们先从一个最简单的、每个人都会写的 Hello world 开始。
A simple “Hello world” is a miracle We should walk through all of the bugs in:
 Compiler Linker VM (maybe) OS  其实这个 Hello world 能够每次都正确运行已经是一个奇迹了，为什么呢？首先，编译器得没 bug，链接器得没 bug ；然后我们可能跑在 VM 上，那 VM 还得没 bug；并且 Hello world 那还有一个 syscall，那我们还得保证操作系统没有 bug；到这还不算吧，我们还得要硬件没有 bug。所以一个最简单程序它能正常运行起来，我们要穿越巨长的一条路径，然后这个路径里面所有的东西都不能出问题，我们才能看到一个最简单的 Hello world。
但是分布式系统里面呢，就更加复杂了。比如大家现在用的很典型的微服务。假设你提供了一个微服务，然后在微服务提供的功能就是输出一个 Hello world ，然后让别人来 Call。
A RPC “Hello world” is a miracle We should walk through all of the bugs in:</description>
    </item>
    
    <item>
      <title>Building a Reliable Large-Scale Distributed Database - Principles and Practice</title>
      <link>https://pingcap.com/blog-cn/talk-principles-practice/</link>
      <pubDate>Fri, 21 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-principles-practice/</guid>
      <description>大家好，我叫申砾，是 PingCAP Tech Leader，负责 TiDB 技术相关的工作。我曾就职网易有道、360 搜索，主要在做垂直搜索相关的事情，现在主要关注分布式计算/存储领域。过去的一年半时间我在 PingCAP 做分布式关系数据库 TiDB。目前我们的整个项目已经开源了大概一年时间，获得了不少关注。在 Github 上 Star 数量超过 5k，并且 Contributor 数量为 50+，拥有一个活跃的社区，在国内和国际上都有一定的知名度。 今天主要想和大家分享一下我们在做一款开源的分布式数据库产品过程中得到的一些经验和体会，包括技术上、产品上以及开源社区方面的内容，不会涉及太多技术上的细节。
数据库现状 近年来，随着移动互联网、物联网、人工智能等技术的兴起，我们已经进入了一个信息爆炸的大数据时代，需要处理和分析的数据越来越多，这些数据如何保存、如何应用是一个重要的问题。
传统的 SQL 数据库一般通过中间件、分库分表等方案获得 Scale 的能力。但是这些方案仍然很难做到对应用透明且保证数据均匀分布，同时也无法支持一致性的跨节点事务、JOIN 等操作。在进行扩容的时候往往需要人工介入，随着集群规模的增大，维护和扩展的复杂度呈指数级上升。
以 Google 的 BigTable 论文为开端，涌现出了一大批 NoSQL 方案。这些方案致力于解决扩展性，而牺牲一致性。如果采用 NoSQL 方案替换原有关系型数据库，往往要涉及大规模的业务重构，这相当于将数据库层的计算逻辑复杂度转嫁给业务层，同时还要损失掉事务等特性。
以上两种方案都没有完美地解决高可用的问题，跨机房多活、故障恢复、扩容经常都需要繁重的人工介入。
最近几年，人们希望有一种既有 SQL/NoSQL 的优点，又能避免他们的不足的新型数据库，于是提出了 NewSQL 的概念。Google 发布的 Spanner/F1，算是第一个真正在大规模业务上验证过的分布式数据库，向业界证明了 NewSQL 这条道路的正确性。TiDB 作为 Google Spanner/F1 的开源实现，正是业界盼望已久的 NewSQL 开源数据库。
什么是 NewSQL 并不是所有号称 NewSQL 的数据库都是 NewSQL。我们认为作为 NewSQL 数据库需要有下面几点特性：
首先是 Scale。这点上我想大家都深有体会，不管什么数据解决方案，最基本的要求就是能有足够的能力，保存用户所有的数据。
第二是事务。ACID Transaction，这个东西如果业务不需要，就感觉不到；一旦你的业务有这种需求，就能体会到它的重要性了。事实证明这个需求是广泛存在的，Google 的 BigTable 没有提供事务，结果内部很多业务都有需求，于是各个组造了一堆轮子，Jeff Dean 看不下去，出来说他最大的错误就是没有给 BigTable 提供事务。</description>
    </item>
    
    <item>
      <title>回到过去，找回遗失的珍宝 - TiDB 的历史读功能</title>
      <link>https://pingcap.com/blog-cn/time-travel/</link>
      <pubDate>Wed, 19 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/time-travel/</guid>
      <description>数据作为业务的核心，关系着整个业务的生死，所以对于数据库来说，数据的安全性是放在首位的，从宏观角度来看，安全性不仅仅在于的数据库本身足够稳定不会主动的丢失数据，有的时候更是对业务本身甚至人为失误造成损失是否有足够且便捷的应对方案，例如在游戏行业中经常遇到的反作弊(作弊玩家回档)问题，对于金融业务的审计需求等等，如果在数据库层面上提供相关机制，会让业务开发的工作量和复杂度减少很多。
传统的方案会定期备份数据，几天一次，甚至一天一次，把数据全量备份。当意外发生的时候，可以用来还原。但是用备份数据还原，代价还是非常大的，所有备份时间点后的数据都会丢失，你绝对不希望走到这一步。另外全量备份带来的存储和计算资源的额外开销，对于企业来说也是一笔不小的成本。
可是这种事情是无法完全避免的，我们所有的人都会犯错。对于一个快速迭代的业务，应用的代码不可能做到全面充分的测试，很可能因为应用逻辑的 Bug 导致数据写错，或者被恶意用户找到 bug，当你发现问题时，可以立即把应用回滚到旧版本，但是写错的数据却会一直留在数据库里。
出现这种问题的时候，你该怎么办？你只知道有些数据不对了，但是对的数据是什么，你不知道。如果能回到过去，找回之前的数据该多好。
TiDB 针对这样的需求和场景支持历史版本的读取，所以可以将错误的版本之前的数据取出来，将损失降到最低。
如何使用 TiDB 的历史读功能 使用这个功能非常简单，只需要执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;2016-10-10 09:30:11.123&amp;quot;
这个 session variable 的名字是 TiDB 里定义的 tidb_snapshot, 值是一个时间的字符串，精确到毫秒，执行了这个语句之后，之后这个客户端发出的所有读请求，读到的都是这个时间点看到的数据，这时是不能进行写操作的，因为历史是无法改变的。如果想退出历史读模式，读取最新数据，只需要再次执行一个 SET 语句：
set @@tidb_snapshot = &amp;quot;&amp;quot;
把 tidb_snapshot 设置成空字符串就可以了。
即使在那个历史时间点后，发生了 Schema 更改也没有关系，TiDB 会使用当时的 Schema 执行 SQL 请求。
TiDB 历史读功能和其他数据库的比较 这个功能 MySQL 并不支持，但是在其他的数据库里，比如 Oracle, PostgreSQL 里有类似的功能，叫做历史表(Temporial Table)，是一个SQL 标准。使用的方法是需要你用特殊的建表语法，额外创建一张历史表，历史表比原表多了两个系统定义的字段，代表有效时间，这多出的两个字段是系统维护的。当原表更新数据的时候，系统会把旧版本数据插入到历史表里，当你查询历史数据时，需要用一个特殊的语法指定历史时间，得到需要的结果。
TiDB 和其他数据库的历史表功能相比，主要有以下两个优势：
1，系统默认支持
如果不是默认的行为，我们通常不会特意去建一张历史表，到真正需要用到的时候，你会发现历史表没有创建。
2，使用方便
不需要额外建一张表，不需要用特殊的语法查询。
3，全局视角，而不是以表为单位
TiDB 即使执行了 Drop Table, Drop Database 这样的操作，也可以读到旧的数据。</description>
    </item>
    
    <item>
      <title>How do we build TiDB</title>
      <link>https://pingcap.com/blog-cn/how-do-we-build-tidb/</link>
      <pubDate>Sat, 01 Oct 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/how-do-we-build-tidb/</guid>
      <description>首先我们聊聊 Database 的历史，在已经有这么多种数据库的背景下我们为什么要创建另外一个数据库；以及说一下现在方案遇到的困境，说一下 Google Spanner 和 F1，TiKV 和 TiDB，说一下架构的事情，在这里我们会重点聊一下 TiKV。因为我们产品的很多特性是 TiKV 提供的，比如说跨数据中心的复制，Transaction，auto-scale。
再聊一下为什么 TiKV 用 Raft 能实现所有这些重要的特性，以及 scale，MVCC 和事务模型。东西非常多，我今天不太可能把里面的技术细节都描述得特别细，因为几乎每一个话题都可以找到一篇或者是多篇论文。但讲完之后我还在这边，所以详细的技术问题大家可以单独来找我聊。
后面再说一下我们现在遇到的窘境，就是大家常规遇到的分布式方案有哪些问题，比如 MySQL Sharding。我们创建了无数 MySQL Proxy，比如官方的 MySQL proxy，Youtube 的 Vitess，淘宝的 Cobar、TDDL,以及基于 Cobar 的 MyCAT，金山的 Kingshard，360 的 Atlas，京东的 JProxy，我在豌豆荚也写了一个。可以说，随便一个大公司都会造一个MySQL Sharding的方案。
为什么我们要创建另外一个数据库？ 昨天晚上我还跟一个同学聊到，基于 MySQL 的方案它的天花板在哪里，它的天花板特别明显。有一个思路是能不能通过 MySQL 的 server 把 InnoDB 变成一个分布式数据库，听起来这个方案很完美，但是很快就会遇到天花板。因为 MySQL 生成的执行计划是个单机的，它认为整个计划的 cost 也是单机的，我读取一行和读取下一行之间的开销是很小的，比如迭代 next row 可以立刻拿到下一行。实际上在一个分布式系统里面，这是不一定的。
另外，你把数据都拿回来计算这个太慢了，很多时候我们需要把我们的 expression 或者计算过程等等运算推下去，向上返回一个最终的计算结果，这个一定要用分布式的 plan，前面控制执行计划的节点，它必须要理解下面是分布式的东西，才能生成最好的 plan，这样才能实现最高的执行效率。
比如说你做一个 sum，你是一条条拿回来加，还是让一堆机器一起算，最后给我一个结果。 例如我有 100 亿条数据分布在 10 台机器上，并行在这 10 台 机器我可能只拿到 10 个结果，如果把所有的数据每一条都拿回来，这就太慢了，完全丧失了分布式的价值。聊到 MySQL 想实现分布式，另外一个实现分布式的方案是什么，就是 Proxy。但是 Proxy 本身的天花板在那里，就是它不支持分布式的 transaction，它不支持跨节点的 join，它无法理解复杂的 plan，一个复杂的 plan 打到 Proxy 上面，Proxy 就傻了，我到底应该往哪一个节点上转发呢，如果我涉及到 subquery sql 怎么办？所以这个天花板是瞬间会到，在传统模型下面的修改，很快会达不到我们的要求。</description>
    </item>
    
    <item>
      <title>演讲实录|黄东旭：分布式数据库模式与反模式</title>
      <link>https://pingcap.com/blog-cn/talk-tidb-pattern/</link>
      <pubDate>Mon, 12 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/talk-tidb-pattern/</guid>
      <description>我叫黄东旭，是 PingCAP 的联合创始人兼 CTO，也是本场论坛的主持人。我原来在 MSRA，后来到了网易、豌豆荚。跟在座的大部分数据分析师不太一样的是，我是一个数据库开发，虽然是 CTO，但是还在写代码。
同时，我也是一些用的比较广泛的分布式的开源软件的作者。比如说我们做的 TiDB、TiKV 这些大型的分布式关系型数据库的项目。
我们现在正在做一个 OLTP 的数据库，主要 focus 在大数据的关系型数据库的存储和可扩展性，还有关系的模型，以及在线交易型数据库上的应用。
所以，今天整个数据库的模式和反模式，我都会围绕着如何在一个海量的并发，海量的数据存储的容量上，去做在线实时的数据库业务的一些模式来讲。并从数据库的开发者角度，来为大家分享怎样写出更加适合数据库的一些程序。
基础软件的发展趋势 一开始我先简单介绍一下，现在我认为的一些基础软件上的发展趋势。
开源 第一点，开源是一个非常大的趋势。大家可以看到一些比较著名的基础软件，基本都是开源的，比如 Docker，比如 k8s。甚至在互联网公司里面用的非常多的软件，像 MySQL、Hadoop 等这种新一代的大数据处理的数据库等基础软件，也大多是开源的。其实这背后的逻辑非常简单：在未来其实你很难去将你所有的技术软件都用闭源, 因为开源会慢慢组成一个生态，而并不是被某一个公司绑定住。比如国家经常说去 IOE，为什么？很大的原因就是基本上你的业务是被基础软件绑死的，这个其实是不太好的一个事情。而且现在跟过去二十年前不一样，无论是开源软件的质量，还是社区的迭代速度，都已经是今非昔比，所以基本上开源再也不是低质低量的代名词，在互联网公司已经被验证很多次了。
分布式 第二，分布式会渐渐成为主流的趋势。这是为什么？这个其实也很好理解，因为随着数据量越来越大，大家可以看到，随着现在的硬件发展，我感觉摩尔定律有渐渐失效的趋势。所以单个节点的计算资源或者计算能力，它的增长速度是远比数据的增长速度要慢的。在这种情况下，你要完成业务，存储数据，要应对这么大的并发，只有一种办法就是横向的扩展。横向的扩展，分布式基本是唯一的出路。scale-up 和 scale-out 这两个选择其实我是坚定的站在 scale-out 这边。当然传统的关系数据库都会说我现在用的 Oracle，IBM DB2，他们现在还是在走 scale-up 的路线，但是未来我觉得 scale-out 的方向会渐渐成为主流。 碎片化
碎片化 第三，就是整个基础软件碎片化。现在看上去会越来越严重。但是回想在十年前、二十年前，大家在写程序的时候，我上面一层业务，下面一层数据库。但是现在你会发现，随着可以给你选择的东西越来越多，可以给你在开源社区里面能用到的组件越来越多，业务越来越复杂，你会发现，像缓存有一个单独的软件，比如 redis，队列又有很多可以选择的，比如说 zeromq, rabbitmq, celery 各种各样的队列；数据库有 NoSQL、HBase，关系型数据库有 MySQL 、PG 等各种各样的基础软件都可以选。但是就没有一个非常好东西能够完全解决自己的问题。所以这是一个碎片化的现状。
微服务 第四，是微服务的模式兴起。其实这个也是最近两年在软件架构领域非常火的一个概念。这个概念的背后思想，其实也是跟当年的 SOA 是一脉相承的。就是说一个大的软件项目，其实是非常难去 handle 复杂度的，当你业务变得越来越大以后，维护成本和开发成本会随着项目的代码量呈指数级别上升的。所以现在比较流行的就是，把各个业务之间拆的非常细，然后互相之间尽量做到无状态，整个系统的复杂度可以控制，是由很多比较简单的小的组件组合在一起，来对外提供服务的。
这个服务看上去非常美妙，一会儿会说有什么问题。最典型的问题就是，当你的上层业务都拆成无状态的小服务以后，你会发现原有的逻辑需要有状态的存储服务的时候你是没法拆的。我所有的业务都分成一小块，每一小块都是自己的数据库或者数据存储。比如说一个简单的 case，我每一个小部分都需要依赖同一个用户信息服务，这个信息服务会变成整个系统的一个状态集中的点，如果这个点没有办法做弹性扩展或者容量扩展的话，就会变成整个系统很致命的单点。
所以现在整个基础软件的现状，特别在互联网行业是非常典型的几个大的趋势。我觉得大概传统行业跟互联网行业整合，应该在三到五年，这么一个时间。所以互联网行业遇到的今天，可能就是传统行业，或者其他的行业会遇到的明天。所以，通过现在整个互联网里面，在数据存储、数据架构方面的一些比较新的思想，我们就能知道如何去做这个程序的设计，应对明天数据的量级。
现有存储系统的痛点 其实今天主要的内容是讲存储系统，存储系统现在有哪些痛点？其实我觉得在座的各位应该也都能切身的体会到。
弹性扩展 首先，大数据量级下你如何实现弹性扩展？因为我们今天主要讨论的是 OLTP ，是在线的存储服务，并不是离线分析的服务。所以在线的存储服务，它其实要做到的可用性、一致性，是要比离线的分析业务强得多的。但是在这种情况下，你们怎样做到业务无感知的弹性扩展，你的数据怎么很好的满足现有的高并发、大吞吐，还有数据容量的方案。
可用性 第二，在分布式的存储系统下，你的应用的可用性到底是如何去定义，如何去保证？其实这个也很好理解，因为在大规模的分布式系统里面，任何一个节点，任何一个数据中心或者支架都有可能出现硬件的故障，软件的故障，各种各样的故障，但这个时候你很多业务是并没有办法停止，或者并没有办法去容忍 Down time 的。所以在一个新的环境之下，你如何对你系统的可用性做定义和保证，这是一个新的课题。一会儿我会讲到最新的研究方向和成果。</description>
    </item>
    
    <item>
      <title>TiKV 事务模型概览，Google Spanner 开源实现</title>
      <link>https://pingcap.com/blog-cn/tidb-transaction-model/</link>
      <pubDate>Thu, 01 Sep 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-transaction-model/</guid>
      <description>随着时代的发展，应用和数据的规模越来越大。然而在这个一切都可以水平扩展的时代，你会发现，大多数应用的最下层的关系型数据库，竟然难以找到一个优雅易用的水平扩展解决方案，一直以来不得不依赖静态 Sharding ，牺牲掉事务，然后在业务层各种 Workarounds。作为后端开发者应该深有体会。
层出不穷的 NoSQL 看似解决了数据水平扩展的问题，但是由于跨行事务的缺失和接口的局限，在很多业务中落地还是需要付出很多代价的。最近 Google 基础设施的神人 Jeff Dean 在一次采访中回顾自己作为工程师最大的后悔是什么的问题时提到，他最后悔的事情是没有在 BigTable 中加入跨行事务模型，以至于后来各种各样的团队尝试在 BigTable 上不停的造事务的轮子，但其实这个特性应该是由 BigTable 提供。同样的观点也在他后来的论文中反复提到过。
Google 2012 年在 OSDI 上发表了 Spanner，作为 BigTable 的下一代产品，最主要的特性就是支持跨行事务和在分布式场景上实现 Serializable 的事务隔离级别。我们在2015年底从零开始按照论文做 Spanner 的开源实现 TiKV，于近期开源，和 Spanner 一样，也是一个支持分布式事务和水平扩展的 KV 数据库。一个分布式数据库涉及的技术面非常广泛， 今天我们主要探讨的是 TiKV 的 MVCC（多版本并发控制） 和 Transaction 实现。
MVCC 其实并不是一个新的概念了，在传统的单机关系型数据库使用 MVCC 技术来规避大量的悲观锁的使用，提高并发事务的读写性能。值得注意的是 MVCC 只是一个思想，并不是某个特定的实现，它表示每条记录都有多个版本的，互相不影响，以一个 kv 数据库为例从逻辑上的一行的表示就并不是
Record := {key, value} 而是
Record := {key, value, version} 支持分布式 MVCC 在 KV 系统中比较著名的应该是在 BigTable。在 TiKV 中我们的整个事务模型是构建在一个分布式 MVCC 的基础之上：</description>
    </item>
    
    <item>
      <title>基于 Raft 构建弹性伸缩的存储系统的一些实践</title>
      <link>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</link>
      <pubDate>Sat, 20 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/building-distributed-db-with-raft/</guid>
      <description>最近几年来，越来越多的文章介绍了 Raft 或者 Paxos 这样的分布式一致性算法，且主要集中在算法细节和日志同步方面的应用。但是呢，这些算法的潜力并不仅限于此，基于这样的分布式一致性算法构建一个完整的可弹性伸缩的高可用的大规模存储系统，是一个很新的课题，我结合我们这一年多以来在 TiKV 这样一个大规模分布式数据库上的实践，谈谈其中的一些设计和挑战。
本次分享的主要内容是如何使用 Raft 来构建一个可以「弹性伸缩」存储。其实最近这两年也有很多的文章开始关注类似 Paxos 或者 Raft 这类的分布式一致性算法，但是主要内容还是在介绍算法本身和日志复制，但是对于如何基于这样的分布式一致性算法构建一个大规模的存储系统介绍得并不多，我们目前在以 Raft 为基础去构建一个大规模的分布式数据库 TiKV ，在这方面积累了一些第一手的经验，今天和大家聊聊类似系统的设计，本次分享的内容不会涉及很多 Raft 算法的细节，大家有个 Paxos 或者 Raft 的概念，知道它们是干什么的就好。
先聊聊 Scale 其实一个分布式存储的核心无非两点，一个是 Sharding 策略，一个是元信息存储，如何在 Sharding 的过程中保持业务的透明及一致性是一个拥有「弹性伸缩」能力的存储系统的关键。如果一个存储系统，只有静态的数据 Sharding 策略是很难进行业务透明的弹性扩展的，比如各种 MySQL 的静态路由中间件（如 Cobar）或者 Twemproxy 这样的 Redis 中间件等，这些系统都很难无缝地进行 Scale。
Sharding 的几种策略 在集群中的每一个物理节点都存储若干个 Sharding 单元，数据移动和均衡的单位都是 Sharding 单元。策略主要分两种，一种是 Range 另外一种是 Hash。针对不同类型的系统可以选择不同的策略，比如 HDFS 的Datanode 的数据分布就是一个很典型的例子：
首先是 Range Range 的想法比较简单粗暴，首先假设整个数据库系统的 key 都是可排序的，这点其实还是蛮普遍的，比如 HBase 中 key 是按照字节序排序，MySQL 可以按照自增 ID 排序，其实对于一些存储引擎来说，排序其实是天然的，比如 LSM-Tree 或者 BTree 都是天然有序的。Range 的策略就是一段连续的 key 作为一个 Sharding 单元：</description>
    </item>
    
    <item>
      <title>云时代数据库的核心特点</title>
      <link>https://pingcap.com/blog-cn/cloud-native-db/</link>
      <pubDate>Tue, 02 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/cloud-native-db/</guid>
      <description>引言 最近几年，随着云计算相关技术的发展，各种不同类型的云层出不穷，服务越来越多不同类型的企业业务，传统企业也渐渐开始探索上云的道路。在云上，作为业务最核心的数据库，相比之前的传统方案会有哪些变化呢？在正式聊云时代的数据库特点之前，我们需要了解一下目前云时代架构发生的变化。
畅想一下，未来的服务都跑在云端，任何的服务资源都可以像水电煤一样按需选购。从 IaaS 层的容器/虚拟机，到 PaaS 层的数据库，缓存和计算单元，再到 SaaS 层的不同类型的应用，我们只需要根据自身业务特点进行资源选配，再也不用担心应用服务支撑不住高速的业务增长，因为在云上一切都是弹性伸缩的。有了可靠的基础软件架构，我们就可以把更多精力放到新业务的探索，新模式的创新，就有可能产生更多不一样的新场景，从而催生更强大能力的云端服务，这是一件多么 cool 的事情。
当然，理想要一步一步实现，未来的基础软件栈到底会怎样呢？社区在这方面正在进行积极地探索，其中最有代表性的就是基于容器（以 Docker 为代表）的虚拟化技术和微服务（Microservice）。
在云时代，一切都应该是可伸缩的，使用 k8s（Kubernetes）在保证资源平衡的前提下，通过 Docker 部署我们依托于容器的微服务模块，我们不用关心服务到底跑在哪里，只需要关心我们需要多少服务资源。Docker 提供了极大的便利性，一次构建，到处运行，我们可以很好地解决开发、测试和上线的环境一致性问题。（如果不能很好地保证测试和实际上线环境的一致性，则很有可能需要花费远超过开发的时间去发现和修复问题。）k8s 更是在 Docker 构建的基础上增加了更多的云特性，包括 Docker 的升级，高可用和弹性伸缩等等。 关于 Docker/k8s 相关的讨论已经很多了，因为时间关系，关于具体的细节就不再展开。我们只需要了解，有了它，可以很轻松地解决服务的安装和部署。
下面再聊聊微服务，微服务将一个服务拆分成相对独立的更小的子服务单元，不同的子服务单元之间通过统一的接口（HTTP/RPC 等）进行数据交互。
相比于传统的解决方案，这种架构有很多的优点。
 更好的开发效率和可维护性。微服务将一个单独的服务进行更细力度的拆分，每一个子服务单元专注于更小的功能模块，可以更好地根据业务建立对应的数据模型，降低复杂度，使得开发变得更轻松，维护和部署变得更加友好. 更好的可扩展性。每个不同的子服务单元相互独立，彼此之间没有任何依赖，所以可以根据业务的具体需要，灵活地部署多个子服务单元进行水平扩展。 更强的容错性。当其中一个子服务出现故障的时候，可以通过辅助的负载均衡工具，自动路由到其他的子服务，不会影响整体服务的可用性.  当然，微服务也不是一个银弹，相对来说，这种方案会使整体系统的设计更加复杂，同时也加大了网络的延迟，对整个系统测试的复杂度也会更高。
Docker 提供的隔离型和可移植性，与微服务是一种天然的契合，微服务将整个软件进行拆分和解耦，而通过 Docker/k8s 可以很自然地做到独立的部署，高可用和容错性，似乎一切都可以完美地运转起来。但是真的是这样么？我们是不是忽略了什么？
是的，我们在讨论前面的问题的时候忽略了一个很重要的东西：状态。
从整个技术发展的角度来看，微服务是一个非常有意义的探索。每个人都期望着每个微服务的子服务都是无状态的，这样我可以自由地启停和伸缩，没有任何的心智负担，但是现实的业务情况是什么样的呢？比如一个电商网站，用户正在下单购买一件商品，此时平台是通过订单子服务的 A 应用来提供服务的，突然，因为机器故障，订单子服务的 A 应用不可用了，改由订单子服务的 B 应用提供服务，那么它是必须要知道刚才用户的订单信息的，否则正在访问自己订单页面的用户会发现自己的订单信息突然不见了。虽然我们尽量想把子服务设计成无状态的，但是很多时候状态都是不可避免的，我们不得不通过存储层保存状态，业界最主要的还是各种数据库，包括 RDBMS 和 NoSQL，比如使用 MySQL、MongoDB、HBase、Cassandra 等，特别是有些场景还要考虑数据一致性问题的时候，更加重了对存储层的依赖。
由此可见，云计算时代系统的架构发生了巨大的变化，这一方面为用户提供了更优秀的特性，另一方面也对云计算的组件提出了更高的要求。数据库作为云计算最基础的组件之一，也需要适应这种架构的变化。（这里我们主要关注 SQL 数据库，云时代的数据库以下简称云数据库。）
那么云数据库主要有一些什么样的特点呢？我认为主要有以下几点。 弹性伸缩 传统的数据库方案，常见的会选用 Oracle，MySQL，PostgreSQL。在云时代，数据量的规模有爆发性的增长，传统的数据库很容易遇到单机的存储瓶颈，不得不选用一些集群方案，常见的比如 Oracle RAC、 MySQL Sharding 等，而这些集群方案或多或少都有一些不令人满意的地方。
比如说，Oracle RAC 通过共享存储的硬件方案解决集群问题，这种方式基本上只能通过停机换用更大的共享内存硬件来解决扩容问题，RAC 节点过多会带来更多的并发问题，同样也会带来更高的成本。</description>
    </item>
    
    <item>
      <title>TiDB 中的子查询优化技术</title>
      <link>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-optimization-for-subquery/</guid>
      <description>子查询简介 子查询是嵌套在另一个查询中的 SQL 表达式，比较常见的是嵌套在 FROM 子句中，如 SELECT ID FROM (SELECT * FROM SRC) AS T。对于出现在 FROM 中的子表达式，一般的 SQL 优化器都会处理的很好。但是当子查询出现在 WHERE 子句或 SELECT 列表中时，优化的难度就会大大增加，因为这时子查询可以出现在表达式中的任何位置，如 CASE...WHEN... 子句等。
对于不在 FROM 子句出现的子查询，分为“关联子查询”(Correlated Subquery) 和“非关联子查询”。关联子查询是指子查询中存在外部引用的列，例如：
SELECT * FROM SRC WHERE EXISTS(SELECT * FROM TMP WHERE TMP.id = SRC.id) 对于非关联子查询，我们可以在 plan 阶段进行预处理，将其改写成一个常量。因此，本文只考虑关联子查询的优化。
一般来说，子查询语句分为三种：
 标量子查询（Scalar Subquery），如(SELECT&amp;hellip;) + (SELECT&amp;hellip;)
 集合比较（Quantified Comparision），如T.a = ANY(SELECT&amp;hellip;)
 存在性测试（Existential Test），如NOT EXISTS(SELECT&amp;hellip;)，T.a IN (SELECT&amp;hellip;)
  对于简单的存在性测试类的子查询，一般的做法是将其改写成 SEMI-JOIN。但是很少有文献给出通用性的算法，指出什么样的查询可以“去关联化”。对于不能去关联化的子查询，数据库的做法通常是使用类似 Nested Loop 的方式去执行，称为 correlated execution。</description>
    </item>
    
    <item>
      <title>TiDB 下推 API 实现细节 - Union Scan</title>
      <link>https://pingcap.com/blog-cn/tidb-api-union-scan/</link>
      <pubDate>Sat, 18 Jun 2016 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/tidb-api-union-scan/</guid>
      <description>TiDB 集群的架构分为上层的 SQL 层和底层的 KV 层，SQL 层通过调用 KV 层的 API 读写数据，由于 SQL 层的节点和 KV 层节点通常不在一台机器上，所以，每次调用 KV 的 API 都是一次 RPC, 而往往一个普通的 Select 语句的执行，需要调用几十到几十万次 KV 的接口，这样的结果就是性能非常差，绝大部分时间都消耗在 RPC 上。
为了解决这个问题，TiDB 实现了下推 API，把一部分简单的 SQL 层的执行逻辑下推到 KV 层执行，让 KV 层可以理解 Table 和 Column，可以批量读取多行结果，可以用 Where 里的 Expression 对结果进行过滤, 可以计算聚合函数，大幅减少了 RPC 次数和数据的传输量。
TiDB 的下推 API 通过把 SQL 层的计算下推到 KV 层，大幅减少 RPC 次数和数据传输量，使性能得到数量级的提升。但是当我们一开始启用下推 API 的时候，发现了一个问题，就是当事务写入了数据，但是还未提交的时候，又执行了 Select 操作。
这个时候，刚刚写入的未提交的脏数据读不到，得到的结果是错误的，比如我们在一个空表 t 执行：
begin; insert t values (1); select * from t; 这时我们期待的结果是一条记录 “1”，但是启用下推 API 后得到的结果是空。</description>
    </item>
    
    <item>
      <title></title>
      <link>https://pingcap.com/blog-cn/TOC-User-Case/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>https://pingcap.com/blog-cn/TOC-User-Case/</guid>
      <description> 用户案例 目录  互联网  小米 美团点评 爱奇艺 丰巢 Shopee 转转（一） 转转（二） 摩拜单车(一) 摩拜单车(二) 易果集团 同程艺龙 今日头条 量化派 去哪儿网 猿辅导 特来电 二维火 客如云 凤凰网 零氪科技 一面数据 Mobikok 卡思数据 G7  游戏  西山居 游族网络 盖娅互娱 株式会社 FUNYOURS JAPAN  金融  北京银行 贝壳金服 Ping++ 360 金融  大型企业  海航易建 威锐达测控 万达网络科技集团   </description>
    </item>
    
  </channel>
</rss>